[preface]
== Preface
In a world where information is growing exponentially, leading tools like Apache Spark, provide support to solve many of the relevant problems we face today. From companies looking for ways to improve based on data driven decisions, to research organizations solving problems in healthcare, finance, education, energy and so on; Spark enables analyzing much more information, faster, and more reliably, than ever before.

Various books have been written for learning Apache Spark; for instance, ``Spark: The Definitive Guide: Big Data Processing Made Simple''footnote:[Chambers B, Zaharia M (2018). _Spark: The Definitive Guide Big Data Processing Made Simple_, 1st edition. O'Reilly Media, Inc. ISBN 1491912219, 9781491912218.] is a comprehensive resource while ``Learning Spark: Lightning-Fast Big Data Analysis''footnote:[Karau H, Konwinski A, Wendell P, Zaharia M (2015). _Learning spark: lightning-fast big data analysis_. O'Reilly Media, Inc.] is an introductory book meant to help users get up and running. However, as of this writing, there is no book to learn Apache Spark using the R computing language and neither, a book specifically designed for the R user nor the aspiring R user.

There are some resources online to learn Apache Spark with R, most notably, the https://spark.rstudio.com[spark.rstudio.com] site and the Spark documentation site under https://spark.apache.org/docs/latest/index.html[spark.apache.org]. Both sites are great online resources; however, the content is not intended to be read from start to finish and assumes the reader has some knowledge of Apache Spark, R and cluster computing.

The goal of this book is to help anyone get started with Apache Spark using R. Additionally, since the R programming language was created to simplify data analysis, it is also our belief that this book provides the easiest path for anyone to learn the tools used to solve data analysis problems with Spark. The first chapters provide an introduction to help anyone get up to speed with these concepts and present the tools required to work on these problems in your own computer. We will then quickly ramp up to relevant data science topics, cluster computing, and advanced topics that should interest even the most advanced users.

Therefore, this book is intended to be a useful resource for a wide range of users; from those of you curious to learn Apache Spark, to the experienced reader seeking to understand why and how to use Apache Spark from R.

This book has the following general outline:

Introduction::
  In the first two chapters _Introduction_ and _Getting Started_, you will learn about Apache Spark, R and the tools to perform data analysis with Spark and R.
Analysis::
  In the _Analysis_ chapter, you will learn how to analyze, explore, transform and visualize data in Apache Spark with R.
Modeling::
  In the _Modeling_ and _Pipelines_ chapters, you will learn how to create statistical models with the purpose of extracting information, predicticting outcomes and automating this process in production-ready workflows.
Scaling::
  Up to this point, chapters will have focused on performing operations on your personal computer and with limited data formats; the _Clusters_, _Connections_, _Data_ and _Tuning_ chapters, introduce distributed computing techniques required to perform analysis and modeling across many machines and data formats to tackle the large-scale data and computation problems that Apache Spark was designed for.
Extensions::
  The Extensions chapter describes optional components and extended functionality applicable to specific, yet relevant, use cases. You will learn about alternative modeling frameworks, graph processing, preprocessing data for deep learning, geospatial analysis and genomics at scale.
Advanced::
  This book closes with a set of advanced chapters, _Distributed R_, _Streaming_ and _Contributing_, which advanced users will be most interested in. However, by the time you reach this section, these chapters won’t seem as intimidating; instead, they will be equally relevant, useful and interesting as the previous chapters.

The first group of chapters, Introduction, Analysis, Modeling and Pipelines, provide a gentle introduction to perform data science and machine learning at scale. If you are planning to read this book while also executing code examples, these are great chapters to consider executing line-by-line. Since these chapters teach all the concepts using your personal computer, you won’t be taking advantage of multiple computers which Spark was designed to use. But worry not, the next set of chapters will teach this in detail!

The second group of chapters, Clusters, Connections, Data and Tuning, introduce fundamental concepts in the exciting world of cluster computing using Spark and, to be honest, they also introduce some of the not-so-fun parts of cluster computing; but believe us, it’s worth learning the concepts we will present. Besides, the overview sections in each chapter are especially interesting, informative, easy to read, and help you develop intuitions as to how cluster computing truly works. For these chapters, we actually don’t recommend executing the code line-by-line; especially not for new readers that are trying to learn Spark from start to finish, you can always come back and execute code once you have a proper Spark cluster. Although, if you already have a cluster at work or you are really motivated to get one, you might want to use the Clusters chapters to pick one and then the Connections chapter to connect to it.

The third group of chapters, Extensions, Distributed R, Streaming and Contributing, present tools that should be quite interesting to most readers and easier to follow along. Since many advanced topics will be presented, it is natural to be more interested in some topics than others; for instance, some of you will be interested in analyzing geographic datasets, while others in processing real-time datasets, or both! Based on your personal interests or problems at hand, we encourage readers to execute the code examples that are most relevant to you. All the code in these chapters is written to be executed in your personal computer, but you are also welcomed to use proper Spark clusters since you’ll have the tools required to troubleshoot issues and tune large-scale computations.

=== Authors

_Javier Luraschi_

Javier is experienced in technologies ranging from desktop, web, mobile and backend; to augmented reality and deep learning applications. He previously worked in Microsoft Research and SAP and holds a double degree in Mathematics and Software Engineering. Javier is the creator of sparklyr, r2d3, cloudml and other R packages.

_Kevin Kuo_

Kevin builds open source libraries for machine learning and model deployment. He has held data science positions in various industries including insurance where he was a credentialed actuary. Kevin is the creator of mlflow, mleap, sparkxgb among various R packages. He is also an amateur mixologist and sommelier.

_Edgar Ruiz_

Edgar Ruiz has a background in deploying enterprise reporting and business intelligence solutions. He is the author of multiple articles and blog posts sharing analytics insights and server infrastructure for data science. Edgar is the author and administrator of the https://db.rstudio.com[db.rstudio.com] web site, and the current administrator of the https://spark.rstudio.com[sparklyr web site]. Co-author of the dbplyr package, and creator of the dbplot, tidypredict and the modeldb package.

=== Formatting

Tables generated from code are formatted as follows:

....
# A tibble: 3 x 2
  numbers text 
    <dbl> <chr>
1       1 one  
2       2 two  
3       3 three
....

The dimensions of the table (number of rows and columns) are described in the first row, followed by column names in the second row and column types in the third row. There are also various subtle visual improvements provided by the `tibble` package that we make use of throughout this book.

Most plots will be rendered using the `ggplot2` package and a custom theme available in the Appendix; however, since this book is not focused on data visualization, we only provide code to render a basic plot that won’t match the formatting we applied. If you are interested to learn more about visualization in R, consider specialized books like ``R graphics cookbook: practical recipes for visualizing data''.footnote:[]

=== Acknowledgments

To the package authors that enabled Spark with R we thank _sparklyr_ by Javier Luraschi, Kevin Kuo, Kevin Ushey and JJ Allaire, _dplyr_ by Romain François and Hadley Wickham, _dbplyr_ by Hadley Wickham and Edgar Ruiz, _DBI_ by Kirill Mülller and the authors of the _Apache Spark_ project itself.

To the package authors that released extensions to enrich the Spark and R ecosystem we thank _crassy_ by Akhil Nair, _geospark_ by Harry Zhu, _graphframes_ by Kevin Kuo, _mleap_ by Kevin Kuo, _rsparkling_ by Jakub Hava, Navdeep Gill, Erin LeDell, and Michal Malohlava, _spark.sas7bdat_ by Jan Wijffels, _sparkavro_ by Aki Ariga, _sparkbq_ by Martin Studer, _sparklyr.nested_ by Matt Pollock, _sparktf_ by Kevin Kuo, _sparkts_ by Nathan Eastwood, _sparkwarc_ by Javier Luraschi, _sparkxgb_ by Kevin Kuo and _variantspark_ by Samuel Macêdo.

We thank our wonderful editor, Melissa Potter, for providing us with guidance, encouragement and countless hours of detailed feedback to make this book the best we could have ever written.

Bradley Boehmke, Bryan Adams, Bryan Jonas, Dusty Turner and Hossein Falaki, we thank you for your technical reviews, time, candid feedback and for sharing your expertise with us. Many readers will have a much more pleasant experience thanks to you.

RStudio, JJ Allaire and Tareef Kawaf from supporting this work and the R community itself for their continuous support and encouragement.

Max Kuhn, for his invaluable feedback to the modeling chapter where, with his permission, we adapted examples from his wonderful book ``Feature Engineering and Selection: A Practical Approach for Predictive Models.''

We also thank everyone indirectly involved not explicitly listed in this section, we are truly standing on the shoulders of giants.

This book itself was written in R using _bookdown_ by Yihui Xie, _rmarkdown_ by JJ Allaire and Yihui Xie, _knitr_ by Yihui Xie, visualizations using _ggplot2_ by Hadley Wickham and Winston Chang, diagrams using _nomnoml_ by Daniel Kallin and Javier Luraschi and document conversions using _pandoc_ by John MacFarlane.

=== Conventions Used in This Book

The following typographical conventions are used in this book:

_Italic_:: Indicates new terms, URLs, email addresses, filenames, and file extensions.

+Constant width+:: Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.

**`Constant width bold`**:: Shows commands or other text that should be typed literally by the user.

_++Constant width italic++_:: Shows text that should be replaced with user-supplied values or by values determined by context.


[TIP]
====
This element signifies a tip or suggestion.
====

[NOTE]
====
This element signifies a general note.
====

[WARNING]
====
This element indicates a warning or caution.
====

=== Using Code Examples
++++
<!--PROD: Please reach out to author to find out if they will be uploading code examples to oreilly.com or their own site (e.g., GitHub). If there is no code download, delete this whole section. If there is, when you email digidist with the link, let them know what you filled in for title_title (should be as close to book title as possible, i.e., learning_python_2e). This info will determine where digidist loads the files.-->
++++

Supplemental material (code examples, exercises, etc.) is available for download at link:$$https://travis-ci.org/r-spark/the-r-in-spark$$[].

This book is here to help you get your job done. In general, if example code is offered with this book, you may use it in your programs and documentation. You do not need to contact us for permission unless you’re reproducing a significant portion of the code. For example, writing a program that uses several chunks of code from this book does not require permission. Selling or distributing a CD-ROM of examples from O’Reilly books does require permission. Answering a question by citing this book and quoting example code does not require permission. Incorporating a significant amount of example code from this book into your product’s documentation does require permission.

We appreciate, but do not require, attribution. An attribution usually includes the title, author, publisher, and ISBN. For example: “_Book Title_ by Some Author (O’Reilly). Copyright 2012 Some Copyright Holder, 978-0-596-xxxx-x.”

If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at pass:[<a class="email" href="mailto:permissions@oreilly.com"><em>permissions@oreilly.com</em></a>].

=== O'Reilly Safari

[role = "safarienabled"]
[NOTE]
====
pass:[<a href="http://oreilly.com/safari" class="orm:hideurl"><em class="hyperlink">Safari</em></a>] (formerly Safari Books Online) is a membership-based training and reference platform for enterprise, government, educators, and individuals.
====

Members have access to thousands of books, training videos, Learning Paths, interactive tutorials, and curated playlists from over 250 publishers, including O’Reilly Media, Harvard Business Review, Prentice Hall Professional, Addison-Wesley Professional, Microsoft Press, Sams, Que, Peachpit Press, Adobe, Focal Press, Cisco Press, John Wiley & Sons, Syngress, Morgan Kaufmann, IBM Redbooks, Packt, Adobe Press, FT Press, Apress, Manning, New Riders, McGraw-Hill, Jones & Bartlett, and Course Technology, among others.

For more information, please visit pass:[<a href="http://oreilly.com/safari" class="orm:hideurl"><em>http://oreilly.com/safari</em></a>]. 

=== How to Contact Us

Please address comments and questions concerning this book to the publisher:

++++
<ul class="simplelist">
  <li>O’Reilly Media, Inc.</li>
  <li>1005 Gravenstein Highway North</li>
  <li>Sebastopol, CA 95472</li>
  <li>800-998-9938 (in the United States or Canada)</li>
  <li>707-829-0515 (international or local)</li>
  <li>707-829-0104 (fax)</li>
</ul>
++++

We have a web page for this book, where we list errata, examples, and any additional information. You can access this page at link:$$http://bit.ly/spark-with-r$$[].

To comment or ask technical questions about this book, send email to pass:[<a class="email" href="mailto:bookquestions@oreilly.com"><em>bookquestions@oreilly.com</em></a>].

For more information about our books, courses, conferences, and news, see our website at link:$$http://www.oreilly.com$$[].

Find us on Facebook: link:$$http://facebook.com/oreilly$$[]

Follow us on Twitter: link:$$http://twitter.com/oreillymedia$$[]

Watch us on YouTube: link:$$http://www.youtube.com/oreillymedia$$[]

++++
<!--Fill in...-->
++++
