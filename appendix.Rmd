```{r include=FALSE, eval=TRUE}
knitr::opts_chunk$set(eval = FALSE)
source("r/render.R")
```

# Appendix {-}

## Prerequisites {#appendix-prerequisites}

### Installing R {#appendix-install-r}

From [r-project.org](https://r-project.org/), download and launch the R installer for your platform, Windows, Macs or Linux available.

```{r appendix-r-download, eval=TRUE, echo=FALSE, fig.width=4, fig.align='center', fig.cap='The R Project for Statistical Computing'}
render_image("images/appendix-download-r.png", "The R Project for Statistical Computing")
```

### Installing Java {#appendix-install-java}

From [java.com/download](https://java.com/download), download and launch the installer for your platform, Windows, Macs or Linux are also available.

```{r appendix-java-download, eval=TRUE, fig.width=4, fig.align='center', echo=FALSE, fig.cap='Java Download Page'}
render_image("images/appendix-download-java.png", "Java Download Page")
```

Starting with Spark 2.1, Java 8 is required; however, previous versions of Spark support Java 7. Regardless, we recommend installing Java 8.

### Installing RStudio {#appendix-install-rstudio}

While installing RStudio is not strictly required to work with Spark with R, it will make you much more productive and therefore, I would recommend you take the time to install RStudio from [rstudio.com/download](https://www.rstudio.com/download), then download and launch the installer for your platform: Windows, Macs or Linux.

```{r appendix-rstudio-download, eval=TRUE, fig.width=4, fig.align='center', echo=FALSE, fig.cap='RStudio Downloads Page'}
render_image("images/appendix-rstudio.png", "RStudio Downloads Page")
```

After launching RStudio, you can use RStudio's console panel to execute the code provided in this chapter.

### Using RStudio {#appendix-using-rstudio}

If you are not familiar with RStudio, you should make note of the following panes:

- **Console**: A standalone R console you can use to execute all the code presented in this book.
- **Packages**: This pane allows you to install `sparklyr` with ease, check its version, navigate to the help contents, etc.
- **Connections**: This pane allows you to connecto to Spark, manage your active connection and view the available datasets.

```{r appendix-rstudio-overview, eval=TRUE, fig.width=4, fig.align='center', echo=FALSE, fig.cap='RStudio Overview'}
render_image("images/appendix-rstudio-overview.png", "RStudio Overview")
```

## Diagrams

### Worlds Store Capacity {#appendix-storage-capacity}

```{r eval=FALSE}
library(tidyverse)
read_csv("data/01-worlds-capacity-to-store-information.csv", skip = 8) %>%
  gather(key = storage, value = capacity, analog, digital) %>%
  mutate(year = X1, terabytes = capacity / 1e+12) %>%
  ggplot(aes(x = year, y = terabytes, group = storage)) +
    geom_line(aes(linetype = storage)) +
    geom_point(aes(shape = storage)) +
    scale_y_log10(
      breaks = scales::trans_breaks("log10", function(x) 10^x),
      labels = scales::trans_format("log10", scales::math_format(10^x))
    ) +
    theme_light() +
    theme(legend.position = "bottom")
```

### Daily downloads of CRAN packages {#appendix-cran-downloads}

```{r eval=FALSE}
downloads_csv <- "data/01-intro-r-cran-downloads.csv"
if (!file.exists(downloads_csv)) {
  downloads <- cranlogs::cran_downloads(from = "2014-01-01", to = "2019-01-01")
  readr::write_csv(downloads, downloads_csv)
}

cran_downloads <- readr::read_csv(downloads_csv)

ggplot(cran_downloads, aes(date, count)) + 
  geom_point(colour="black", pch = 21, size = 1) +
  scale_x_date() +
  xlab("") +
  ylab("") +
  theme_light()
```

### Google trends for mainframes, cloud computing and kubernetes {#appendix-cluster-trends}

Data downloaded from [https://trends.google.com/trends/explore?date=all&q=cloud%20computing,mainframe,kubernetes](https://trends.google.com/trends/explore?date=all&q=cloud%20computing,mainframe,kubernetes).

```{r eval=FALSE}
library(r2d3)

lines <- readLines("data/clusters-trends.csv")
lines <- gsub("<1", 0, lines)
writeLines(lines, "data/clusters-trends.csv")

read.csv("data/clusters-trends.csv", skip = 2) %>%
  mutate(year = as.Date(paste(Month, "-01", sep = ""))) %>%
    mutate(`On-Premise` = `mainframe...Worldwide.`,
           Cloud = `cloud.computing...Worldwide.`,
           Kubernetes = `kubernetes...Worldwide.`) %>%
    tidyr::gather(`On-Premise`, Cloud, Kubernetes, key = "trend", value = "popularity") %>%
    ggplot(aes(x=year, y=popularity, group=trend)) +
      plot_style() +
      geom_line(aes(linetype = trend, color = trend)) +
      scale_x_date(date_breaks = "2 year", date_labels = "%Y") +
      labs(title = "Cluster Computing Trends",
           subtitle = "Search popularity for mainframe (on-premise), cloud computing and kubernetes ") +
      scale_color_grey(start = 0.6, end = 0.2) +
      geom_hline(yintercept = 0, size = 1, colour = "#333333")
```
