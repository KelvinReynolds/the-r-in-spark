<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Extensions | Mastering Apache Spark with R</title>
  <meta name="description" content="The complete guide to large-scale analysis and modeling." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Extensions | Mastering Apache Spark with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The complete guide to large-scale analysis and modeling." />
  <meta name="github-repo" content="javierluraschi/the-r-in-spark" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Extensions | Mastering Apache Spark with R" />
  
  <meta name="twitter:description" content="The complete guide to large-scale analysis and modeling." />
  

<meta name="author" content="Javier Luraschi, Kevin Kuo, Edgar Ruiz" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tuning.html"/>
<link rel="next" href="distributed.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119986300-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119986300-1');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Mastering Apache Spark with R</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#intro-background"><i class="fa fa-check"></i><b>1.1</b> Overview</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#intro-hadoop"><i class="fa fa-check"></i><b>1.2</b> Hadoop</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#intro-spark"><i class="fa fa-check"></i><b>1.3</b> Spark</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#intro-r"><i class="fa fa-check"></i><b>1.4</b> R</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#intro-sparklyr"><i class="fa fa-check"></i><b>1.5</b> sparklyr</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#intro-recap"><i class="fa fa-check"></i><b>1.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="starting.html"><a href="starting.html"><i class="fa fa-check"></i><b>2</b> Getting Started</a><ul>
<li class="chapter" data-level="2.1" data-path="starting.html"><a href="starting.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="starting.html"><a href="starting.html#starting-prerequisites"><i class="fa fa-check"></i><b>2.2</b> Prerequisites</a><ul>
<li class="chapter" data-level="2.2.1" data-path="starting.html"><a href="starting.html#starting-install-sparklyr"><i class="fa fa-check"></i><b>2.2.1</b> Installing sparklyr</a></li>
<li class="chapter" data-level="2.2.2" data-path="starting.html"><a href="starting.html#starting-installing-spark"><i class="fa fa-check"></i><b>2.2.2</b> Installing Spark</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="starting.html"><a href="starting.html#starting-connect-to-spark"><i class="fa fa-check"></i><b>2.3</b> Connecting</a></li>
<li class="chapter" data-level="2.4" data-path="starting.html"><a href="starting.html#starting-sparklyr-hello-world"><i class="fa fa-check"></i><b>2.4</b> Using Spark</a><ul>
<li class="chapter" data-level="2.4.1" data-path="starting.html"><a href="starting.html#starting-spark-web-interface"><i class="fa fa-check"></i><b>2.4.1</b> Web Interface</a></li>
<li class="chapter" data-level="2.4.2" data-path="starting.html"><a href="starting.html#starting-analysis"><i class="fa fa-check"></i><b>2.4.2</b> Analysis</a></li>
<li class="chapter" data-level="2.4.3" data-path="starting.html"><a href="starting.html#starting-modeling"><i class="fa fa-check"></i><b>2.4.3</b> Modeling</a></li>
<li class="chapter" data-level="2.4.4" data-path="starting.html"><a href="starting.html#starting-data"><i class="fa fa-check"></i><b>2.4.4</b> Data</a></li>
<li class="chapter" data-level="2.4.5" data-path="starting.html"><a href="starting.html#starting-extensions"><i class="fa fa-check"></i><b>2.4.5</b> Extensions</a></li>
<li class="chapter" data-level="2.4.6" data-path="starting.html"><a href="starting.html#starting-distributed-r"><i class="fa fa-check"></i><b>2.4.6</b> Distributed R</a></li>
<li class="chapter" data-level="2.4.7" data-path="starting.html"><a href="starting.html#starting-streaming"><i class="fa fa-check"></i><b>2.4.7</b> Streaming</a></li>
<li class="chapter" data-level="2.4.8" data-path="starting.html"><a href="starting.html#starting-logs"><i class="fa fa-check"></i><b>2.4.8</b> Logs</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="starting.html"><a href="starting.html#starting-disconnecting"><i class="fa fa-check"></i><b>2.5</b> Disconnecting</a></li>
<li class="chapter" data-level="2.6" data-path="starting.html"><a href="starting.html#starting-using-spark-from-rstudio"><i class="fa fa-check"></i><b>2.6</b> Using RStudio</a></li>
<li class="chapter" data-level="2.7" data-path="starting.html"><a href="starting.html#starting-resources"><i class="fa fa-check"></i><b>2.7</b> Resources</a></li>
<li class="chapter" data-level="2.8" data-path="starting.html"><a href="starting.html#starting-recap"><i class="fa fa-check"></i><b>2.8</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis.html"><a href="analysis.html"><i class="fa fa-check"></i><b>3</b> Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="analysis.html"><a href="analysis.html#analysis-overview"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="analysis.html"><a href="analysis.html#import"><i class="fa fa-check"></i><b>3.2</b> Import</a></li>
<li class="chapter" data-level="3.3" data-path="analysis.html"><a href="analysis.html#wrangle"><i class="fa fa-check"></i><b>3.3</b> Wrangle</a><ul>
<li class="chapter" data-level="3.3.1" data-path="analysis.html"><a href="analysis.html#built-in-functions"><i class="fa fa-check"></i><b>3.3.1</b> Built-in Functions</a></li>
<li class="chapter" data-level="3.3.2" data-path="analysis.html"><a href="analysis.html#correlations"><i class="fa fa-check"></i><b>3.3.2</b> Correlations</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="analysis.html"><a href="analysis.html#visualize"><i class="fa fa-check"></i><b>3.4</b> Visualize</a><ul>
<li class="chapter" data-level="3.4.1" data-path="analysis.html"><a href="analysis.html#using-ggplot2"><i class="fa fa-check"></i><b>3.4.1</b> Using ggplot2</a></li>
<li class="chapter" data-level="3.4.2" data-path="analysis.html"><a href="analysis.html#using-dbplot"><i class="fa fa-check"></i><b>3.4.2</b> Using dbplot</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="analysis.html"><a href="analysis.html#model"><i class="fa fa-check"></i><b>3.5</b> Model</a><ul>
<li class="chapter" data-level="3.5.1" data-path="analysis.html"><a href="analysis.html#caching"><i class="fa fa-check"></i><b>3.5.1</b> Caching</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="analysis.html"><a href="analysis.html#communicate"><i class="fa fa-check"></i><b>3.6</b> Communicate</a></li>
<li class="chapter" data-level="3.7" data-path="analysis.html"><a href="analysis.html#recap"><i class="fa fa-check"></i><b>3.7</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="modeling.html"><a href="modeling.html"><i class="fa fa-check"></i><b>4</b> Modeling</a><ul>
<li class="chapter" data-level="4.1" data-path="modeling.html"><a href="modeling.html#overview-1"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="modeling.html"><a href="modeling.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>4.2</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="4.3" data-path="modeling.html"><a href="modeling.html#feature-engineering"><i class="fa fa-check"></i><b>4.3</b> Feature Engineering</a></li>
<li class="chapter" data-level="4.4" data-path="modeling.html"><a href="modeling.html#supervised-learning"><i class="fa fa-check"></i><b>4.4</b> Supervised Learning</a><ul>
<li class="chapter" data-level="4.4.1" data-path="modeling.html"><a href="modeling.html#generalized-linear-regression"><i class="fa fa-check"></i><b>4.4.1</b> Generalized Linear Regression</a></li>
<li class="chapter" data-level="4.4.2" data-path="modeling.html"><a href="modeling.html#other-models"><i class="fa fa-check"></i><b>4.4.2</b> Other Models</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="modeling.html"><a href="modeling.html#unsupervised-learning"><i class="fa fa-check"></i><b>4.5</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="4.5.1" data-path="modeling.html"><a href="modeling.html#data-preparation"><i class="fa fa-check"></i><b>4.5.1</b> Data Preparation</a></li>
<li class="chapter" data-level="4.5.2" data-path="modeling.html"><a href="modeling.html#topic-modeling"><i class="fa fa-check"></i><b>4.5.2</b> Topic Modeling</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="modeling.html"><a href="modeling.html#recap-1"><i class="fa fa-check"></i><b>4.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="pipelines.html"><a href="pipelines.html"><i class="fa fa-check"></i><b>5</b> Pipelines</a><ul>
<li class="chapter" data-level="5.1" data-path="pipelines.html"><a href="pipelines.html#overview-2"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="pipelines.html"><a href="pipelines.html#creation"><i class="fa fa-check"></i><b>5.2</b> Creation</a></li>
<li class="chapter" data-level="5.3" data-path="pipelines.html"><a href="pipelines.html#use-cases"><i class="fa fa-check"></i><b>5.3</b> Use Cases</a><ul>
<li class="chapter" data-level="5.3.1" data-path="pipelines.html"><a href="pipelines.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>5.3.1</b> Hyperparameter Tuning</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="pipelines.html"><a href="pipelines.html#operating-modes"><i class="fa fa-check"></i><b>5.4</b> Operating Modes</a></li>
<li class="chapter" data-level="5.5" data-path="pipelines.html"><a href="pipelines.html#interoperability"><i class="fa fa-check"></i><b>5.5</b> Interoperability</a></li>
<li class="chapter" data-level="5.6" data-path="pipelines.html"><a href="pipelines.html#deployment"><i class="fa fa-check"></i><b>5.6</b> Deployment</a><ul>
<li class="chapter" data-level="5.6.1" data-path="pipelines.html"><a href="pipelines.html#batch-scoring"><i class="fa fa-check"></i><b>5.6.1</b> Batch Scoring</a></li>
<li class="chapter" data-level="5.6.2" data-path="pipelines.html"><a href="pipelines.html#real-time-scoring"><i class="fa fa-check"></i><b>5.6.2</b> Real-Time Scoring</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="pipelines.html"><a href="pipelines.html#recap-2"><i class="fa fa-check"></i><b>5.7</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="clusters.html"><a href="clusters.html"><i class="fa fa-check"></i><b>6</b> Clusters</a><ul>
<li class="chapter" data-level="6.1" data-path="clusters.html"><a href="clusters.html#clusters-overview"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="clusters.html"><a href="clusters.html#on-premise"><i class="fa fa-check"></i><b>6.2</b> On-Premise</a><ul>
<li class="chapter" data-level="6.2.1" data-path="clusters.html"><a href="clusters.html#clusters-manager"><i class="fa fa-check"></i><b>6.2.1</b> Managers</a></li>
<li class="chapter" data-level="6.2.2" data-path="clusters.html"><a href="clusters.html#distributions"><i class="fa fa-check"></i><b>6.2.2</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="clusters.html"><a href="clusters.html#cloud"><i class="fa fa-check"></i><b>6.3</b> Cloud</a><ul>
<li class="chapter" data-level="6.3.1" data-path="clusters.html"><a href="clusters.html#clusters-amazon-emr"><i class="fa fa-check"></i><b>6.3.1</b> Amazon</a></li>
<li class="chapter" data-level="6.3.2" data-path="clusters.html"><a href="clusters.html#databricks"><i class="fa fa-check"></i><b>6.3.2</b> Databricks</a></li>
<li class="chapter" data-level="6.3.3" data-path="clusters.html"><a href="clusters.html#google"><i class="fa fa-check"></i><b>6.3.3</b> Google</a></li>
<li class="chapter" data-level="6.3.4" data-path="clusters.html"><a href="clusters.html#ibm"><i class="fa fa-check"></i><b>6.3.4</b> IBM</a></li>
<li class="chapter" data-level="6.3.5" data-path="clusters.html"><a href="clusters.html#microsoft"><i class="fa fa-check"></i><b>6.3.5</b> Microsoft</a></li>
<li class="chapter" data-level="6.3.6" data-path="clusters.html"><a href="clusters.html#qubole"><i class="fa fa-check"></i><b>6.3.6</b> Qubole</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="clusters.html"><a href="clusters.html#kubernetes"><i class="fa fa-check"></i><b>6.4</b> Kubernetes</a></li>
<li class="chapter" data-level="6.5" data-path="clusters.html"><a href="clusters.html#tools"><i class="fa fa-check"></i><b>6.5</b> Tools</a><ul>
<li class="chapter" data-level="6.5.1" data-path="clusters.html"><a href="clusters.html#rstudio"><i class="fa fa-check"></i><b>6.5.1</b> RStudio</a></li>
<li class="chapter" data-level="6.5.2" data-path="clusters.html"><a href="clusters.html#jupyter"><i class="fa fa-check"></i><b>6.5.2</b> Jupyter</a></li>
<li class="chapter" data-level="6.5.3" data-path="clusters.html"><a href="clusters.html#clusters-livy"><i class="fa fa-check"></i><b>6.5.3</b> Livy</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="clusters.html"><a href="clusters.html#recap-3"><i class="fa fa-check"></i><b>6.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="connections.html"><a href="connections.html"><i class="fa fa-check"></i><b>7</b> Connections</a><ul>
<li class="chapter" data-level="7.1" data-path="connections.html"><a href="connections.html#connections-overview"><i class="fa fa-check"></i><b>7.1</b> Overview</a><ul>
<li class="chapter" data-level="7.1.1" data-path="connections.html"><a href="connections.html#connections-spark-edge-nodes"><i class="fa fa-check"></i><b>7.1.1</b> Edge Nodes</a></li>
<li class="chapter" data-level="7.1.2" data-path="connections.html"><a href="connections.html#connections-spark-home"><i class="fa fa-check"></i><b>7.1.2</b> Spark Home</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="connections.html"><a href="connections.html#connections-local"><i class="fa fa-check"></i><b>7.2</b> Local</a></li>
<li class="chapter" data-level="7.3" data-path="connections.html"><a href="connections.html#connections-standalone"><i class="fa fa-check"></i><b>7.3</b> Standalone</a></li>
<li class="chapter" data-level="7.4" data-path="connections.html"><a href="connections.html#connections-yarn"><i class="fa fa-check"></i><b>7.4</b> Yarn</a><ul>
<li class="chapter" data-level="7.4.1" data-path="connections.html"><a href="connections.html#connections-yarn-client"><i class="fa fa-check"></i><b>7.4.1</b> Yarn Client</a></li>
<li class="chapter" data-level="7.4.2" data-path="connections.html"><a href="connections.html#connections-yarn-cluster"><i class="fa fa-check"></i><b>7.4.2</b> Yarn Cluster</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="connections.html"><a href="connections.html#connections-livy"><i class="fa fa-check"></i><b>7.5</b> Livy</a></li>
<li class="chapter" data-level="7.6" data-path="connections.html"><a href="connections.html#connections-mesos"><i class="fa fa-check"></i><b>7.6</b> Mesos</a></li>
<li class="chapter" data-level="7.7" data-path="connections.html"><a href="connections.html#connections-kubernetes"><i class="fa fa-check"></i><b>7.7</b> Kubernetes</a></li>
<li class="chapter" data-level="7.8" data-path="connections.html"><a href="connections.html#cloud-1"><i class="fa fa-check"></i><b>7.8</b> Cloud</a></li>
<li class="chapter" data-level="7.9" data-path="connections.html"><a href="connections.html#batches"><i class="fa fa-check"></i><b>7.9</b> Batches</a></li>
<li class="chapter" data-level="7.10" data-path="connections.html"><a href="connections.html#tools-1"><i class="fa fa-check"></i><b>7.10</b> Tools</a></li>
<li class="chapter" data-level="7.11" data-path="connections.html"><a href="connections.html#multiple"><i class="fa fa-check"></i><b>7.11</b> Multiple</a></li>
<li class="chapter" data-level="7.12" data-path="connections.html"><a href="connections.html#connections-troubleshooting"><i class="fa fa-check"></i><b>7.12</b> Troubleshooting</a><ul>
<li class="chapter" data-level="7.12.1" data-path="connections.html"><a href="connections.html#logging"><i class="fa fa-check"></i><b>7.12.1</b> Logging</a></li>
<li class="chapter" data-level="7.12.2" data-path="connections.html"><a href="connections.html#troubleshoot-spark-submit"><i class="fa fa-check"></i><b>7.12.2</b> Spark Submit</a></li>
<li class="chapter" data-level="7.12.3" data-path="connections.html"><a href="connections.html#windows"><i class="fa fa-check"></i><b>7.12.3</b> Windows</a></li>
</ul></li>
<li class="chapter" data-level="7.13" data-path="connections.html"><a href="connections.html#recap-4"><i class="fa fa-check"></i><b>7.13</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>8</b> Data</a><ul>
<li class="chapter" data-level="8.1" data-path="data.html"><a href="data.html#overview-3"><i class="fa fa-check"></i><b>8.1</b> Overview</a></li>
<li class="chapter" data-level="8.2" data-path="data.html"><a href="data.html#read"><i class="fa fa-check"></i><b>8.2</b> Read</a><ul>
<li class="chapter" data-level="8.2.1" data-path="data.html"><a href="data.html#paths"><i class="fa fa-check"></i><b>8.2.1</b> Paths</a></li>
<li class="chapter" data-level="8.2.2" data-path="data.html"><a href="data.html#schema"><i class="fa fa-check"></i><b>8.2.2</b> Schema</a></li>
<li class="chapter" data-level="8.2.3" data-path="data.html"><a href="data.html#memory"><i class="fa fa-check"></i><b>8.2.3</b> Memory</a></li>
<li class="chapter" data-level="8.2.4" data-path="data.html"><a href="data.html#columns"><i class="fa fa-check"></i><b>8.2.4</b> Columns</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="data.html"><a href="data.html#write"><i class="fa fa-check"></i><b>8.3</b> Write</a></li>
<li class="chapter" data-level="8.4" data-path="data.html"><a href="data.html#copy"><i class="fa fa-check"></i><b>8.4</b> Copy</a></li>
<li class="chapter" data-level="8.5" data-path="data.html"><a href="data.html#data-file-formats"><i class="fa fa-check"></i><b>8.5</b> File Formats</a><ul>
<li class="chapter" data-level="8.5.1" data-path="data.html"><a href="data.html#csv"><i class="fa fa-check"></i><b>8.5.1</b> CSV</a></li>
<li class="chapter" data-level="8.5.2" data-path="data.html"><a href="data.html#json"><i class="fa fa-check"></i><b>8.5.2</b> JSON</a></li>
<li class="chapter" data-level="8.5.3" data-path="data.html"><a href="data.html#parquet"><i class="fa fa-check"></i><b>8.5.3</b> Parquet</a></li>
<li class="chapter" data-level="8.5.4" data-path="data.html"><a href="data.html#others"><i class="fa fa-check"></i><b>8.5.4</b> Others</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="data.html"><a href="data.html#data-file-systems"><i class="fa fa-check"></i><b>8.6</b> File Systems</a></li>
<li class="chapter" data-level="8.7" data-path="data.html"><a href="data.html#data-storage-systems"><i class="fa fa-check"></i><b>8.7</b> Storage Systems</a><ul>
<li class="chapter" data-level="8.7.1" data-path="data.html"><a href="data.html#hive"><i class="fa fa-check"></i><b>8.7.1</b> Hive</a></li>
<li class="chapter" data-level="8.7.2" data-path="data.html"><a href="data.html#cassandra"><i class="fa fa-check"></i><b>8.7.2</b> Cassandra</a></li>
<li class="chapter" data-level="8.7.3" data-path="data.html"><a href="data.html#jdbc"><i class="fa fa-check"></i><b>8.7.3</b> JDBC</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="data.html"><a href="data.html#recap-5"><i class="fa fa-check"></i><b>8.8</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="tuning.html"><a href="tuning.html"><i class="fa fa-check"></i><b>9</b> Tuning</a><ul>
<li class="chapter" data-level="9.1" data-path="tuning.html"><a href="tuning.html#overview-4"><i class="fa fa-check"></i><b>9.1</b> Overview</a><ul>
<li class="chapter" data-level="9.1.1" data-path="tuning.html"><a href="tuning.html#tuning-graph-visualization"><i class="fa fa-check"></i><b>9.1.1</b> Graph</a></li>
<li class="chapter" data-level="9.1.2" data-path="tuning.html"><a href="tuning.html#tuning-event-timeline"><i class="fa fa-check"></i><b>9.1.2</b> Timeline</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="tuning.html"><a href="tuning.html#tuning-configuring"><i class="fa fa-check"></i><b>9.2</b> Configuring</a><ul>
<li class="chapter" data-level="9.2.1" data-path="tuning.html"><a href="tuning.html#connect-settings"><i class="fa fa-check"></i><b>9.2.1</b> Connect Settings</a></li>
<li class="chapter" data-level="9.2.2" data-path="tuning.html"><a href="tuning.html#submit-settings"><i class="fa fa-check"></i><b>9.2.2</b> Submit Settings</a></li>
<li class="chapter" data-level="9.2.3" data-path="tuning.html"><a href="tuning.html#runtime-settings"><i class="fa fa-check"></i><b>9.2.3</b> Runtime Settings</a></li>
<li class="chapter" data-level="9.2.4" data-path="tuning.html"><a href="tuning.html#sparklyr-settings"><i class="fa fa-check"></i><b>9.2.4</b> sparklyr Settings</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="tuning.html"><a href="tuning.html#tuning-partitioning"><i class="fa fa-check"></i><b>9.3</b> Partitioning</a><ul>
<li class="chapter" data-level="9.3.1" data-path="tuning.html"><a href="tuning.html#implicit"><i class="fa fa-check"></i><b>9.3.1</b> Implicit</a></li>
<li class="chapter" data-level="9.3.2" data-path="tuning.html"><a href="tuning.html#explicit"><i class="fa fa-check"></i><b>9.3.2</b> Explicit</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="tuning.html"><a href="tuning.html#tuning-caching"><i class="fa fa-check"></i><b>9.4</b> Caching</a><ul>
<li class="chapter" data-level="9.4.1" data-path="tuning.html"><a href="tuning.html#checkpointing"><i class="fa fa-check"></i><b>9.4.1</b> Checkpointing</a></li>
<li class="chapter" data-level="9.4.2" data-path="tuning.html"><a href="tuning.html#tuning-memory"><i class="fa fa-check"></i><b>9.4.2</b> Memory</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="tuning.html"><a href="tuning.html#tuning-shuffling"><i class="fa fa-check"></i><b>9.5</b> Shuffling</a></li>
<li class="chapter" data-level="9.6" data-path="tuning.html"><a href="tuning.html#tuning-serialization"><i class="fa fa-check"></i><b>9.6</b> Serialization</a></li>
<li class="chapter" data-level="9.7" data-path="tuning.html"><a href="tuning.html#configuration-files"><i class="fa fa-check"></i><b>9.7</b> Configuration Files</a></li>
<li class="chapter" data-level="9.8" data-path="tuning.html"><a href="tuning.html#recap-6"><i class="fa fa-check"></i><b>9.8</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="extensions.html"><a href="extensions.html"><i class="fa fa-check"></i><b>10</b> Extensions</a><ul>
<li class="chapter" data-level="10.1" data-path="extensions.html"><a href="extensions.html#overview-5"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="extensions.html"><a href="extensions.html#h2o"><i class="fa fa-check"></i><b>10.2</b> H2O</a></li>
<li class="chapter" data-level="10.3" data-path="extensions.html"><a href="extensions.html#graphs"><i class="fa fa-check"></i><b>10.3</b> Graphs</a></li>
<li class="chapter" data-level="10.4" data-path="extensions.html"><a href="extensions.html#xgboost"><i class="fa fa-check"></i><b>10.4</b> XGBoost</a></li>
<li class="chapter" data-level="10.5" data-path="extensions.html"><a href="extensions.html#deep-learning"><i class="fa fa-check"></i><b>10.5</b> Deep Learning</a></li>
<li class="chapter" data-level="10.6" data-path="extensions.html"><a href="extensions.html#genomics"><i class="fa fa-check"></i><b>10.6</b> Genomics</a></li>
<li class="chapter" data-level="10.7" data-path="extensions.html"><a href="extensions.html#spatial"><i class="fa fa-check"></i><b>10.7</b> Spatial</a></li>
<li class="chapter" data-level="10.8" data-path="extensions.html"><a href="extensions.html#troubleshooting"><i class="fa fa-check"></i><b>10.8</b> Troubleshooting</a></li>
<li class="chapter" data-level="10.9" data-path="extensions.html"><a href="extensions.html#recap-7"><i class="fa fa-check"></i><b>10.9</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="distributed.html"><a href="distributed.html"><i class="fa fa-check"></i><b>11</b> Distributed R</a><ul>
<li class="chapter" data-level="11.1" data-path="distributed.html"><a href="distributed.html#overview-6"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="distributed.html"><a href="distributed.html#use-cases-1"><i class="fa fa-check"></i><b>11.2</b> Use Cases</a><ul>
<li class="chapter" data-level="11.2.1" data-path="distributed.html"><a href="distributed.html#custom-parsers"><i class="fa fa-check"></i><b>11.2.1</b> Custom Parsers</a></li>
<li class="chapter" data-level="11.2.2" data-path="distributed.html"><a href="distributed.html#partitioned-modeling"><i class="fa fa-check"></i><b>11.2.2</b> Partitioned Modeling</a></li>
<li class="chapter" data-level="11.2.3" data-path="distributed.html"><a href="distributed.html#distributed-grid-search"><i class="fa fa-check"></i><b>11.2.3</b> Grid Search</a></li>
<li class="chapter" data-level="11.2.4" data-path="distributed.html"><a href="distributed.html#web-apis"><i class="fa fa-check"></i><b>11.2.4</b> Web APIs</a></li>
<li class="chapter" data-level="11.2.5" data-path="distributed.html"><a href="distributed.html#simulations"><i class="fa fa-check"></i><b>11.2.5</b> Simulations</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="distributed.html"><a href="distributed.html#partitions"><i class="fa fa-check"></i><b>11.3</b> Partitions</a></li>
<li class="chapter" data-level="11.4" data-path="distributed.html"><a href="distributed.html#grouping"><i class="fa fa-check"></i><b>11.4</b> Grouping</a></li>
<li class="chapter" data-level="11.5" data-path="distributed.html"><a href="distributed.html#columns-1"><i class="fa fa-check"></i><b>11.5</b> Columns</a></li>
<li class="chapter" data-level="11.6" data-path="distributed.html"><a href="distributed.html#context"><i class="fa fa-check"></i><b>11.6</b> Context</a></li>
<li class="chapter" data-level="11.7" data-path="distributed.html"><a href="distributed.html#functions"><i class="fa fa-check"></i><b>11.7</b> Functions</a></li>
<li class="chapter" data-level="11.8" data-path="distributed.html"><a href="distributed.html#packages"><i class="fa fa-check"></i><b>11.8</b> Packages</a></li>
<li class="chapter" data-level="11.9" data-path="distributed.html"><a href="distributed.html#cluster-requirements"><i class="fa fa-check"></i><b>11.9</b> Cluster Requirements</a><ul>
<li class="chapter" data-level="11.9.1" data-path="distributed.html"><a href="distributed.html#installing-r"><i class="fa fa-check"></i><b>11.9.1</b> Installing R</a></li>
<li class="chapter" data-level="11.9.2" data-path="distributed.html"><a href="distributed.html#apache-arrow"><i class="fa fa-check"></i><b>11.9.2</b> Apache Arrow</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="distributed.html"><a href="distributed.html#troubleshooting-1"><i class="fa fa-check"></i><b>11.10</b> Troubleshooting</a><ul>
<li class="chapter" data-level="11.10.1" data-path="distributed.html"><a href="distributed.html#worker-logs"><i class="fa fa-check"></i><b>11.10.1</b> Worker Logs</a></li>
<li class="chapter" data-level="11.10.2" data-path="distributed.html"><a href="distributed.html#resolving-timeouts"><i class="fa fa-check"></i><b>11.10.2</b> Resolving Timeouts</a></li>
<li class="chapter" data-level="11.10.3" data-path="distributed.html"><a href="distributed.html#inspecting-partition"><i class="fa fa-check"></i><b>11.10.3</b> Inspecting Partition</a></li>
<li class="chapter" data-level="11.10.4" data-path="distributed.html"><a href="distributed.html#debugging-workers"><i class="fa fa-check"></i><b>11.10.4</b> Debugging Workers</a></li>
</ul></li>
<li class="chapter" data-level="11.11" data-path="distributed.html"><a href="distributed.html#recap-8"><i class="fa fa-check"></i><b>11.11</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="streaming.html"><a href="streaming.html"><i class="fa fa-check"></i><b>12</b> Streaming</a><ul>
<li class="chapter" data-level="12.1" data-path="streaming.html"><a href="streaming.html#overview-7"><i class="fa fa-check"></i><b>12.1</b> Overview</a></li>
<li class="chapter" data-level="12.2" data-path="streaming.html"><a href="streaming.html#transformations"><i class="fa fa-check"></i><b>12.2</b> Transformations</a><ul>
<li class="chapter" data-level="12.2.1" data-path="streaming.html"><a href="streaming.html#analysis-1"><i class="fa fa-check"></i><b>12.2.1</b> Analysis</a></li>
<li class="chapter" data-level="12.2.2" data-path="streaming.html"><a href="streaming.html#modeling-1"><i class="fa fa-check"></i><b>12.2.2</b> Modeling</a></li>
<li class="chapter" data-level="12.2.3" data-path="streaming.html"><a href="streaming.html#pipelines-1"><i class="fa fa-check"></i><b>12.2.3</b> Pipelines</a></li>
<li class="chapter" data-level="12.2.4" data-path="streaming.html"><a href="streaming.html#distributed-r-streaming-r-code"><i class="fa fa-check"></i><b>12.2.4</b> Distributed R {streaming-r-code}</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="streaming.html"><a href="streaming.html#kafka"><i class="fa fa-check"></i><b>12.3</b> Kafka</a></li>
<li class="chapter" data-level="12.4" data-path="streaming.html"><a href="streaming.html#shiny"><i class="fa fa-check"></i><b>12.4</b> Shiny</a></li>
<li class="chapter" data-level="12.5" data-path="streaming.html"><a href="streaming.html#recap-9"><i class="fa fa-check"></i><b>12.5</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="contributing.html"><a href="contributing.html"><i class="fa fa-check"></i><b>13</b> Contributing</a><ul>
<li class="chapter" data-level="13.1" data-path="contributing.html"><a href="contributing.html#contributing-overview"><i class="fa fa-check"></i><b>13.1</b> Overview</a></li>
<li class="chapter" data-level="13.2" data-path="contributing.html"><a href="contributing.html#contributing-spark-api"><i class="fa fa-check"></i><b>13.2</b> Spark API</a></li>
<li class="chapter" data-level="13.3" data-path="contributing.html"><a href="contributing.html#spark-extensions"><i class="fa fa-check"></i><b>13.3</b> Spark Extensions</a></li>
<li class="chapter" data-level="13.4" data-path="contributing.html"><a href="contributing.html#scala-code"><i class="fa fa-check"></i><b>13.4</b> Scala Code</a></li>
<li class="chapter" data-level="13.5" data-path="contributing.html"><a href="contributing.html#recap-10"><i class="fa fa-check"></i><b>13.5</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>14</b> Appendix</a><ul>
<li class="chapter" data-level="14.1" data-path="appendix.html"><a href="appendix.html#appendix-preface"><i class="fa fa-check"></i><b>14.1</b> Preface</a><ul>
<li class="chapter" data-level="14.1.1" data-path="appendix.html"><a href="appendix.html#appendix-ggplot2-theme"><i class="fa fa-check"></i><b>14.1.1</b> Formatting</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="appendix.html"><a href="appendix.html#appendix-intro"><i class="fa fa-check"></i><b>14.2</b> Introduction</a><ul>
<li class="chapter" data-level="14.2.1" data-path="appendix.html"><a href="appendix.html#appendix-storage-capacity"><i class="fa fa-check"></i><b>14.2.1</b> Worlds Store Capacity</a></li>
<li class="chapter" data-level="14.2.2" data-path="appendix.html"><a href="appendix.html#appendix-cran-downloads"><i class="fa fa-check"></i><b>14.2.2</b> Daily downloads of CRAN packages</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="appendix.html"><a href="appendix.html#appendix-starting"><i class="fa fa-check"></i><b>14.3</b> Getting Started</a><ul>
<li class="chapter" data-level="14.3.1" data-path="appendix.html"><a href="appendix.html#appendix-prerequisites"><i class="fa fa-check"></i><b>14.3.1</b> Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="appendix.html"><a href="appendix.html#appendix-analysis"><i class="fa fa-check"></i><b>14.4</b> Analysis</a><ul>
<li class="chapter" data-level="14.4.1" data-path="appendix.html"><a href="appendix.html#hive-functions"><i class="fa fa-check"></i><b>14.4.1</b> Hive Functions</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="appendix.html"><a href="appendix.html#appendix-modeling"><i class="fa fa-check"></i><b>14.5</b> Modeling</a><ul>
<li class="chapter" data-level="14.5.1" data-path="appendix.html"><a href="appendix.html#appendix-ml-functionlist"><i class="fa fa-check"></i><b>14.5.1</b> MLlib Functions</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="appendix.html"><a href="appendix.html#appendix-clusters"><i class="fa fa-check"></i><b>14.6</b> Clusters</a><ul>
<li class="chapter" data-level="14.6.1" data-path="appendix.html"><a href="appendix.html#appendix-cluster-trends"><i class="fa fa-check"></i><b>14.6.1</b> Google trends for mainframes, cloud computing and kubernetes</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="appendix.html"><a href="appendix.html#appendix-streaming"><i class="fa fa-check"></i><b>14.7</b> Streaming</a><ul>
<li class="chapter" data-level="14.7.1" data-path="appendix.html"><a href="appendix.html#appendix-streaming-generator"><i class="fa fa-check"></i><b>14.7.1</b> Stream Generator</a></li>
<li class="chapter" data-level="14.7.2" data-path="appendix.html"><a href="appendix.html#appendix-streaming-kafka"><i class="fa fa-check"></i><b>14.7.2</b> Installing Kafka</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>15</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mastering Apache Spark with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="extensions" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Extensions</h1>
<blockquote>
<p>“I try to know as many people as I can. You never know which one you’ll need.”</p>
<p>— Tyrion Lannister</p>
</blockquote>
<p>In the previous chapter, <a href="tuning">Tuning</a>, you learned how Spark processes data at large-scale by allowing users to configure the cluster resources, partition data implicitly or explicitly, execute commands across distributed compute nodes, shuffle data across them when needed, cache data to improve performance and serialize data efficiently over the network. You also learned how to configure the different Spark settings used while connecting, submitting a job, running and application and particular settings applicable only to R and R extensions that we will present in this chapter.</p>
<p>The <a href="analysis.html#analysis">Analysis</a>, <a href="modeling.html#modeling">Modeling</a> and Data chapters provided a foundation to read and understand most datasets. However, the functionality that was presented was scoped to Spark’s built-in features and tabular datasets. This chapter will go beyond tabular data and explore how to analyze and model networks of interconnected objects through graph processing, analyze genomics datasets, prepare data for deep learning, analyze geographic datasets and use advanced modeling libraries like H2O and XGBoost over large-scale datasets.</p>
<p>The combination of all the content presented in all the previous chapters should take care of most of your large-scale computing needs. However, for those few use cases where functionality is still lacking, the following chapters will provide tools to extend Spark yourself; either, through custom R transformation, custom Scala code or through recent new execution mode in Spark that enable analyzing real-time datasets. Although, before reinventing the wheel, we will present some of the extensions available in Spark.</p>
<div id="overview-5" class="section level2">
<h2><span class="header-section-number">10.1</span> Overview</h2>
<p>In the Introduction chapter we presented the R community as a vibrant group of individuals collaborating with each other in many ways, one of them, by moving open science forward by creating R packages that can be installed from CRAN. In a similar way, but in a much smaller scale, the R community has contributed extensions that increase the functionality initially supported in Spark and R. Spark itself also provides support for creating Spark extensions and, in-fact, many R extensions make use of Spark extensions.</p>
<p>Extensions are constantly being created so this section will be outdated at any given point in time, in addition, we might not even be aware of many Spark and R extensions; however, at the very least we can track the extensions that are available in CRAN by looking at the “reverse imports” for <code>sparklyr</code> in CRAN. <span class="citation">(“CRAN - Package Sparklyr” <a href="#ref-extensions-sparklyr-cran">2019</a>)</span> Extensions and R packages published in CRAN tend to be the most stable since when a package is published in CRAN, it will go through a review process which increases the overall quality of a contribution.</p>
<p>While we wish we could present all the extensions, we’ will’ve scoped this chapter to the extensions that should be the most interesting to most readers. You can find additional ones under the <a href="https://github.com/r-spark">github.com/r-spark</a> organization or by searching repos on GitHub with the <code>sparklyr</code> tag.</p>
<dl>
<dt>rsparkling</dt>
<dd>The <code>rsparkling</code> extensions allows you to use H2O and Spark from R. This extension is what we would consider advanced modeling in Spark. While Spark’s built-in modeling library, Spark MLlib, is quite useful in many cases; H2O’s modeling capabilities can compute additional statistical metrics and can provide performance and scalability improvements over Spark MLlib. We, ourselves, have not performed detailed comparisons nor benchmarks between MLlib and H2O; so this is something you will have to research on your own to create a complete picture of when to use H2O’s capabilities.
</dd>
<dt>graphframes</dt>
<dd>The <code>graphframes</code> extensions adds support to process graphs in Spark. A graph is a structure that describes a set of objects in which some pairs of the objects are in some sense related. As you learned in the Introduction chapter, ranking web pages was an early motivation to develop precursors to Spark powered by MapReduce; web pages happen to form a graph if you consider a link between pages as the relationship between each pair of pages. Computing operations likes PageRank over graphs can be quite useful in web search and social networks to mention a few applications.
</dd>
<dt>sparktf</dt>
<dd>The <code>sparktf</code> extension provides support to write TensorFlow records in Spark. TensorFlow is one of the leading deep learning frameworks and it is often used with large amounts of numerical data represented as TensorFlow records, a file format optimized for TensorFlow. Spark it is often used to process unstructured and large-scale datasets into smaller numerical datasets that can easily fit into a GPU. You can use this extension to save datasets in the TensorFLow record file format.
</dd>
<dt>xgboost</dt>
<dd>The <code>xgboost</code> extension brings the well-known XGBoost modeling library to the world of large-scale computing. XGBoost is a scalable, portable and distributed library for gradient boosting. It became well known in the machine learning competition circles after its use in the winning solution of the Higgs Machine Learning Challenge <span class="citation">(“Higgs Boson Machine Learning Challenge” <a href="#ref-extensions-higgs-challenge">2019</a>)</span> and has remained popular in other Kaggle competitions since then.
</dd>
<dt>variantspark</dt>
<dd>The <code>variantspark</code> extension provides an interface to use Variant Spark, a scalable toolkit for genome-wide association studies (GWAS). It currently provides functionality to build random forest models, estimating variable importance and reading Variant Call Format (VCF) files. While there are other random forest implementations in Spark, most of them are not optimized to deal with GWAS datasets, which usually come with thousands of samples and millions of variables.
</dd>
<dt>geospark</dt>
<dd>The <code>geospark</code> extensions enables us to load and query large-scale geographic datasets. Usually datasets containing latitude and longitude points or complex areas defined in the Well-known Text (WKT) format, a text markup language for representing vector geometry objects on a map.
</dd>
</dl>
<p>Before you learn how and when to use each extension, we should first briefly explain how extensions can be used with R and Spark.</p>
<p>First, a Spark extension is just and R package that happens to be aware of Spark. As any other R package, you will first have to install the R package. Once installed, it is important to know that you will need to reconnect to Spark before the extension can be used. So, in general, the pattern you should follow goes as follows:</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb323-1" title="1"><span class="kw">library</span>(sparkextension)</a>
<a class="sourceLine" id="cb323-2" title="2"><span class="kw">library</span>(sparklyr)</a>
<a class="sourceLine" id="cb323-3" title="3"></a>
<a class="sourceLine" id="cb323-4" title="4">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;&lt;master&gt;&quot;</span>)</a></code></pre></div>
<p>Notice that <code>sparklyr</code> is loaded after the extensions to allow the extension to register properly. If you had to install and load a new extension you would simply have to disconnect first using <code>spark_disconnect(sc)</code>, restart your R session, and repeat the steps above with the new extension.</p>
<p>It’s not hard to install and use Spark extensions from R; however, each extension can be a world on it’s own so most of the time you will have to spend time understanding what the extension is, when to use it and how to use it properly. The first extension you will learn about is the <code>rsparkling</code> extension which enables you to use H2O in Spark with R.</p>
</div>
<div id="h2o" class="section level2">
<h2><span class="header-section-number">10.2</span> H2O</h2>
<p><a href="https://www.h2o.ai/">H2O</a> is open-source software for large-scale modeling created by H2O.ai, which allows you to fit thousands of potential models as part of discovering patterns in data. You can consider using H2O to complement or replace Spark’s default modeling algorithms. It is common to Spark’s default modeling algorithms and transition to H2O when Spark’s algorithms fall short or when advanced functionality (like additional modeling metrics or automatic model selection) are desired</p>
<p>We can’t do justice to H2O’s great modeling capabilities in a single paragraph, explaining H2O properly will require a book in itself. Instead, we would like to recommend reading the “Practical machine learning with H2O” <span class="citation">(Cook <a href="#ref-extensions-practical-h2o">2016</a>)</span> book to explore in-depth H2O’s modeling algorithms and features. In the meantime, you can use this section as a brief guide to get started using H2O in Spark with R.</p>
<p>In order to use H2O with Spark, it is important to know that there are four components involved: H2O, Sparkling Water, <a href="https://github.com/h2oai/sparkling-water/tree/master/r">rsparkling</a> and Spark. Sparkling Water allows users to combine the fast, scalable machine learning algorithms of H2O with the capabilities of Spark. You can think of Sparkling Water as a component bridging Spark with H2O and <code>rsparkling</code> as the R front-end for Sparkling Water, this is illustrated in Figure <a href="extensions.html#fig:extensions-h2o-diagram">10.1</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-h2o-diagram"></span>
<img src="the-r-in-spark_files/figure-html/extensions-h2o-diagram-1.png" alt="H2O components with Spark and R" width="768" />
<p class="caption">
FIGURE 10.1: H2O components with Spark and R
</p>
</div>
<p>First, install <code>rsparkling</code> and <code>h2o</code> as specified in the <code>rsparkling</code> documentation site. <span class="citation">(“RSparkling — H2o Sparkling Water 2.3.31 Documentation” <a href="#ref-extensions-h2o-rsparkling-docs">2019</a>)</span></p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb324-1" title="1"><span class="kw">install.packages</span>(<span class="st">&quot;h2o&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;source&quot;</span>,</a>
<a class="sourceLine" id="cb324-2" title="2">  <span class="dt">repos =</span> <span class="st">&quot;http://h2o-release.s3.amazonaws.com/h2o/rel-yates/5/R&quot;</span>)</a>
<a class="sourceLine" id="cb324-3" title="3"><span class="kw">install.packages</span>(<span class="st">&quot;rsparkling&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;source&quot;</span>,</a>
<a class="sourceLine" id="cb324-4" title="4">  <span class="dt">repos =</span> <span class="st">&quot;http://h2o-release.s3.amazonaws.com/sparkling-water/rel-2.3/31/R&quot;</span>)</a></code></pre></div>
<p>It is important to notice that you need to use compatible versions of Spark, Sparkling Water and H2O as specified in their docs; we present instructions for Spark 2.3, but using different Spark versions will require you to install different versions. So let’s start by checking the version of H2O by running,</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb325-1" title="1"><span class="kw">packageVersion</span>(<span class="st">&quot;h2o&quot;</span>)</a></code></pre></div>
<pre><code>## [1] &#39;3.26.0.2&#39;</code></pre>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb327-1" title="1"><span class="kw">packageVersion</span>(<span class="st">&quot;rsparkling&quot;</span>)</a></code></pre></div>
<pre><code>## [1] &#39;0.2.18&#39;</code></pre>
<p>We can then connect with the supported Spark versions as follows, you will have to adjust the <code>master</code> parameter for your particular cluster.</p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb329-1" title="1"><span class="kw">library</span>(rsparkling)</a>
<a class="sourceLine" id="cb329-2" title="2"><span class="kw">library</span>(sparklyr)</a>
<a class="sourceLine" id="cb329-3" title="3"><span class="kw">library</span>(h2o)</a>
<a class="sourceLine" id="cb329-4" title="4"></a>
<a class="sourceLine" id="cb329-5" title="5">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3&quot;</span>,</a>
<a class="sourceLine" id="cb329-6" title="6">                    <span class="dt">config =</span> <span class="kw">list</span>(<span class="dt">sparklyr.connect.timeout =</span> <span class="dv">3</span> <span class="op">*</span><span class="st"> </span><span class="dv">60</span>))</a>
<a class="sourceLine" id="cb329-7" title="7"></a>
<a class="sourceLine" id="cb329-8" title="8">cars &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, mtcars)</a></code></pre></div>
<p>H2O provides a web interface which can help you monitor training and access much of H2O’s functionality. The web interface can be accessed through <code>h2o_flow(sc)</code>, it is referred to as H2O Flow and is shown in Figure <a href="extensions.html#fig:extensions-h2o-flow">10.2</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-h2o-flow"></span>
<img src="images/extensions-h2o-flow-resized.png" alt="H2O Flow Interface using Spark with R" width="1500" />
<p class="caption">
FIGURE 10.2: H2O Flow Interface using Spark with R
</p>
</div>
<p>When using H2O, you will have to convert your Spark DataFrame into and H2O DataFrame through <code>as_h2o_frame</code>:</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb330-1" title="1">cars_h2o &lt;-<span class="st"> </span><span class="kw">as_h2o_frame</span>(sc, cars)</a>
<a class="sourceLine" id="cb330-2" title="2">cars_h2o</a></code></pre></div>
<pre><code>   mpg cyl disp  hp drat    wt  qsec vs am gear carb
1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1

[32 rows x 11 columns] </code></pre>
<p>Then you can use many of the modeling functions available in the <code>h2o</code> package with ease. For instance, we can fit a generalized linear model with ease:</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb332-1" title="1">model &lt;-<span class="st"> </span><span class="kw">h2o.glm</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="st">&quot;wt&quot;</span>, <span class="st">&quot;cyl&quot;</span>),</a>
<a class="sourceLine" id="cb332-2" title="2">                 <span class="dt">y =</span> <span class="st">&quot;mpg&quot;</span>,</a>
<a class="sourceLine" id="cb332-3" title="3">                 <span class="dt">training_frame =</span> cars_h2o,</a>
<a class="sourceLine" id="cb332-4" title="4">                 <span class="dt">lambda_search =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<p>H2O provides additional metrics not necessarily available in Spark’s modeling algorithms, the model that we just fit <code>Residual Deviance</code> is provided in the model while this would not be a standard metric when using Spark MLlib.</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb333-1" title="1">model</a></code></pre></div>
<pre><code>...
MSE:  6.017684
RMSE:  2.453097
MAE:  1.940985
RMSLE:  0.1114801
Mean Residual Deviance :  6.017684
R^2 :  0.8289895
Null Deviance :1126.047
Null D.o.F. :31
Residual Deviance :192.5659
Residual D.o.F. :29
AIC :156.2425</code></pre>
<p>Then you can run prediction over the generalized linear model, a similar approach would work for many other models available in H2O:</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb335-1" title="1">predictions &lt;-<span class="st"> </span><span class="kw">as_h2o_frame</span>(sc, <span class="kw">copy_to</span>(sc, <span class="kw">data.frame</span>(<span class="dt">wt =</span> <span class="dv">2</span>, <span class="dt">cyl =</span> <span class="dv">6</span>)))</a>
<a class="sourceLine" id="cb335-2" title="2"><span class="kw">h2o.predict</span>(model, predictions)</a></code></pre></div>
<pre><code>   predict
1 24.05984

[1 row x 1 column]</code></pre>
<p>H2O can also be used to perform automatic training and tuning of many models; meaning that, H2O can choose which model to use for you using AutoML. <span class="citation">(“AutoML: Automatic Machine Learning” <a href="#ref-extensions-h2o-automl">2019</a>)</span></p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb337-1" title="1">automl &lt;-<span class="st"> </span><span class="kw">h2o.automl</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="st">&quot;wt&quot;</span>, <span class="st">&quot;cyl&quot;</span>), <span class="dt">y =</span> <span class="st">&quot;mpg&quot;</span>,</a>
<a class="sourceLine" id="cb337-2" title="2">                     <span class="dt">training_frame =</span> cars_h2o,</a>
<a class="sourceLine" id="cb337-3" title="3">                     <span class="dt">max_models =</span> <span class="dv">20</span>,</a>
<a class="sourceLine" id="cb337-4" title="4">                     <span class="dt">seed =</span> <span class="dv">1</span>)</a></code></pre></div>
<p>For this particular dataset, H2O finds out that a Deep Learning model is a better fit than GLM<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>. Specifically, H2O’s AutoML explored using XGBoost, Deep Learning, GLM and a Stacked Ensemble models.</p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb338-1" title="1">automl<span class="op">@</span>leaderboard</a></code></pre></div>
<pre><code>model_id              mean_residual_dev…     rmse      mse      mae     rmsle
1 DeepLearning_…                6.541322 2.557601 6.541322 2.192295 0.1242028
2 XGBoost_grid_1…               6.958945 2.637981 6.958945 2.129421 0.1347795
3 XGBoost_grid_1_…              6.969577 2.639996 6.969577 2.178845 0.1336290
4 XGBoost_grid_1_…              7.266691 2.695680 7.266691 2.167930 0.1331849
5 StackedEnsemble…              7.304556 2.702694 7.304556 1.938982 0.1304792
6 XGBoost_3_…                   7.313948 2.704431 7.313948 2.088791 0.1348819</code></pre>
<p>Rather than using the leaderboard, you can focus on the best model through <code>automl@leader</code>; for example, you can glance at the particular parameters from this Deep Learning model as follows:</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb340-1" title="1">tibble<span class="op">::</span><span class="kw">tibble</span>(<span class="dt">parameter =</span> <span class="kw">names</span>(automl<span class="op">@</span>leader<span class="op">@</span>parameters),</a>
<a class="sourceLine" id="cb340-2" title="2">               <span class="dt">value =</span> <span class="kw">as.character</span>(automl<span class="op">@</span>leader<span class="op">@</span>parameters))</a></code></pre></div>
<pre><code># A tibble: 20 x 2
   parameter                         values                                                       
   &lt;chr&gt;                             &lt;chr&gt;                                                        
 1 model_id                          DeepLearning_grid_1_AutoML…         
 2 training_frame                    automl_training_frame_rdd…
 3 nfolds                            5                                                            
 4 keep_cross_validation_models      FALSE                                                        
 5 keep_cross_validation_predictions TRUE                                                         
 6 fold_assignment                   Modulo                                                       
 7 overwrite_with_best_model         FALSE                                                        
 8 activation                        RectifierWithDropout                                         
 9 hidden                            200                                                          
10 epochs                            10003.6618461538                                             
11 seed                              1                                                            
12 rho                               0.95                                                         
13 epsilon                           1e-06                                                        
14 input_dropout_ratio               0.2                                                          
15 hidden_dropout_ratios             0.4                                                          
16 stopping_rounds                   0                                                            
17 stopping_metric                   deviance                                                     
18 stopping_tolerance                0.05                                                         
19 x                                 c(&quot;cyl&quot;, &quot;wt&quot;)                                         
20 y                                 mpg </code></pre>
<p>You can then predict using the leader as follows,</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb342-1" title="1"><span class="kw">h2o.predict</span>(automl<span class="op">@</span>leader, predictions)</a></code></pre></div>
<pre><code>   predict
1 30.74639

[1 row x 1 column] </code></pre>
<p>Many additional examples are available under <a href="http://spark.rstudio.com/guides/h2o/">spark.rstudio.com/guides/h2o</a>, you can also request help from <a href="https://github.com/h2oai/sparkling-water/tree/master/r">github.com/h2oai/sparkling-water/tree/master/r</a>, the official GitHub repository for the <code>rsparkling</code> package.</p>
<p>The next extension, <code>graphframes</code>, will allow you to process large-scale relational datasets; however, before you start using it, make sure to disconnect with <code>spark_disconnect(sc)</code> and restart your R session since using a different extensions requires you to reconnect to Spark and reload <code>sparklyr</code>.</p>
</div>
<div id="graphs" class="section level2">
<h2><span class="header-section-number">10.3</span> Graphs</h2>
<p>The first paper in the history of graph theory was written by Leonhard Euler on the Seven Bridges of Königsberg in 1736. The problem was to devise a walk through the city that would cross each of those bridges once and only, the original diagram is shown in Figure <a href="extensions.html#fig:extensions-eulers-paths">10.3</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-eulers-paths"></span>
<img src="images/extensions-eulers-paths-resized.png" alt="Seven Bridges of Königsberg from the Euler Archive" width="1500" />
<p class="caption">
FIGURE 10.3: Seven Bridges of Königsberg from the Euler Archive
</p>
</div>
<p>Today, a graph is defined as an ordered pair <span class="math inline">\(G=(V,E)\)</span>, with <span class="math inline">\(V\)</span> a set of vertices (nodes or points) and <span class="math inline">\(E \subseteq \{\{x, y\} | (x, y) ∈ \mathrm{V}^2 \land x \ne y\}\)</span> a set of edges (links or lines) which are either an unordered pair for <em>undirected graphs</em> or an ordered pair for <em>directed graphs</em>. The former describing links where the direction does not matter and the latter linked where it does.</p>
<p>As a simple example, we can use the <code>highschool</code> dataset from the <code>ggraph</code> package which tracks friendship among high school boys. In this dataset, the vertices are the students and the edges describe pairs of students who happen to be friends in a particular year.</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb344-1" title="1"><span class="kw">install.packages</span>(<span class="st">&quot;ggraph&quot;</span>)</a>
<a class="sourceLine" id="cb344-2" title="2"><span class="kw">install.packages</span>(<span class="st">&quot;igraph&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb345-1" title="1">ggraph<span class="op">::</span>highschool</a></code></pre></div>
<pre><code># A tibble: 506 x 3
    from    to  year
   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
 1     1    14  1957
 2     1    15  1957
 3     1    21  1957
 4     1    54  1957
 5     1    55  1957
 6     2    21  1957
 7     2    22  1957
 8     3     9  1957
 9     3    15  1957
10     4     5  1957
# … with 496 more rows</code></pre>
<p>While the highschool dataset can be easily processed in R, even medium size graph datasets can be hard to process without distributing this work across a cluster of machines which Spark is suited for. Spark supports processing graphs through the <a href="https://github.com/rstudio/graphframes">graphframes</a> extension which in turn uses the <a href="https://spark.apache.org/graphx/">GraphX</a> Spark component. GraphX is Apache Spark’s API for graphs and graph-parallel computation, it’s comparable in performance to the fastest specialized graph processing systems and provides a growing library of graph algorithms.</p>
<p>A graph in Spark is also represented as a dataframe of edges and vertices; however, the format is slightly different since we will need to construct a dataframe for vertices. Lets first install the <a href="https://graphframes.github.io/">GraphFrames</a> extension,</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb347-1" title="1"><span class="kw">install.packages</span>(<span class="st">&quot;graphframes&quot;</span>)</a></code></pre></div>
<p>Followed by connecting, copying the <code>highschool</code> dataset and transforming the graph to the format that this extension expects, we will scope this dataset to the friendships of year 1957.</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb348-1" title="1"><span class="kw">library</span>(graphframes)</a>
<a class="sourceLine" id="cb348-2" title="2"><span class="kw">library</span>(sparklyr)</a>
<a class="sourceLine" id="cb348-3" title="3"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb348-4" title="4"></a>
<a class="sourceLine" id="cb348-5" title="5">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3&quot;</span>)</a>
<a class="sourceLine" id="cb348-6" title="6">highschool_tbl &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, ggraph<span class="op">::</span>highschool, <span class="st">&quot;highschool&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb348-7" title="7"><span class="st">  </span><span class="kw">filter</span>(year <span class="op">==</span><span class="st"> </span><span class="dv">1957</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb348-8" title="8"><span class="st">  </span><span class="kw">transmute</span>(<span class="dt">from =</span> <span class="kw">as.character</span>(<span class="kw">as.integer</span>(from)),</a>
<a class="sourceLine" id="cb348-9" title="9">            <span class="dt">to =</span> <span class="kw">as.character</span>(<span class="kw">as.integer</span>(to)))</a>
<a class="sourceLine" id="cb348-10" title="10"></a>
<a class="sourceLine" id="cb348-11" title="11">from_tbl &lt;-<span class="st"> </span>highschool_tbl <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">distinct</span>(from) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">transmute</span>(<span class="dt">id =</span> from)</a>
<a class="sourceLine" id="cb348-12" title="12">to_tbl &lt;-<span class="st"> </span>highschool_tbl <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">distinct</span>(to) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">transmute</span>(<span class="dt">id =</span> to)</a>
<a class="sourceLine" id="cb348-13" title="13"></a>
<a class="sourceLine" id="cb348-14" title="14">vertices_tbl &lt;-<span class="st"> </span><span class="kw">distinct</span>(<span class="kw">sdf_bind_rows</span>(from_tbl, to_tbl))</a>
<a class="sourceLine" id="cb348-15" title="15">edges_tbl &lt;-<span class="st"> </span>highschool_tbl <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">transmute</span>(<span class="dt">src =</span> from, <span class="dt">dst =</span> to)</a></code></pre></div>
<p>The <code>vertices_tbl</code> table is expected to have a single <code>id</code> column:</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb349-1" title="1">vertices_tbl</a></code></pre></div>
<pre><code># Source: spark&lt;?&gt; [?? x 1]
   id   
   &lt;chr&gt;
 1 1    
 2 34   
 3 37   
 4 43   
 5 44   
 6 45   
 7 56   
 8 57   
 9 65   
10 71   
# … with more rows</code></pre>
<p>While the <code>edges_tbl</code> is expected to have a <code>src</code> and <code>dst</code> columns:</p>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb351-1" title="1">edges_tbl</a></code></pre></div>
<pre><code># Source: spark&lt;?&gt; [?? x 2]
   src   dst  
   &lt;chr&gt; &lt;chr&gt;
 1 1     14   
 2 1     15   
 3 1     21   
 4 1     54   
 5 1     55   
 6 2     21   
 7 2     22   
 8 3     9    
 9 3     15   
10 4     5    
# … with more rows</code></pre>
<p>You can now create a GraphFrame,</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb353-1" title="1">graph &lt;-<span class="st"> </span><span class="kw">gf_graphframe</span>(vertices_tbl, edges_tbl)</a></code></pre></div>
<p>We can now use this graph to start analyzing this dataset. For instance, by finding out how many friends on average every one has, this is referred as the degree or valency of a vertex:</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb354-1" title="1"><span class="kw">gf_degrees</span>(graph) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">friends =</span> <span class="kw">mean</span>(degree))</a></code></pre></div>
<pre><code># Source: spark&lt;?&gt; [?? x 1]
  friends
    &lt;dbl&gt;
1    6.94</code></pre>
<p>We can then find what the shortest path to some specific vertex (person for this dataset). Since the data is anonymized, we can just pick the person identified as <code>33</code> and find how many degrees of separation exist between them:</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb356-1" title="1"><span class="kw">gf_shortest_paths</span>(graph, <span class="dv">33</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb356-2" title="2"><span class="st">  </span><span class="kw">filter</span>(<span class="kw">size</span>(distances) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb356-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">distance =</span> <span class="kw">explode</span>(<span class="kw">map_values</span>(distances))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb356-4" title="4"><span class="st">  </span><span class="kw">select</span>(id, distance)</a></code></pre></div>
<pre><code># Source: spark&lt;?&gt; [?? x 2]
   id    distance
   &lt;chr&gt;    &lt;int&gt;
 1 19           5
 2 5            4
 3 27           6
 4 4            4
 5 11           6
 6 23           4
 7 36           1
 8 26           2
 9 33           0
10 18           5
# … with more rows</code></pre>
<p>Finally, we can also compute PageRank over this graph, which was presented in the Introduction chapter as Google’s web page ranking algorithm:</p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb358-1" title="1"><span class="kw">gf_graphframe</span>(vertices_tbl, edges_tbl) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb358-2" title="2"><span class="st">  </span><span class="kw">gf_pagerank</span>(<span class="dt">reset_prob =</span> <span class="fl">0.15</span>, <span class="dt">max_iter =</span> 10L)</a></code></pre></div>
<pre><code>GraphFrame
Vertices:
  Database: spark_connection
  $ id       &lt;dbl&gt; 12, 12, 14, 14, 27, 27, 55, 55, 64, 64, 41, 41, 47, 47, 6…
  $ pagerank &lt;dbl&gt; 0.3573460, 0.3573460, 0.3893665, 0.3893665, 0.2362396, 0.…
Edges:
  Database: spark_connection
  $ src    &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 12, 12, 12,…
  $ dst    &lt;dbl&gt; 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,…
  $ weight &lt;dbl&gt; 0.25000000, 0.25000000, 0.25000000, 0.25000000, 0.25000000,…</code></pre>
<p>To give you some insights into this dataset, Figure <a href="extensions.html#fig:extensions-graph-pagerank">10.4</a> plots this chart using the <code>ggraph</code> and highlights the highest PageRank scores for this dataset,</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb360-1" title="1">highschool_tbl <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb360-2" title="2"><span class="st">  </span>igraph<span class="op">::</span><span class="kw">graph_from_data_frame</span>(<span class="dt">directed =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb360-3" title="3"><span class="st">  </span><span class="kw">ggraph</span>(<span class="dt">layout =</span> <span class="st">&#39;kk&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb360-4" title="4"><span class="st">    </span><span class="kw">geom_edge_link</span>(<span class="dt">alpha =</span> <span class="fl">0.2</span>,</a>
<a class="sourceLine" id="cb360-5" title="5">                   <span class="dt">arrow =</span> <span class="kw">arrow</span>(<span class="dt">length =</span> <span class="kw">unit</span>(<span class="dv">2</span>, <span class="st">&#39;mm&#39;</span>)),</a>
<a class="sourceLine" id="cb360-6" title="6">                   <span class="dt">end_cap =</span> <span class="kw">circle</span>(<span class="dv">2</span>, <span class="st">&#39;mm&#39;</span>),</a>
<a class="sourceLine" id="cb360-7" title="7">                   <span class="dt">start_cap =</span> <span class="kw">circle</span>(<span class="dv">2</span>, <span class="st">&#39;mm&#39;</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb360-8" title="8"><span class="st">    </span><span class="kw">geom_node_point</span>(<span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">alpha =</span> <span class="fl">0.4</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:extensions-graph-pagerank"></span>
<img src="images/extensions-graph-pagerank-resized.png" alt="Highschool ggraph dataset with highest pagerank highlighted" width="1500" />
<p class="caption">
FIGURE 10.4: Highschool ggraph dataset with highest pagerank highlighted
</p>
</div>
<p>There are many more graph algorithms provided in <code>graphframes</code>, to mention some: breadth-first search, connected components, label propagation for detecting communities, strongly connected components and triangle count. For questions on this extension refer to the official GitHub repo, <a href="https://github.com/rstudio/graphframes">github.com/rstudio/graphframes</a>. We will now present a popular gradient boosting framework, make sure to disconnect, restart before trying the next extension.</p>
</div>
<div id="xgboost" class="section level2">
<h2><span class="header-section-number">10.4</span> XGBoost</h2>
<p>A decision tree is a flowchart-like structure in which each internal node represents a test on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label. For example, the diagram in Figure <a href="extensions.html#fig:extensions-decision-diagram">10.5</a> shows an a decision tree that could help classify if an employee is likely to leave given a set of factors, like job satisfaction and overtime. When a decision tree is used to predict continuous variables instead of discrete outcomes, say, how likely someone is to leave a company, decision trees are referred to as regression trees.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-decision-diagram"></span>
<img src="the-r-in-spark_files/figure-html/extensions-decision-diagram-1.png" alt="A Decision tree to predict job attrition based on known factors" width="768" />
<p class="caption">
FIGURE 10.5: A Decision tree to predict job attrition based on known factors
</p>
</div>
<p>While a decision tree representation is quite easy to understand and to interpret, finding out the decisions in the tree requires mathematical techniques like gradient descent to find a local minimum. Gradient descent takes steps proportional to the negative of the gradient of the function at the current point. The gradient is represented by <span class="math inline">\(\nabla\)</span>, the learning rate by <span class="math inline">\(\gamma\)</span> and one simply starts from a given state <span class="math inline">\(a_n\)</span> and compute the next iteration <span class="math inline">\(a_{n+1}\)</span> by simply following the direction of the gradient:</p>
<p><span class="math inline">\(a_{n+1} = a_n - \gamma \nabla F(a_n)\)</span></p>
<p>XGBoost is an open-source software library which provides a gradient boosting framework. It aims to provide a scalable, portable and distributed gradient boosting for training gradient-boosted decision trees (GBDT) and gradient-boosted regression trees (GBDT). Gradient-boosted means xgboost uses gradient descent and boosting, which is a technique that chooses each predictor sequentially.</p>
<p><code>sparkxgb</code> is an extension that you can use to train XGBoost models in Spark; however, please beware that currently Windows is unsupported. To use this extension, first install it from CRAN:</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb361-1" title="1"><span class="kw">install.packages</span>(<span class="st">&quot;sparkxgb&quot;</span>)</a></code></pre></div>
<p>Then you would need to import the <code>sparkxgb</code> extension followed by your usual Spark connection code, adjusting <code>master</code> as needed:</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb362-1" title="1"><span class="kw">library</span>(sparkxgb)</a>
<a class="sourceLine" id="cb362-2" title="2"><span class="kw">library</span>(sparklyr)</a>
<a class="sourceLine" id="cb362-3" title="3"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb362-4" title="4"></a>
<a class="sourceLine" id="cb362-5" title="5">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3&quot;</span>)</a></code></pre></div>
<p>For this example, we will use the <code>attrition</code> dataset from the <code>rsample</code> package which you would need to install with <code>install.packages("rsample")</code>. This dataset is a fictional dataset created by IBM data scientists to uncover the factors that lead to employee attrition.</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb363-1" title="1">attrition &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, rsample<span class="op">::</span>attrition)</a>
<a class="sourceLine" id="cb363-2" title="2">attrition</a></code></pre></div>
<pre><code># Source: spark&lt;?&gt; [?? x 31]
     Age Attrition BusinessTravel DailyRate Department DistanceFromHome
   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;              &lt;int&gt; &lt;chr&gt;                 &lt;int&gt;
 1    41 Yes       Travel_Rarely       1102 Sales                     1
 2    49 No        Travel_Freque…       279 Research_…                8
 3    37 Yes       Travel_Rarely       1373 Research_…                2
 4    33 No        Travel_Freque…      1392 Research_…                3
 5    27 No        Travel_Rarely        591 Research_…                2
 6    32 No        Travel_Freque…      1005 Research_…                2
 7    59 No        Travel_Rarely       1324 Research_…                3
 8    30 No        Travel_Rarely       1358 Research_…               24
 9    38 No        Travel_Freque…       216 Research_…               23
10    36 No        Travel_Rarely       1299 Research_…               27
# … with more rows, and 25 more variables: Education &lt;chr&gt;,
#   EducationField &lt;chr&gt;, EnvironmentSatisfaction &lt;chr&gt;, Gender &lt;chr&gt;,
#   HourlyRate &lt;int&gt;, JobInvolvement &lt;chr&gt;, JobLevel &lt;int&gt;, JobRole &lt;chr&gt;,
#   JobSatisfaction &lt;chr&gt;, MaritalStatus &lt;chr&gt;, MonthlyIncome &lt;int&gt;,
#   MonthlyRate &lt;int&gt;, NumCompaniesWorked &lt;int&gt;, OverTime &lt;chr&gt;,
#   PercentSalaryHike &lt;int&gt;, PerformanceRating &lt;chr&gt;,
#   RelationshipSatisfaction &lt;chr&gt;, StockOptionLevel &lt;int&gt;,
#   TotalWorkingYears &lt;int&gt;, TrainingTimesLastYear &lt;int&gt;,
#   WorkLifeBalance &lt;chr&gt;, YearsAtCompany &lt;int&gt;, YearsInCurrentRole &lt;int&gt;,
#   YearsSinceLastPromotion &lt;int&gt;, YearsWithCurrManager &lt;int&gt;</code></pre>
<p>To build an XGBoost model in Spark use <code>xgboost_classifier()</code>, we will compute attrition against all other features by using the <code>Attrition ~ .</code> formula and specify two for the number of classes since the attrition attribute tracks only whether an employee leaves or not. Then you can use <code>ml_predict()</code> to predict over large-scale datasets:</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb365-1" title="1">xgb_model &lt;-<span class="st"> </span><span class="kw">xgboost_classifier</span>(attrition,</a>
<a class="sourceLine" id="cb365-2" title="2">                                Attrition <span class="op">~</span><span class="st"> </span>.,</a>
<a class="sourceLine" id="cb365-3" title="3">                                <span class="dt">num_class =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb365-4" title="4">                                <span class="dt">num_round =</span> <span class="dv">50</span>,</a>
<a class="sourceLine" id="cb365-5" title="5">                                <span class="dt">max_depth =</span> <span class="dv">4</span>)</a>
<a class="sourceLine" id="cb365-6" title="6"></a>
<a class="sourceLine" id="cb365-7" title="7">xgb_model <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb365-8" title="8"><span class="st">  </span><span class="kw">ml_predict</span>(attrition) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb365-9" title="9"><span class="st">  </span><span class="kw">select</span>(Attrition, predicted_label, <span class="kw">starts_with</span>(<span class="st">&quot;probability_&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb365-10" title="10"><span class="st">  </span><span class="kw">glimpse</span>()</a></code></pre></div>
<pre><code>Observations: ??
Variables: 4
Database: spark_connection
$ Attrition       &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, …
$ predicted_label &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Y…
$ probability_No  &lt;dbl&gt; 0.753938094, 0.024780750, 0.915146366, 0.143568754, 0.07…
$ probability_Yes &lt;dbl&gt; 0.24606191, 0.97521925, 0.08485363, 0.85643125, 0.927375…</code></pre>
<p>XGBoost became well known in the competition circles after its use in the winning solution of the Higgs Machine Learning Challenge which uses the ATLAS experiment to identify the Higgs boson. Since then, it has become a popular model and used for a large number of Kaggle competitions. However, decision trees could prove limiting especially in datasets with non tabular data like images, audio and text which you can tackle with deep learning models, should we remind you to disconnect and restart?</p>
</div>
<div id="deep-learning" class="section level2">
<h2><span class="header-section-number">10.5</span> Deep Learning</h2>
<p>A perceptron is a mathematical model introduced by Rosenblatt <span class="citation">(Rosenblatt <a href="#ref-extensions-rosenblatt-perceptron">1958</a>)</span> who developed it as a theory for a hypothetical nervous system. The perceptron maps stimuli to numeric inputs that are weighted into a threshold function that activates only when enough stimuli is present, mathematically:</p>
<p><span class="math inline">\(f(x) = \begin{cases} 1 &amp; \sum_{i=1}^m w_i x_i + b &gt; 0\\ 0 &amp; \text{otherwise} \end{cases}\)</span></p>
<p>Minsky found out that a single perceptron can only classify datasets that are linearly separable; however, he also presented in his perceptrons book <span class="citation">(Minsky and Papert <a href="#ref-extensions-minsky-perceptrons">2017</a>)</span> that layering perceptrons would bring additional classification capabilities, the original diagram showcasing a multi-layered perceptron is presented in Figure <a href="extensions.html#fig:extensions-minsky-layered">10.6</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-minsky-layered"></span>
<img src="images/extensions-minsky-multi-layers.png" alt="Layered perceptrons as illustrated in the perceptrons book" width="1821" />
<p class="caption">
FIGURE 10.6: Layered perceptrons as illustrated in the perceptrons book
</p>
</div>
<p>Before we start, let’s first install all the packages we are about to use,</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb367-1" title="1"><span class="kw">install.packages</span>(<span class="st">&quot;sparktf&quot;</span>)</a>
<a class="sourceLine" id="cb367-2" title="2"><span class="kw">install.packages</span>(<span class="st">&quot;tfdatasets&quot;</span>)</a></code></pre></div>
<p>Using Spark we can create a multi-layer perceptron classifier with <code>ml_multilayer_perceptron_classifier()</code> and gradient descent to classify and predict over large datasets. Gradient descent was introduced to layered perceptrons by Geoff Hinton <span class="citation">(Ackley, Hinton, and Sejnowski <a href="#ref-extensions-hinton-layered">1985</a>)</span> and like XGBoost, it also makes use of gradient descent.</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb368-1" title="1"><span class="kw">library</span>(sparktf)</a>
<a class="sourceLine" id="cb368-2" title="2"><span class="kw">library</span>(sparklyr)</a>
<a class="sourceLine" id="cb368-3" title="3"></a>
<a class="sourceLine" id="cb368-4" title="4">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3&quot;</span>)</a>
<a class="sourceLine" id="cb368-5" title="5"></a>
<a class="sourceLine" id="cb368-6" title="6">attrition &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, rsample<span class="op">::</span>attrition)</a>
<a class="sourceLine" id="cb368-7" title="7"></a>
<a class="sourceLine" id="cb368-8" title="8">nn_model &lt;-<span class="st"> </span><span class="kw">ml_multilayer_perceptron_classifier</span>(</a>
<a class="sourceLine" id="cb368-9" title="9">  attrition,</a>
<a class="sourceLine" id="cb368-10" title="10">  Attrition <span class="op">~</span><span class="st"> </span>Age <span class="op">+</span><span class="st"> </span>DailyRate <span class="op">+</span><span class="st"> </span>DistanceFromHome <span class="op">+</span><span class="st"> </span>MonthlyIncome,</a>
<a class="sourceLine" id="cb368-11" title="11">  <span class="dt">layers =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb368-12" title="12">  <span class="dt">solver =</span> <span class="st">&quot;gd&quot;</span>)</a>
<a class="sourceLine" id="cb368-13" title="13"></a>
<a class="sourceLine" id="cb368-14" title="14">nn_model <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb368-15" title="15"><span class="st">  </span><span class="kw">ml_predict</span>(attrition) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb368-16" title="16"><span class="st">  </span><span class="kw">select</span>(Attrition, predicted_label, <span class="kw">starts_with</span>(<span class="st">&quot;probability_&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb368-17" title="17"><span class="st">  </span><span class="kw">glimpse</span>()</a></code></pre></div>
<pre><code>Observations: ??
Variables: 4
Database: spark_connection
$ Attrition       &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;…
$ predicted_label &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, …
$ probability_No  &lt;dbl&gt; 0.8439275, 0.8439275, 0.8439275, 0.8439275, 0.8439275,…
$ probability_Yes &lt;dbl&gt; 0.1560725, 0.1560725, 0.1560725, 0.1560725, 0.1560725,…</code></pre>
<p>Notice that the columns must be numeric so you will have to manually convert them with feature transforming techniques presented in the Modeling chapter. It is natural to try to add more layers to classify more complex datasets; however, adding too many layers will cause the gradient to vanish and other techniques will have to use these deep layered networks also known as, deep learning models.</p>
<p>Deep learning models solve the vanishing gradient problem by making use of special activation functions, dropout, data augmentation and graphic processing units (GPUs). You can use Spark to retrieve and preprocess large datasets into numerical-only datasets that can fit in a GPU for deep learning training. Tensorflow is one of the most popular deep learning frameworks and supports a binary format known as TensorFlow Records.</p>
<p>You can write TensorFlow records using the <code>sparktf</code> in Spark which you can prepare to process in GPU instances with libraries like Keras or TensorFlow.</p>
<p>You can then preprocess large datasets in Spark and write it as TensorFlow records using <code>spark_write_tf()</code>:</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb370-1" title="1"><span class="kw">copy_to</span>(sc, iris) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb370-2" title="2"><span class="st">  </span><span class="kw">ft_string_indexer_model</span>(</a>
<a class="sourceLine" id="cb370-3" title="3">    <span class="st">&quot;Species&quot;</span>, <span class="st">&quot;label&quot;</span>,</a>
<a class="sourceLine" id="cb370-4" title="4">    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;setosa&quot;</span>, <span class="st">&quot;versicolor&quot;</span>, <span class="st">&quot;virginica&quot;</span>)</a>
<a class="sourceLine" id="cb370-5" title="5">  ) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb370-6" title="6"><span class="st">  </span><span class="kw">spark_write_tfrecord</span>(<span class="dt">path =</span> <span class="st">&quot;tfrecord&quot;</span>)</a></code></pre></div>
<p>Once trained, you can use the <code>tfdatasets</code> package to load the dataset followed by training with <code>keras</code> or <code>tensorflow</code>. You will also need to install the TensorFlow runtime with <code>install_tensorflow()</code> and install Python on your own. To learn more about training deep learning models with Keras we recommend reading “Deep Learning with R”. <span class="citation">(Chollet and Allaire <a href="#ref-extensions-chollet-jj">2018</a>)</span></p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb371-1" title="1">tensorflow<span class="op">::</span><span class="kw">install_tensorflow</span>()</a>
<a class="sourceLine" id="cb371-2" title="2">tfdatasets<span class="op">::</span><span class="kw">tfrecord_dataset</span>(<span class="st">&quot;tfrecord/part-r-00000&quot;</span>)</a></code></pre></div>
<pre><code>&lt;DatasetV1Adapter shapes: (), types: tf.string&gt;</code></pre>
<p>Training deep learning models in a single local node with one or more GPUs is often enough for most applications; however, recent state-of-the-art deep learning models train using distributed computing frameworks like Apache Spark. Distributed computing frameworks are used to achieve higher petaflops each day the systems spends training these models. OpenAI analyzed trends in the field of <em>Artificial Intelligence</em> and cluster computing <span class="citation">(“AI and Compute” <a href="#ref-extensions-openai-compute">2019</a>)</span> and illustrated in Figure <a href="extensions.html#fig:extensions-distributed-training">10.7</a>. It should be obvious from the figure that there is a trend in recent years to use distributed computing frameworks.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-distributed-training"></span>
<img src="images/extensions-distributed-training-resized.png" alt="Training using distributed systems based on OpenAI analysis" width="1500" />
<p class="caption">
FIGURE 10.7: Training using distributed systems based on OpenAI analysis
</p>
</div>
<p>Training large-scale deep learning models is possible in Spark and TensorFlow through frameworks like Horovod. Today, it’s possible to use Horovod with Spark from R using the <code>reticulate</code> package since Horovod requires Python and Open MPI which goes beyond the scope of this book. Instead, we will introduce a different Spark extension in the domain of genomics.</p>
</div>
<div id="genomics" class="section level2">
<h2><span class="header-section-number">10.6</span> Genomics</h2>
<p>The human genome consists of two copies of about three billion base pairs of DNA within the 23 chromosome pairs, Figure <a href="extensions.html#fig:extensions-genomics-diagram">10.8</a> shows the organization of the genome into chromosomes. DNA strands are composed of nucleotides, each composed of one of four nitrogen-containing nucleobases: cytosine (C), guanine (G), adenine (A) or thymine (T). <span class="citation">(“Human Genome” <a href="#ref-extensions-genomics-wikipedia">2019</a>)</span> Since the DNA of all humans is nearly identical, we only need to store the differences from the reference genome in the form of a Variant Call Format (VCF) file.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-genomics-diagram"></span>
<img src="images/extensions-genomics-diagram-resized.png" alt="The idealized human diploid karyotype showing the organization of the genome into chromosomes" width="1500" />
<p class="caption">
FIGURE 10.8: The idealized human diploid karyotype showing the organization of the genome into chromosomes
</p>
</div>
<p>VariantSpark is a framework based on scala and spark to analyze genome datasets. It is being developed by CSIRO Bioinformatics team in Australia. VariantSpark was tested on datasets with 3000 samples each one containing 80 million features in either unsupervised clustering approaches and supervised applications, like classification and regression. VariantSpark can read VCF files and run analyses while using familiar Spark DataFrames.</p>
<p>To get started, install <code>variantspark</code> from CRAN, connect to Spark and retrieve a <code>vsc</code> connection to VariantSpark:</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb373-1" title="1"><span class="kw">library</span>(variantspark)</a>
<a class="sourceLine" id="cb373-2" title="2"><span class="kw">library</span>(sparklyr)</a>
<a class="sourceLine" id="cb373-3" title="3"></a>
<a class="sourceLine" id="cb373-4" title="4">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3&quot;</span>,</a>
<a class="sourceLine" id="cb373-5" title="5">                    <span class="dt">config =</span> <span class="kw">list</span>(<span class="dt">sparklyr.connect.timeout =</span> <span class="dv">3</span> <span class="op">*</span><span class="st"> </span><span class="dv">60</span>))</a>
<a class="sourceLine" id="cb373-6" title="6"></a>
<a class="sourceLine" id="cb373-7" title="7">vsc &lt;-<span class="st"> </span><span class="kw">vs_connect</span>(sc)</a></code></pre></div>
<p>We can start by loading a VCF file,</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb374-1" title="1">vsc_data &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata/&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;variantspark&quot;</span>)</a>
<a class="sourceLine" id="cb374-2" title="2"></a>
<a class="sourceLine" id="cb374-3" title="3">hipster_vcf &lt;-<span class="st"> </span><span class="kw">vs_read_vcf</span>(vsc, <span class="kw">file.path</span>(vsc_data, <span class="st">&quot;hipster.vcf.bz2&quot;</span>))</a>
<a class="sourceLine" id="cb374-4" title="4">hipster_labels &lt;-<span class="st"> </span><span class="kw">vs_read_csv</span>(vsc, <span class="kw">file.path</span>(vsc_data, <span class="st">&quot;hipster_labels.txt&quot;</span>))</a>
<a class="sourceLine" id="cb374-5" title="5">labels &lt;-<span class="st"> </span><span class="kw">vs_read_labels</span>(vsc, <span class="kw">file.path</span>(vsc_data, <span class="st">&quot;hipster_labels.txt&quot;</span>))</a></code></pre></div>
<p>VariantSpark uses Random Forest to assign an Importance score to each tested variant reflecting its association to the interest phenotype. A variant with higher Importance score implies it is more strongly associated with the phenotype of interest. You can compute the Importance and transform it into a Spark table as follows,</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb375-1" title="1">importance_tbl &lt;-<span class="st"> </span><span class="kw">vs_importance_analysis</span>(vsc, hipster_vcf, </a>
<a class="sourceLine" id="cb375-2" title="2">                                         labels, <span class="dt">n_trees =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb375-3" title="3"><span class="st">  </span><span class="kw">importance_tbl</span>()</a>
<a class="sourceLine" id="cb375-4" title="4"></a>
<a class="sourceLine" id="cb375-5" title="5">importance_tbl</a></code></pre></div>
<pre><code># Source: spark&lt;?&gt; [?? x 2]
   variable    importance
   &lt;chr&gt;            &lt;dbl&gt;
 1 2_109511398 0         
 2 2_109511454 0         
 3 2_109511463 0.00000164
 4 2_109511467 0.00000309
 5 2_109511478 0         
 6 2_109511497 0         
 7 2_109511525 0         
 8 2_109511527 0         
 9 2_109511532 0         
10 2_109511579 0         
# … with more rows</code></pre>
<p>You can then use <code>dplyr</code> and <code>ggplot2</code> to transform the output and visualize it,</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb377-1" title="1"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb377-2" title="2"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb377-3" title="3"></a>
<a class="sourceLine" id="cb377-4" title="4">importance_df &lt;-<span class="st"> </span>importance_tbl <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb377-5" title="5"><span class="st">  </span><span class="kw">arrange</span>(<span class="op">-</span>importance) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb377-6" title="6"><span class="st">  </span><span class="kw">head</span>(<span class="dv">20</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb377-7" title="7"><span class="st">  </span><span class="kw">collect</span>()</a>
<a class="sourceLine" id="cb377-8" title="8"></a>
<a class="sourceLine" id="cb377-9" title="9"><span class="kw">ggplot</span>(importance_df) <span class="op">+</span></a>
<a class="sourceLine" id="cb377-10" title="10"><span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> variable, <span class="dt">y =</span> importance) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb377-11" title="11"><span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&#39;identity&#39;</span>) <span class="op">+</span><span class="st">          </span></a>
<a class="sourceLine" id="cb377-12" title="12"><span class="st">  </span><span class="kw">scale_x_discrete</span>(<span class="dt">limits =</span> </a>
<a class="sourceLine" id="cb377-13" title="13">    importance_df[<span class="kw">order</span>(importance_df<span class="op">$</span>importance), <span class="dv">1</span>]<span class="op">$</span>variable) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb377-14" title="14"><span class="st">  </span><span class="kw">coord_flip</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:extensions-genomics-importance"></span>
<img src="images/extensions-genomics-importance-resized.png" alt="Genomic importance analysis using variantspark" width="1500" />
<p class="caption">
FIGURE 10.9: Genomic importance analysis using variantspark
</p>
</div>
<p>This concludes a brief introduction to genomic analysis in Spark using the variantspark extensions. Next, we will move away from microscopic genes, to macroscopic datasets that contain geographic locations across the world.</p>
</div>
<div id="spatial" class="section level2">
<h2><span class="header-section-number">10.7</span> Spatial</h2>
<p><a href="https://github.com/harryprince/geospark">geospark</a> enables distributed geospatial computing using a grammar compatible with <a href="https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf"><code>dplyr</code></a> and <a href="https://github.com/rstudio/cheatsheets/raw/master/sf.pdf"><code>sf</code></a> package which provides a set of tools for working with geospatial vectors.</p>
<p>You can install <code>geospark</code> from GitHub as follows:</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb378-1" title="1"><span class="kw">install.packages</span>(<span class="st">&quot;remotes&quot;</span>)</a>
<a class="sourceLine" id="cb378-2" title="2">remotes<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;r-spark/geospark&quot;</span>)</a></code></pre></div>
<p>Then we will initialize the geospark extension and connect to Spark:</p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb379-1" title="1"><span class="kw">library</span>(geospark)</a>
<a class="sourceLine" id="cb379-2" title="2"><span class="kw">library</span>(sparklyr)</a>
<a class="sourceLine" id="cb379-3" title="3"></a>
<a class="sourceLine" id="cb379-4" title="4">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3&quot;</span>)</a></code></pre></div>
<p>Next we will load a spatial dataset containing polygons and points.</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb380-1" title="1">polygons &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;examples/polygons.txt&quot;</span>, <span class="dt">package=</span><span class="st">&quot;geospark&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb380-2" title="2"><span class="st">  </span><span class="kw">read.table</span>(<span class="dt">sep=</span><span class="st">&quot;|&quot;</span>, <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;area&quot;</span>, <span class="st">&quot;geom&quot;</span>))</a>
<a class="sourceLine" id="cb380-3" title="3"></a>
<a class="sourceLine" id="cb380-4" title="4">points &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;examples/points.txt&quot;</span>, <span class="dt">package=</span><span class="st">&quot;geospark&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb380-5" title="5"><span class="st">  </span><span class="kw">read.table</span>(<span class="dt">sep =</span> <span class="st">&quot;|&quot;</span>, <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;city&quot;</span>, <span class="st">&quot;state&quot;</span>, <span class="st">&quot;geom&quot;</span>))</a>
<a class="sourceLine" id="cb380-6" title="6"></a>
<a class="sourceLine" id="cb380-7" title="7">polygons_wkt &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, polygons)</a>
<a class="sourceLine" id="cb380-8" title="8">points_wkt &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, points)</a></code></pre></div>
<p>There are various spatial operations defined in <code>geospark</code>, which Figure <a href="extensions.html#fig:extensions-geospark-operations">10.10</a> describes. These operations allow you to control how geospatial data should be queried based on overlap, intersection, disjoint sets, etc.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-geospark-operations"></span>
<img src="images/extensions-geospark-operations.png" alt="Spatial operations available in geospark." width="1234" />
<p class="caption">
FIGURE 10.10: Spatial operations available in geospark.
</p>
</div>
<p>For instance, we can use these operations to find the polygons that contain a given set of points using <code>st_contains()</code>,</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb381-1" title="1"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb381-2" title="2">polygons_wkt &lt;-<span class="st"> </span><span class="kw">mutate</span>(polygons_wkt, <span class="dt">y =</span> <span class="kw">st_geomfromwkt</span>(geom))</a>
<a class="sourceLine" id="cb381-3" title="3">points_wkt &lt;-<span class="st"> </span><span class="kw">mutate</span>(points_wkt, <span class="dt">x =</span> <span class="kw">st_geomfromwkt</span>(geom))</a>
<a class="sourceLine" id="cb381-4" title="4"></a>
<a class="sourceLine" id="cb381-5" title="5"><span class="kw">inner_join</span>(polygons_wkt,</a>
<a class="sourceLine" id="cb381-6" title="6">           points_wkt,</a>
<a class="sourceLine" id="cb381-7" title="7">           <span class="dt">sql_on =</span> <span class="kw">sql</span>(<span class="st">&quot;st_contains(y,x)&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb381-8" title="8"><span class="st">  </span><span class="kw">group_by</span>(area, state) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb381-9" title="9"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">cnt =</span> <span class="kw">n</span>()) </a></code></pre></div>
<pre><code># Source: spark&lt;?&gt; [?? x 3]
# Groups: area
  area            state   cnt
  &lt;chr&gt;           &lt;chr&gt; &lt;dbl&gt;
1 california area CA       10
2 new york area   NY        9
3 dakota area     ND       10
4 texas area      TX       10
5 dakota area     SD        1</code></pre>
<p>You can also plot these datasets by collecting a subset of the entire dataset or aggregating the geometries in spark before collecting them, one package you should look into is the <code>sf</code> package. We will now start closing this chapter by presenting a couple troubleshooting techniques applicable to all extensions.</p>
</div>
<div id="troubleshooting" class="section level2">
<h2><span class="header-section-number">10.8</span> Troubleshooting</h2>
<p>When using a new extension for the first time, we recommend increasing the connection timeout since Spark will usually have to download extension dependencies and changing logging to verbose to help troubleshoot when the download process does not complete:</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb383-1" title="1">config &lt;-<span class="st"> </span><span class="kw">spark_config</span>()</a>
<a class="sourceLine" id="cb383-2" title="2">config<span class="op">$</span>sparklyr.connect.timeout &lt;-<span class="st"> </span><span class="dv">3</span> <span class="op">*</span><span class="st"> </span><span class="dv">60</span></a>
<a class="sourceLine" id="cb383-3" title="3">config<span class="op">$</span>sparklyr.log.console =<span class="st"> </span><span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb383-4" title="4"></a>
<a class="sourceLine" id="cb383-5" title="5">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">config =</span> config)</a></code></pre></div>
<p>In addition, you should know that <a href="http://ant.apache.org/ivy/">Apache IVY</a> is a popular dependency manager focusing on flexibility, simplicity, and is used by Apache Spark while installing extensions. When the connection fails while using an extension, consider clearing your <a href="http://ant.apache.org/ivy/history/2.0.0/settings/caches.html">IVY Cache</a> by running:</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb384-1" title="1"><span class="kw">unlink</span>(<span class="st">&quot;~/.ivy2&quot;</span>, <span class="dt">recursive =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<p>In addition, you can also consider opening GitHub issues from the following extensions repos to get help from the extension authors:</p>
<ul>
<li><em>rsparkling</em>: <a href="https://github.com/h2oai/sparkling-water">github.com/h2oai/sparkling-water</a>.</li>
<li><em>sparkxgb</em>: <a href="https://github.com/rstudio/sparkxgb">github.com/rstudio/sparkxgb</a>.</li>
<li><em>sparktf</em>: <a href="https://github.com/rstudio/sparktf">github.com/rstudio/sparktf</a>.</li>
<li><em>variantspark</em>: <a href="https://github.com/r-spark/variantspark">github.com/r-spark/variantspark</a>.</li>
<li><em>geospark</em>: <a href="https://github.com/r-spark/geospark">github.com/r-spark/geospark</a>.</li>
</ul>
</div>
<div id="recap-7" class="section level2">
<h2><span class="header-section-number">10.9</span> Recap</h2>
<p>This chapter provided a brief overview on using some of the Spark extensions available in R, which happens to be as easy as installing a package. You then learned how to use the <code>rsparkling</code> extension which provides access to H2O in Spark to which provides additional modeling functionality like enhanced metrics and ability to automatically select models. We then jumped to <code>graphframes</code>, an extension to help you process relational datasets which are formally referred as graphs; you learned how to compute simple connection metrics or run complex algorithms like pagerank.</p>
<p>THe XGBoost and Deep Learning sections provided alternate modeling techniques that use gradient descent, the former over decision trees and the latter over deep multi-layered perceptrons where Spark can be used to preprocess datasets into records that can then be later consument by TensorFlow and Keras using the <code>sparktf</code> extension. The last two sections introduced extensions to process genomic and spatial datasets through the <code>variantspark</code> and <code>geospark</code> extensions.</p>
<p>These extensions and many more, provide a comprehensive library of advanced functionality that in combination with analysis and modeling techniques presented, should cover most tasks required to run in computing clusters. However, when functionality is lacking, you can consider writing your own extension as we will present in the Contributing chapter or you can apply custom transformations over each partition using R code as we will describe in the next chapter, Distributed R.</p>

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-extensions-hinton-layered">
<p>Ackley, David H, Geoffrey E Hinton, and Terrence J Sejnowski. 1985. “A Learning Algorithm for Boltzmann Machines.” <em>Cognitive Science</em>.</p>
</div>
<div id="ref-extensions-openai-compute">
<p>“AI and Compute.” 2019. <a href="https://openai.com/blog/ai-and-compute">https://openai.com/blog/ai-and-compute</a>.</p>
</div>
<div id="ref-extensions-h2o-automl">
<p>“AutoML: Automatic Machine Learning.” 2019. <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html">http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html</a>.</p>
</div>
<div id="ref-extensions-chollet-jj">
<p>Chollet, Francois, and J.J. Allaire. 2018. <em>Deep Learning with R</em>. Manning Publications.</p>
</div>
<div id="ref-extensions-practical-h2o">
<p>Cook, Darren. 2016. <em>Practical Machine Learning with H2o: Powerful, Scalable Techniques for Deep Learning and Ai</em>. O’Reilly Media, Inc.</p>
</div>
<div id="ref-extensions-sparklyr-cran">
<p>“CRAN - Package Sparklyr.” 2019. <a href="https://cran.r-project.org/web/packages/sparklyr/index.html">https://cran.r-project.org/web/packages/sparklyr/index.html</a>.</p>
</div>
<div id="ref-extensions-higgs-challenge">
<p>“Higgs Boson Machine Learning Challenge.” 2019. <a href="https://www.kaggle.com/c/higgs-boson">https://www.kaggle.com/c/higgs-boson</a>.</p>
</div>
<div id="ref-extensions-genomics-wikipedia">
<p>“Human Genome.” 2019. <a href="https://en.wikipedia.org/wiki/Human_genome">https://en.wikipedia.org/wiki/Human_genome</a>.</p>
</div>
<div id="ref-extensions-minsky-perceptrons">
<p>Minsky, Marvin, and Seymour A Papert. 2017. <em>Perceptrons: An Introduction to Computational Geometry</em>. MIT press.</p>
</div>
<div id="ref-extensions-rosenblatt-perceptron">
<p>Rosenblatt, Frank. 1958. “The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain.” <em>Psychological Review</em>.</p>
</div>
<div id="ref-extensions-h2o-rsparkling-docs">
<p>“RSparkling — H2o Sparkling Water 2.3.31 Documentation.” 2019. <a href="http://docs.h2o.ai/sparkling-water/2.3/latest-stable/doc/rsparkling.html">http://docs.h2o.ai/sparkling-water/2.3/latest-stable/doc/rsparkling.html</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="7">
<li id="fn7"><p>Notice that AutoML uses cross-validation which we did not use in GLM.<a href="extensions.html#fnref7" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tuning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="distributed.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
