<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 10 Extensions | Mastering Apache Spark with R</title>
  <meta name="description" content="The complete guide to large-scale analysis and modeling.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 10 Extensions | Mastering Apache Spark with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The complete guide to large-scale analysis and modeling." />
  <meta name="github-repo" content="javierluraschi/the-r-in-spark" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Extensions | Mastering Apache Spark with R" />
  
  <meta name="twitter:description" content="The complete guide to large-scale analysis and modeling." />
  

<meta name="author" content="Javier Luraschi, Kevin Kuo, Edgar Ruiz">


<meta name="date" content="2019-05-31">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="tuning.html">
<link rel="next" href="distributed.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/dagre-0.0.1/dagre.min.js"></script>
<script src="libs/lodash-3.7.0/lodash.js"></script>
<script src="libs/nomnoml-0.2.0/nomnoml.js"></script>
<script src="libs/nomnoml-binding-0.1.0/nomnoml.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119986300-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119986300-1');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Learning Apache Spark with R</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#intro-background"><i class="fa fa-check"></i><b>1.1</b> Information</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#intro-hadoop"><i class="fa fa-check"></i><b>1.2</b> Hadoop</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#intro-spark"><i class="fa fa-check"></i><b>1.3</b> Spark</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#intro-r"><i class="fa fa-check"></i><b>1.4</b> R</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#intro-sparklyr"><i class="fa fa-check"></i><b>1.5</b> sparklyr</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#intro-recap"><i class="fa fa-check"></i><b>1.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="starting.html"><a href="starting.html"><i class="fa fa-check"></i><b>2</b> Getting Started</a><ul>
<li class="chapter" data-level="2.1" data-path="starting.html"><a href="starting.html#starting-prerequisites"><i class="fa fa-check"></i><b>2.1</b> Prerequisites</a></li>
<li class="chapter" data-level="2.2" data-path="starting.html"><a href="starting.html#starting-install-sparklyr"><i class="fa fa-check"></i><b>2.2</b> Installing sparklyr</a></li>
<li class="chapter" data-level="2.3" data-path="starting.html"><a href="starting.html#starting-installing-spark"><i class="fa fa-check"></i><b>2.3</b> Installing Spark</a></li>
<li class="chapter" data-level="2.4" data-path="starting.html"><a href="starting.html#starting-connect-to-spark"><i class="fa fa-check"></i><b>2.4</b> Connecting to Spark</a></li>
<li class="chapter" data-level="2.5" data-path="starting.html"><a href="starting.html#starting-sparklyr-hello-world"><i class="fa fa-check"></i><b>2.5</b> Using Spark</a><ul>
<li class="chapter" data-level="2.5.1" data-path="starting.html"><a href="starting.html#starting-spark-web-interface"><i class="fa fa-check"></i><b>2.5.1</b> Web Interface</a></li>
<li class="chapter" data-level="2.5.2" data-path="starting.html"><a href="starting.html#starting-analysis"><i class="fa fa-check"></i><b>2.5.2</b> Analysis</a></li>
<li class="chapter" data-level="2.5.3" data-path="starting.html"><a href="starting.html#starting-modeling"><i class="fa fa-check"></i><b>2.5.3</b> Modeling</a></li>
<li class="chapter" data-level="2.5.4" data-path="starting.html"><a href="starting.html#starting-data"><i class="fa fa-check"></i><b>2.5.4</b> Data</a></li>
<li class="chapter" data-level="2.5.5" data-path="starting.html"><a href="starting.html#starting-extensions"><i class="fa fa-check"></i><b>2.5.5</b> Extensions</a></li>
<li class="chapter" data-level="2.5.6" data-path="starting.html"><a href="starting.html#starting-distributed-r"><i class="fa fa-check"></i><b>2.5.6</b> Distributed R</a></li>
<li class="chapter" data-level="2.5.7" data-path="starting.html"><a href="starting.html#starting-streaming"><i class="fa fa-check"></i><b>2.5.7</b> Streaming</a></li>
<li class="chapter" data-level="2.5.8" data-path="starting.html"><a href="starting.html#starting-logs"><i class="fa fa-check"></i><b>2.5.8</b> Logs</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="starting.html"><a href="starting.html#starting-disconnecting"><i class="fa fa-check"></i><b>2.6</b> Disconnecting</a></li>
<li class="chapter" data-level="2.7" data-path="starting.html"><a href="starting.html#starting-using-spark-from-rstudio"><i class="fa fa-check"></i><b>2.7</b> Using RStudio</a></li>
<li class="chapter" data-level="2.8" data-path="starting.html"><a href="starting.html#starting-resources"><i class="fa fa-check"></i><b>2.8</b> Resources</a></li>
<li class="chapter" data-level="2.9" data-path="starting.html"><a href="starting.html#starting-recap"><i class="fa fa-check"></i><b>2.9</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis.html"><a href="analysis.html"><i class="fa fa-check"></i><b>3</b> Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="analysis.html"><a href="analysis.html#r-as-an-interface-to-spark"><i class="fa fa-check"></i><b>3.1</b> R as an Interface to Spark</a><ul>
<li class="chapter" data-level="3.1.1" data-path="analysis.html"><a href="analysis.html#exercise"><i class="fa fa-check"></i><b>3.1.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="analysis.html"><a href="analysis.html#import-access"><i class="fa fa-check"></i><b>3.2</b> Import / Access</a></li>
<li class="chapter" data-level="3.3" data-path="analysis.html"><a href="analysis.html#wrangle"><i class="fa fa-check"></i><b>3.3</b> Wrangle</a><ul>
<li class="chapter" data-level="3.3.1" data-path="analysis.html"><a href="analysis.html#correlations"><i class="fa fa-check"></i><b>3.3.1</b> Correlations</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="analysis.html"><a href="analysis.html#visualize"><i class="fa fa-check"></i><b>3.4</b> Visualize</a><ul>
<li class="chapter" data-level="3.4.1" data-path="analysis.html"><a href="analysis.html#recommended-approach"><i class="fa fa-check"></i><b>3.4.1</b> Recommended approach</a></li>
<li class="chapter" data-level="3.4.2" data-path="analysis.html"><a href="analysis.html#simple-plots"><i class="fa fa-check"></i><b>3.4.2</b> Simple Plots</a></li>
<li class="chapter" data-level="3.4.3" data-path="analysis.html"><a href="analysis.html#histograms"><i class="fa fa-check"></i><b>3.4.3</b> Histograms</a></li>
<li class="chapter" data-level="3.4.4" data-path="analysis.html"><a href="analysis.html#scatter-vs-raster-plots"><i class="fa fa-check"></i><b>3.4.4</b> Scatter vs Raster Plots</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="analysis.html"><a href="analysis.html#model"><i class="fa fa-check"></i><b>3.5</b> Model</a><ul>
<li class="chapter" data-level="3.5.1" data-path="analysis.html"><a href="analysis.html#cache-model-data"><i class="fa fa-check"></i><b>3.5.1</b> Cache model data</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="analysis.html"><a href="analysis.html#communicate"><i class="fa fa-check"></i><b>3.6</b> Communicate</a><ul>
<li class="chapter" data-level="3.6.1" data-path="analysis.html"><a href="analysis.html#reports"><i class="fa fa-check"></i><b>3.6.1</b> Reports</a></li>
<li class="chapter" data-level="3.6.2" data-path="analysis.html"><a href="analysis.html#presentation-decks"><i class="fa fa-check"></i><b>3.6.2</b> Presentation decks</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="analysis.html"><a href="analysis.html#recap"><i class="fa fa-check"></i><b>3.7</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="modeling.html"><a href="modeling.html"><i class="fa fa-check"></i><b>4</b> Modeling</a><ul>
<li class="chapter" data-level="4.1" data-path="modeling.html"><a href="modeling.html#overview"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="modeling.html"><a href="modeling.html#the-data"><i class="fa fa-check"></i><b>4.2</b> The Data</a></li>
<li class="chapter" data-level="4.3" data-path="modeling.html"><a href="modeling.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>4.3</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="4.4" data-path="modeling.html"><a href="modeling.html#feature-engineering"><i class="fa fa-check"></i><b>4.4</b> Feature Engineering</a></li>
<li class="chapter" data-level="4.5" data-path="modeling.html"><a href="modeling.html#model-building"><i class="fa fa-check"></i><b>4.5</b> Model Building</a><ul>
<li class="chapter" data-level="4.5.1" data-path="modeling.html"><a href="modeling.html#logistic-regression-as-a-generalized-linear-regression"><i class="fa fa-check"></i><b>4.5.1</b> Logistic Regression as a Generalized Linear Regression</a></li>
<li class="chapter" data-level="4.5.2" data-path="modeling.html"><a href="modeling.html#more-machine-learning-algorithms"><i class="fa fa-check"></i><b>4.5.2</b> More Machine Learning Algorithms</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="modeling.html"><a href="modeling.html#working-with-textual-data"><i class="fa fa-check"></i><b>4.6</b> Working with Textual Data</a><ul>
<li class="chapter" data-level="4.6.1" data-path="modeling.html"><a href="modeling.html#data-prep"><i class="fa fa-check"></i><b>4.6.1</b> Data Prep</a></li>
<li class="chapter" data-level="4.6.2" data-path="modeling.html"><a href="modeling.html#topic-modeling"><i class="fa fa-check"></i><b>4.6.2</b> Topic Modeling</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="modeling.html"><a href="modeling.html#conclusion"><i class="fa fa-check"></i><b>4.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="pipelines.html"><a href="pipelines.html"><i class="fa fa-check"></i><b>5</b> Pipelines</a><ul>
<li class="chapter" data-level="5.1" data-path="pipelines.html"><a href="pipelines.html#estimators-and-transformers"><i class="fa fa-check"></i><b>5.1</b> Estimators and Transformers</a></li>
<li class="chapter" data-level="5.2" data-path="pipelines.html"><a href="pipelines.html#pipelines-and-pipeline-models"><i class="fa fa-check"></i><b>5.2</b> Pipelines and Pipeline Models</a></li>
<li class="chapter" data-level="5.3" data-path="pipelines.html"><a href="pipelines.html#applying-pipelines-to-okcupid-data"><i class="fa fa-check"></i><b>5.3</b> Applying Pipelines to OKCupid Data</a><ul>
<li class="chapter" data-level="5.3.1" data-path="pipelines.html"><a href="pipelines.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>5.3.1</b> Hyperparameter Tuning</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="pipelines.html"><a href="pipelines.html#operating-modes-of-pipelines-functions"><i class="fa fa-check"></i><b>5.4</b> Operating Modes of Pipelines Functions</a></li>
<li class="chapter" data-level="5.5" data-path="pipelines.html"><a href="pipelines.html#model-persistence-and-interoperability"><i class="fa fa-check"></i><b>5.5</b> Model Persistence and Interoperability</a><ul>
<li class="chapter" data-level="5.5.1" data-path="pipelines.html"><a href="pipelines.html#sparklyr-ml-models"><i class="fa fa-check"></i><b>5.5.1</b> Sparklyr ML Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="clusters.html"><a href="clusters.html"><i class="fa fa-check"></i><b>6</b> Clusters</a><ul>
<li class="chapter" data-level="6.1" data-path="clusters.html"><a href="clusters.html#clusters-overview"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="clusters.html"><a href="clusters.html#on-premise"><i class="fa fa-check"></i><b>6.2</b> On-Premise</a><ul>
<li class="chapter" data-level="6.2.1" data-path="clusters.html"><a href="clusters.html#clusters-manager"><i class="fa fa-check"></i><b>6.2.1</b> Managers</a></li>
<li class="chapter" data-level="6.2.2" data-path="clusters.html"><a href="clusters.html#distributions"><i class="fa fa-check"></i><b>6.2.2</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="clusters.html"><a href="clusters.html#cloud"><i class="fa fa-check"></i><b>6.3</b> Cloud</a><ul>
<li class="chapter" data-level="6.3.1" data-path="clusters.html"><a href="clusters.html#clusters-amazon-emr"><i class="fa fa-check"></i><b>6.3.1</b> Amazon</a></li>
<li class="chapter" data-level="6.3.2" data-path="clusters.html"><a href="clusters.html#databricks"><i class="fa fa-check"></i><b>6.3.2</b> Databricks</a></li>
<li class="chapter" data-level="6.3.3" data-path="clusters.html"><a href="clusters.html#google"><i class="fa fa-check"></i><b>6.3.3</b> Google</a></li>
<li class="chapter" data-level="6.3.4" data-path="clusters.html"><a href="clusters.html#ibm"><i class="fa fa-check"></i><b>6.3.4</b> IBM</a></li>
<li class="chapter" data-level="6.3.5" data-path="clusters.html"><a href="clusters.html#microsoft"><i class="fa fa-check"></i><b>6.3.5</b> Microsoft</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="clusters.html"><a href="clusters.html#kubernetes"><i class="fa fa-check"></i><b>6.4</b> Kubernetes</a></li>
<li class="chapter" data-level="6.5" data-path="clusters.html"><a href="clusters.html#tools"><i class="fa fa-check"></i><b>6.5</b> Tools</a><ul>
<li class="chapter" data-level="6.5.1" data-path="clusters.html"><a href="clusters.html#rstudio"><i class="fa fa-check"></i><b>6.5.1</b> RStudio</a></li>
<li class="chapter" data-level="6.5.2" data-path="clusters.html"><a href="clusters.html#jupyter"><i class="fa fa-check"></i><b>6.5.2</b> Jupyter</a></li>
<li class="chapter" data-level="6.5.3" data-path="clusters.html"><a href="clusters.html#clusters-livy"><i class="fa fa-check"></i><b>6.5.3</b> Livy</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="clusters.html"><a href="clusters.html#recap-1"><i class="fa fa-check"></i><b>6.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="connections.html"><a href="connections.html"><i class="fa fa-check"></i><b>7</b> Connections</a><ul>
<li class="chapter" data-level="7.1" data-path="connections.html"><a href="connections.html#connections-overview"><i class="fa fa-check"></i><b>7.1</b> Overview</a><ul>
<li class="chapter" data-level="7.1.1" data-path="connections.html"><a href="connections.html#connections-spark-edge-nodes"><i class="fa fa-check"></i><b>7.1.1</b> Edge Nodes</a></li>
<li class="chapter" data-level="7.1.2" data-path="connections.html"><a href="connections.html#connections-spark-home"><i class="fa fa-check"></i><b>7.1.2</b> Spark Home</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="connections.html"><a href="connections.html#connections-local"><i class="fa fa-check"></i><b>7.2</b> Local</a></li>
<li class="chapter" data-level="7.3" data-path="connections.html"><a href="connections.html#connections-standalone"><i class="fa fa-check"></i><b>7.3</b> Standalone</a></li>
<li class="chapter" data-level="7.4" data-path="connections.html"><a href="connections.html#connections-yarn"><i class="fa fa-check"></i><b>7.4</b> Yarn</a><ul>
<li class="chapter" data-level="7.4.1" data-path="connections.html"><a href="connections.html#connections-yarn-client"><i class="fa fa-check"></i><b>7.4.1</b> Yarn Client</a></li>
<li class="chapter" data-level="7.4.2" data-path="connections.html"><a href="connections.html#connections-yarn-cluster"><i class="fa fa-check"></i><b>7.4.2</b> Yarn Cluster</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="connections.html"><a href="connections.html#connections-livy"><i class="fa fa-check"></i><b>7.5</b> Livy</a></li>
<li class="chapter" data-level="7.6" data-path="connections.html"><a href="connections.html#connections-mesos"><i class="fa fa-check"></i><b>7.6</b> Mesos</a></li>
<li class="chapter" data-level="7.7" data-path="connections.html"><a href="connections.html#connections-kubernetes"><i class="fa fa-check"></i><b>7.7</b> Kubernetes</a></li>
<li class="chapter" data-level="7.8" data-path="connections.html"><a href="connections.html#cloud-1"><i class="fa fa-check"></i><b>7.8</b> Cloud</a></li>
<li class="chapter" data-level="7.9" data-path="connections.html"><a href="connections.html#batches"><i class="fa fa-check"></i><b>7.9</b> Batches</a></li>
<li class="chapter" data-level="7.10" data-path="connections.html"><a href="connections.html#tools-1"><i class="fa fa-check"></i><b>7.10</b> Tools</a></li>
<li class="chapter" data-level="7.11" data-path="connections.html"><a href="connections.html#multiple"><i class="fa fa-check"></i><b>7.11</b> Multiple</a></li>
<li class="chapter" data-level="7.12" data-path="connections.html"><a href="connections.html#connections-troubleshooting"><i class="fa fa-check"></i><b>7.12</b> Troubleshooting</a><ul>
<li class="chapter" data-level="7.12.1" data-path="connections.html"><a href="connections.html#logging"><i class="fa fa-check"></i><b>7.12.1</b> Logging</a></li>
<li class="chapter" data-level="7.12.2" data-path="connections.html"><a href="connections.html#troubleshoot-spark-submit"><i class="fa fa-check"></i><b>7.12.2</b> Spark Submit</a></li>
<li class="chapter" data-level="7.12.3" data-path="connections.html"><a href="connections.html#windows"><i class="fa fa-check"></i><b>7.12.3</b> Windows</a></li>
</ul></li>
<li class="chapter" data-level="7.13" data-path="connections.html"><a href="connections.html#recap-2"><i class="fa fa-check"></i><b>7.13</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>8</b> Data</a><ul>
<li class="chapter" data-level="8.1" data-path="data.html"><a href="data.html#source-types-and-file-systems"><i class="fa fa-check"></i><b>8.1</b> Source types and file systems</a><ul>
<li class="chapter" data-level="8.1.1" data-path="data.html"><a href="data.html#default-packages"><i class="fa fa-check"></i><b>8.1.1</b> Default packages</a></li>
<li class="chapter" data-level="8.1.2" data-path="data.html"><a href="data.html#source-types"><i class="fa fa-check"></i><b>8.1.2</b> Source types</a></li>
<li class="chapter" data-level="8.1.3" data-path="data.html"><a href="data.html#file-systems"><i class="fa fa-check"></i><b>8.1.3</b> File systems</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="data.html"><a href="data.html#reading-data"><i class="fa fa-check"></i><b>8.2</b> Reading data</a><ul>
<li class="chapter" data-level="8.2.1" data-path="data.html"><a href="data.html#folders-as-a-table"><i class="fa fa-check"></i><b>8.2.1</b> Folders as a table</a></li>
<li class="chapter" data-level="8.2.2" data-path="data.html"><a href="data.html#file-layout"><i class="fa fa-check"></i><b>8.2.2</b> File layout</a></li>
<li class="chapter" data-level="8.2.3" data-path="data.html"><a href="data.html#spark-memory"><i class="fa fa-check"></i><b>8.2.3</b> Spark memory</a></li>
<li class="chapter" data-level="8.2.4" data-path="data.html"><a href="data.html#column-names"><i class="fa fa-check"></i><b>8.2.4</b> Column Names</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="data.html"><a href="data.html#writing-data"><i class="fa fa-check"></i><b>8.3</b> Writing Data</a><ul>
<li class="chapter" data-level="8.3.1" data-path="data.html"><a href="data.html#spark-not-r-as-pass-through"><i class="fa fa-check"></i><b>8.3.1</b> Spark, not R, as pass-through</a></li>
<li class="chapter" data-level="8.3.2" data-path="data.html"><a href="data.html#practical-approach"><i class="fa fa-check"></i><b>8.3.2</b> Practical approach</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="data.html"><a href="data.html#date-time"><i class="fa fa-check"></i><b>8.4</b> Date &amp; time</a></li>
<li class="chapter" data-level="8.5" data-path="data.html"><a href="data.html#specific-types-and-protocols"><i class="fa fa-check"></i><b>8.5</b> Specific types and protocols</a><ul>
<li class="chapter" data-level="8.5.1" data-path="data.html"><a href="data.html#amazon-s3"><i class="fa fa-check"></i><b>8.5.1</b> Amazon S3</a></li>
<li class="chapter" data-level="8.5.2" data-path="data.html"><a href="data.html#sql"><i class="fa fa-check"></i><b>8.5.2</b> SQL</a></li>
<li class="chapter" data-level="8.5.3" data-path="data.html"><a href="data.html#hive"><i class="fa fa-check"></i><b>8.5.3</b> Hive</a></li>
<li class="chapter" data-level="8.5.4" data-path="data.html"><a href="data.html#comma-delimited-values-csv"><i class="fa fa-check"></i><b>8.5.4</b> Comma Delimited Values (CSV)</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="data.html"><a href="data.html#recap-3"><i class="fa fa-check"></i><b>8.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="tuning.html"><a href="tuning.html"><i class="fa fa-check"></i><b>9</b> Tuning</a><ul>
<li class="chapter" data-level="9.1" data-path="tuning.html"><a href="tuning.html#overview-1"><i class="fa fa-check"></i><b>9.1</b> Overview</a><ul>
<li class="chapter" data-level="9.1.1" data-path="tuning.html"><a href="tuning.html#tuning-graph-visualization"><i class="fa fa-check"></i><b>9.1.1</b> Graph</a></li>
<li class="chapter" data-level="9.1.2" data-path="tuning.html"><a href="tuning.html#tuning-event-timeline"><i class="fa fa-check"></i><b>9.1.2</b> Timeline</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="tuning.html"><a href="tuning.html#tuning-configuring"><i class="fa fa-check"></i><b>9.2</b> Configuring</a><ul>
<li class="chapter" data-level="9.2.1" data-path="tuning.html"><a href="tuning.html#connect-settings"><i class="fa fa-check"></i><b>9.2.1</b> Connect Settings</a></li>
<li class="chapter" data-level="9.2.2" data-path="tuning.html"><a href="tuning.html#submit-settings"><i class="fa fa-check"></i><b>9.2.2</b> Submit Settings</a></li>
<li class="chapter" data-level="9.2.3" data-path="tuning.html"><a href="tuning.html#runtime-settings"><i class="fa fa-check"></i><b>9.2.3</b> Runtime Settings</a></li>
<li class="chapter" data-level="9.2.4" data-path="tuning.html"><a href="tuning.html#sparklyr-settings"><i class="fa fa-check"></i><b>9.2.4</b> sparklyr Settings</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="tuning.html"><a href="tuning.html#tuning-partitioning"><i class="fa fa-check"></i><b>9.3</b> Partitioning</a><ul>
<li class="chapter" data-level="9.3.1" data-path="tuning.html"><a href="tuning.html#implicit"><i class="fa fa-check"></i><b>9.3.1</b> Implicit</a></li>
<li class="chapter" data-level="9.3.2" data-path="tuning.html"><a href="tuning.html#explicit"><i class="fa fa-check"></i><b>9.3.2</b> Explicit</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="tuning.html"><a href="tuning.html#tuning-caching"><i class="fa fa-check"></i><b>9.4</b> Caching</a><ul>
<li class="chapter" data-level="9.4.1" data-path="tuning.html"><a href="tuning.html#checkpointing"><i class="fa fa-check"></i><b>9.4.1</b> Checkpointing</a></li>
<li class="chapter" data-level="9.4.2" data-path="tuning.html"><a href="tuning.html#tuning-memory"><i class="fa fa-check"></i><b>9.4.2</b> Memory</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="tuning.html"><a href="tuning.html#tuning-shuffling"><i class="fa fa-check"></i><b>9.5</b> Shuffling</a></li>
<li class="chapter" data-level="9.6" data-path="tuning.html"><a href="tuning.html#tuning-serialization"><i class="fa fa-check"></i><b>9.6</b> Serialization</a></li>
<li class="chapter" data-level="9.7" data-path="tuning.html"><a href="tuning.html#configuration-files"><i class="fa fa-check"></i><b>9.7</b> Configuration Files</a></li>
<li class="chapter" data-level="9.8" data-path="tuning.html"><a href="tuning.html#recap-4"><i class="fa fa-check"></i><b>9.8</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="extensions.html"><a href="extensions.html"><i class="fa fa-check"></i><b>10</b> Extensions</a><ul>
<li class="chapter" data-level="10.1" data-path="extensions.html"><a href="extensions.html#overview-2"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="extensions.html"><a href="extensions.html#h2o"><i class="fa fa-check"></i><b>10.2</b> H2O</a></li>
<li class="chapter" data-level="10.3" data-path="extensions.html"><a href="extensions.html#graphs"><i class="fa fa-check"></i><b>10.3</b> Graphs</a></li>
<li class="chapter" data-level="10.4" data-path="extensions.html"><a href="extensions.html#xgboost"><i class="fa fa-check"></i><b>10.4</b> XGBoost</a></li>
<li class="chapter" data-level="10.5" data-path="extensions.html"><a href="extensions.html#deep-learning"><i class="fa fa-check"></i><b>10.5</b> Deep Learning</a></li>
<li class="chapter" data-level="10.6" data-path="extensions.html"><a href="extensions.html#genomics"><i class="fa fa-check"></i><b>10.6</b> Genomics</a></li>
<li class="chapter" data-level="10.7" data-path="extensions.html"><a href="extensions.html#spatial"><i class="fa fa-check"></i><b>10.7</b> Spatial</a></li>
<li class="chapter" data-level="10.8" data-path="extensions.html"><a href="extensions.html#troubleshooting"><i class="fa fa-check"></i><b>10.8</b> Troubleshooting</a></li>
<li class="chapter" data-level="10.9" data-path="extensions.html"><a href="extensions.html#recap-5"><i class="fa fa-check"></i><b>10.9</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="distributed.html"><a href="distributed.html"><i class="fa fa-check"></i><b>11</b> Distributed R</a><ul>
<li class="chapter" data-level="11.1" data-path="distributed.html"><a href="distributed.html#overview-3"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="distributed.html"><a href="distributed.html#use-cases"><i class="fa fa-check"></i><b>11.2</b> Use Cases</a><ul>
<li class="chapter" data-level="11.2.1" data-path="distributed.html"><a href="distributed.html#custom-parsers"><i class="fa fa-check"></i><b>11.2.1</b> Custom Parsers</a></li>
<li class="chapter" data-level="11.2.2" data-path="distributed.html"><a href="distributed.html#partitioned-modeling"><i class="fa fa-check"></i><b>11.2.2</b> Partitioned Modeling</a></li>
<li class="chapter" data-level="11.2.3" data-path="distributed.html"><a href="distributed.html#distributed-grid-search"><i class="fa fa-check"></i><b>11.2.3</b> Grid Search</a></li>
<li class="chapter" data-level="11.2.4" data-path="distributed.html"><a href="distributed.html#web-apis"><i class="fa fa-check"></i><b>11.2.4</b> Web APIs</a></li>
<li class="chapter" data-level="11.2.5" data-path="distributed.html"><a href="distributed.html#distributed-rendering"><i class="fa fa-check"></i><b>11.2.5</b> Distributed Rendering</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="distributed.html"><a href="distributed.html#partitions"><i class="fa fa-check"></i><b>11.3</b> Partitions</a></li>
<li class="chapter" data-level="11.4" data-path="distributed.html"><a href="distributed.html#grouping"><i class="fa fa-check"></i><b>11.4</b> Grouping</a></li>
<li class="chapter" data-level="11.5" data-path="distributed.html"><a href="distributed.html#columns"><i class="fa fa-check"></i><b>11.5</b> Columns</a></li>
<li class="chapter" data-level="11.6" data-path="distributed.html"><a href="distributed.html#context"><i class="fa fa-check"></i><b>11.6</b> Context</a></li>
<li class="chapter" data-level="11.7" data-path="distributed.html"><a href="distributed.html#functions"><i class="fa fa-check"></i><b>11.7</b> Functions</a></li>
<li class="chapter" data-level="11.8" data-path="distributed.html"><a href="distributed.html#packages"><i class="fa fa-check"></i><b>11.8</b> Packages</a></li>
<li class="chapter" data-level="11.9" data-path="distributed.html"><a href="distributed.html#cluster-requirements"><i class="fa fa-check"></i><b>11.9</b> Cluster Requirements</a><ul>
<li class="chapter" data-level="11.9.1" data-path="distributed.html"><a href="distributed.html#installing-r"><i class="fa fa-check"></i><b>11.9.1</b> Installing R</a></li>
<li class="chapter" data-level="11.9.2" data-path="distributed.html"><a href="distributed.html#apache-arrow"><i class="fa fa-check"></i><b>11.9.2</b> Apache Arrow</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="distributed.html"><a href="distributed.html#troubleshooting-1"><i class="fa fa-check"></i><b>11.10</b> Troubleshooting</a><ul>
<li class="chapter" data-level="11.10.1" data-path="distributed.html"><a href="distributed.html#worker-logs"><i class="fa fa-check"></i><b>11.10.1</b> Worker Logs</a></li>
<li class="chapter" data-level="11.10.2" data-path="distributed.html"><a href="distributed.html#resolving-timeouts"><i class="fa fa-check"></i><b>11.10.2</b> Resolving Timeouts</a></li>
<li class="chapter" data-level="11.10.3" data-path="distributed.html"><a href="distributed.html#inspecting-partition"><i class="fa fa-check"></i><b>11.10.3</b> Inspecting Partition</a></li>
<li class="chapter" data-level="11.10.4" data-path="distributed.html"><a href="distributed.html#debugging-workers"><i class="fa fa-check"></i><b>11.10.4</b> Debugging Workers</a></li>
</ul></li>
<li class="chapter" data-level="11.11" data-path="distributed.html"><a href="distributed.html#recap-6"><i class="fa fa-check"></i><b>11.11</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="streaming.html"><a href="streaming.html"><i class="fa fa-check"></i><b>12</b> Streaming</a><ul>
<li class="chapter" data-level="12.1" data-path="streaming.html"><a href="streaming.html#spark-streaming"><i class="fa fa-check"></i><b>12.1</b> Spark Streaming</a></li>
<li class="chapter" data-level="12.2" data-path="streaming.html"><a href="streaming.html#working-with-spark-streams"><i class="fa fa-check"></i><b>12.2</b> Working with Spark Streams</a></li>
<li class="chapter" data-level="12.3" data-path="streaming.html"><a href="streaming.html#sparklyr-extras"><i class="fa fa-check"></i><b>12.3</b> <code>sparklyr</code> extras</a><ul>
<li class="chapter" data-level="12.3.1" data-path="streaming.html"><a href="streaming.html#stream-monitor"><i class="fa fa-check"></i><b>12.3.1</b> Stream monitor</a></li>
<li class="chapter" data-level="12.3.2" data-path="streaming.html"><a href="streaming.html#stream-generator"><i class="fa fa-check"></i><b>12.3.2</b> Stream generator</a></li>
<li class="chapter" data-level="12.3.3" data-path="streaming.html"><a href="streaming.html#shiny-reactive"><i class="fa fa-check"></i><b>12.3.3</b> Shiny reactive</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="streaming.html"><a href="streaming.html#intro-example"><i class="fa fa-check"></i><b>12.4</b> Intro example</a></li>
<li class="chapter" data-level="12.5" data-path="streaming.html"><a href="streaming.html#transformations"><i class="fa fa-check"></i><b>12.5</b> Transformations</a><ul>
<li class="chapter" data-level="12.5.1" data-path="streaming.html"><a href="streaming.html#dplyr"><i class="fa fa-check"></i><b>12.5.1</b> dplyr</a></li>
<li class="chapter" data-level="12.5.2" data-path="streaming.html"><a href="streaming.html#transformer-functions"><i class="fa fa-check"></i><b>12.5.2</b> Transformer functions</a></li>
<li class="chapter" data-level="12.5.3" data-path="streaming.html"><a href="streaming.html#r-code"><i class="fa fa-check"></i><b>12.5.3</b> R code</a></li>
<li class="chapter" data-level="12.5.4" data-path="streaming.html"><a href="streaming.html#ml-pipelines"><i class="fa fa-check"></i><b>12.5.4</b> ML Pipelines</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="streaming.html"><a href="streaming.html#shiny-integration"><i class="fa fa-check"></i><b>12.6</b> Shiny integration</a></li>
<li class="chapter" data-level="12.7" data-path="streaming.html"><a href="streaming.html#kafka"><i class="fa fa-check"></i><b>12.7</b> Kafka</a><ul>
<li class="chapter" data-level="12.7.1" data-path="streaming.html"><a href="streaming.html#workflow"><i class="fa fa-check"></i><b>12.7.1</b> Workflow</a></li>
<li class="chapter" data-level="12.7.2" data-path="streaming.html"><a href="streaming.html#spark-integration"><i class="fa fa-check"></i><b>12.7.2</b> Spark integration</a></li>
<li class="chapter" data-level="12.7.3" data-path="streaming.html"><a href="streaming.html#r-integration"><i class="fa fa-check"></i><b>12.7.3</b> R integration</a></li>
<li class="chapter" data-level="12.7.4" data-path="streaming.html"><a href="streaming.html#example"><i class="fa fa-check"></i><b>12.7.4</b> Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="contributing.html"><a href="contributing.html"><i class="fa fa-check"></i><b>13</b> Contributing</a><ul>
<li class="chapter" data-level="13.1" data-path="contributing.html"><a href="contributing.html#contributing-overview"><i class="fa fa-check"></i><b>13.1</b> Overview</a></li>
<li class="chapter" data-level="13.2" data-path="contributing.html"><a href="contributing.html#contributing-spark-api"><i class="fa fa-check"></i><b>13.2</b> Spark API</a></li>
<li class="chapter" data-level="13.3" data-path="contributing.html"><a href="contributing.html#spark-extensions"><i class="fa fa-check"></i><b>13.3</b> Spark Extensions</a></li>
<li class="chapter" data-level="13.4" data-path="contributing.html"><a href="contributing.html#scala-code"><i class="fa fa-check"></i><b>13.4</b> Scala Code</a></li>
<li class="chapter" data-level="13.5" data-path="contributing.html"><a href="contributing.html#recap-7"><i class="fa fa-check"></i><b>13.5</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>14</b> Appendix</a><ul>
<li class="chapter" data-level="14.1" data-path="appendix.html"><a href="appendix.html#appendix-prerequisites"><i class="fa fa-check"></i><b>14.1</b> Prerequisites</a><ul>
<li class="chapter" data-level="14.1.1" data-path="appendix.html"><a href="appendix.html#appendix-install-r"><i class="fa fa-check"></i><b>14.1.1</b> Installing R</a></li>
<li class="chapter" data-level="14.1.2" data-path="appendix.html"><a href="appendix.html#appendix-install-java"><i class="fa fa-check"></i><b>14.1.2</b> Installing Java</a></li>
<li class="chapter" data-level="14.1.3" data-path="appendix.html"><a href="appendix.html#appendix-install-rstudio"><i class="fa fa-check"></i><b>14.1.3</b> Installing RStudio</a></li>
<li class="chapter" data-level="14.1.4" data-path="appendix.html"><a href="appendix.html#appendix-using-rstudio"><i class="fa fa-check"></i><b>14.1.4</b> Using RStudio</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="appendix.html"><a href="appendix.html#diagrams"><i class="fa fa-check"></i><b>14.2</b> Diagrams</a><ul>
<li class="chapter" data-level="14.2.1" data-path="appendix.html"><a href="appendix.html#appendix-storage-capacity"><i class="fa fa-check"></i><b>14.2.1</b> Worlds Store Capacity</a></li>
<li class="chapter" data-level="14.2.2" data-path="appendix.html"><a href="appendix.html#appendix-cran-downloads"><i class="fa fa-check"></i><b>14.2.2</b> Daily downloads of CRAN packages</a></li>
<li class="chapter" data-level="14.2.3" data-path="appendix.html"><a href="appendix.html#appendix-cluster-trends"><i class="fa fa-check"></i><b>14.2.3</b> Google trends for mainframes, cloud computing and kubernetes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="appendix.html"><a href="appendix.html#appendix-ggplot2-theme"><i class="fa fa-check"></i><b>14.3</b> Formatting</a></li>
<li class="chapter" data-level="14.4" data-path="appendix.html"><a href="appendix.html#ml-functionlist"><i class="fa fa-check"></i><b>14.4</b> List of ML Functions</a><ul>
<li class="chapter" data-level="14.4.1" data-path="appendix.html"><a href="appendix.html#classification"><i class="fa fa-check"></i><b>14.4.1</b> Classification</a></li>
<li class="chapter" data-level="14.4.2" data-path="appendix.html"><a href="appendix.html#regression"><i class="fa fa-check"></i><b>14.4.2</b> Regression</a></li>
<li class="chapter" data-level="14.4.3" data-path="appendix.html"><a href="appendix.html#clustering"><i class="fa fa-check"></i><b>14.4.3</b> Clustering</a></li>
<li class="chapter" data-level="14.4.4" data-path="appendix.html"><a href="appendix.html#recommendation"><i class="fa fa-check"></i><b>14.4.4</b> Recommendation</a></li>
<li class="chapter" data-level="14.4.5" data-path="appendix.html"><a href="appendix.html#frequent-pattern-mining"><i class="fa fa-check"></i><b>14.4.5</b> Frequent Pattern Mining</a></li>
<li class="chapter" data-level="14.4.6" data-path="appendix.html"><a href="appendix.html#feature-transformers"><i class="fa fa-check"></i><b>14.4.6</b> Feature Transformers</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="appendix.html"><a href="appendix.html#kafka-1"><i class="fa fa-check"></i><b>14.5</b> Kafka</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>15</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mastering Apache Spark with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="extensions" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Extensions</h1>
<p>In the previous chapter, <a href="tuning">Tuning</a>, you learned how Spark processes data at large-scale by allowing users to configure the cluster resources, partition data implicitly or explicitly, execute commands across distributed compute nodes, shuffle data across them when needed, cache data to improve performance and serialize data efficiently over the network. You also learned how to configure the different Spark settings used while connecting, submitting a job, running and application and particular settings applicable only to R and R extensions that we will present in this chapter.</p>
<p>The <a href="analysis.html#analysis">Analysis</a>, <a href="modeling.html#modeling">Modeling</a> and <a href="data.html#data">Data</a> chapters provided a foundation to read and understand most datasets. However, the functionality that was presented was scoped to Spark’s built-in features and tabular datasets. This chapter will go beyond tabular data and explore how to analyze and model networks of interconnected objects through graph processing, read genomics datasets, prepare data for deep learning, analyze geographic datasets and use advanced modeling libraries like H2O and XGBoost over large-scale datasets.</p>
<p>The combination of all the content presented in all the previous chapters should take care of most of your large-scale computing needs. However, for those few use cases where functionality is still lacking, the following chapters will teach you provide the tools to extend Spark yourself; either, through custom R transformation, custom Scala code or through recent new execution mode in Spark that enable analyzing realtime datasets. Although, before reinventing the wheel, we will present all the extensions available when using Spark with R.</p>
<div id="overview-2" class="section level2">
<h2><span class="header-section-number">10.1</span> Overview</h2>
<p>In the <a href="intro.html#intro">Introduction</a> chapter we presented the R community as a vibrant group of individuals collaborating with each other in many ways, one of them, by moving open science forward by creating R packages that can be installed from CRAN. In a similar way, but in a much smaller scale, the R community has contributed extensions that increase the functionality initially supported in Spark and R. Spark itself also provides support for creating Spark extensions and, in-fact, many R extensions make use of Spark extensions.</p>
<p>Extensions are constantly being created so this section will be outdated at any given point in time, in addition, we might not be even aware of many Spark and R extensions; however, at the very least we can track the extensions that are available in CRAN by looking at the “reverse imports” for <code>sparklyr</code> in CRAN <span class="citation">(“CRAN - Package Sparklyr” <a href="#ref-extensions-sparklyr-cran">2019</a>)</span>. Extensions and R packages published in CRAN tend to be the most stable since when a package is published in CRAN, it will go through a review process which increases the overall quality of a contribution.</p>
<p>While we wish we could present all the extensions, we’ve picked a few that we believe should be interesting to most readers and which we will present next. You can find a few more under the <a href="https://github.com/r-spark">github.com/r-spark</a> organization or by searching repos in GitHub with the <code>sparklyr</code> tag.</p>
<dl>
<dt>rsparkling</dt>
<dd>The <code>rsparkling</code> extensions allows you to use H2O and Spark from R. This extension is what we would consider advanced modeling in Spark. While Spark’s built-in modeling library, Spark MLlib, is quite useful in many cases; H2O’s modeling capabilities can compute additional statistical metrics and can proivide performance and scalability improvements over Spark MLlib. We, ourselves, have not performed detailed comparisons nor benchamarks between MLlib and H2O; so this is something you will have to research on your own to create a complete picture of when to use H2O’s capabilities.
</dd>
<dt>graphframes</dt>
<dd>The <code>graphframes</code> extensions adds support to process graphs in Spark. A graph is a structure that describes a set of objects in which some pairs of the objects are in some sense related. As you learned in the Introduction chapter, ranking web pages was an early motivation to develop precursos to Spark powered by MapReduce; web pages happen to form a graph if you consider a link between pages as the relationship between each pair of pages. Computing operations likes PageRank over graphs can be quite useful in web search and social networks to mention a few applications.
</dd>
<dt>sparktf</dt>
<dd>The <code>sparktf</code> extension provides support to write TensorFlow records in Spark. TensorFlow is one of the leading deep learning frameworks and it is often used with large amounts of numerical data represented as TensorFlow records, a file format optimized for TensorFlow. Spark it is often used to process unstructured and large-scale datasets into smaller numerical datasets that can easily fit into a GPU. You can use this extension to save datasets in the TensorFLow record file format.
</dd>
<dt>xgboost</dt>
<dd>The <code>xgboost</code> extension brings the well-known XGBoost modeling library to the world of large-scale computing. XGBoost is a scalable, portable and distributed library for gradient boosting. It became well known in the machine learning competition circles after its use in the winning solution of the Higgs Machine Learning Challenge <span class="citation">(“Higgs Boson Machine Learning Challenge” <a href="#ref-extensions-higgs-challenge">2019</a>)</span> and has remain popular in other Kaggle competitions since then.
</dd>
<dt>variantspark</dt>
<dd>The <code>variantspark</code> extension provides an interface to use Variant Spark, a scalable toolkit for genome-wide association studies (GWAS). It currently provides functionality to build random forest models, estimating variable importance and reading Variant Call Format (VCF) files. While there are other random forest implementations in Spark, most of them are not optimized to deal with GWAS datasets, which usually come with thousands of samples and millions of variables.
</dd>
<dt>geospark</dt>
<dd>The <code>geospark</code> extensions enables us to load and query large-scale geographic datasets. Usually datasets containing latitude and longitude points or complex areas defined in the Well-known Text (WKT) format, a text markup language for representing vector geometry objects on a map.
</dd>
</dl>
<p>Before you learn how and when to use each extension, we should first briefly explain how extensions can be used with R and Spark.</p>
<p>First, an Spark extension is just and R package that happens to be aware of Spark. As any other R package, you will first have to install the R package with <code>install.packages("package-name")</code>. Once installed, it is important to know that you willn need to reconnect to Spark before the extension can be used. Son in general, the pattern you should follow goes as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparkextension)
<span class="kw">library</span>(sparklyr)

sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;&lt;master&gt;&quot;</span>)</code></pre>
<p>Notice that <code>sparklyr</code> is loaded after the extensions to allow the extension to register properly. If you had to install and load a new extension you would simply have to disconnect first using <code>spark_disconnect(sc)</code> and repeat the steps above with the new extension.</p>
<p>As you can notice, it’s not hard to install and use Spark extensions from R; however, each extension can be a world on it’s own so most of the time you will have to spend time understand what the extension is, when to use it and how to use it properly. The first extension you will learn about is the <code>rsparkling</code> extension which enables you to use H2O in Spark with R.</p>
</div>
<div id="h2o" class="section level2">
<h2><span class="header-section-number">10.2</span> H2O</h2>
<p><a href="https://www.h2o.ai/">H2O</a> is open-source software for large-scale modeling created by H2O.ai, which allows you to fit thousands of potential models as part of discovering patterns in data. You can consider using H2O to complement or replace Spark’s default modeling algorithms. It is common to Spark’s default modeling algorithms and transition to H2O when Spark’s algorithms fall short or when advanced functionality (like additional modeling metrics) are required.</p>
<p>We can’t do justice to H2O’s great modeling capabilities in a single paragraph, explaining H2O properly will require a book in itself. Instead, we would like to recommend reading the “Practical machine learning with H2O” <span class="citation">(Cook <a href="#ref-extensions-practical-h2o">2016</a>)</span> book to explore in-depth H2O’s modeling algorithms and features. In the meantime, you can use this section as a brief guide to get started using H2O in Spark with R.</p>
<p>In order to use H2O with Spark, it is important to know that there are four compoinents involved: H2O, Sparkling Water, [rsparkling][rsparkling](<a href="https://github.com/h2oai/sparkling-water/tree/master/r" class="uri">https://github.com/h2oai/sparkling-water/tree/master/r</a>) and Spark. Sparkling Water allows users to combine the fast, scalable machine learning algorithms of H2O with the capabilities of Spark. You can think of Sparkling Water as a component bridging Spark with H2O and <code>rsparkling</code> as the R front-end for Sparkling Water, this is illustrated in Figure <a href="extensions.html#fig:extensions-h2o-diagram">10.1</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-h2o-diagram"></span>
<div id="htmlwidget-e1600b660174ed2f0f14" style="width:768px;height:288px;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-e1600b660174ed2f0f14">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n  #direction: right\n   \n\n#spacing: 20\n#padding: 16\n[R | \n  [rsparkling]\n  [sparklyr]\n]->[Spark |\n  [Sparkling Water]\n  [H2O]\n]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 10.1: H2O components with Spark and R
</p>
</div>
<p>First, install <code>rsparkling</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;rsparkling&quot;</span>)</code></pre>
<p>Is is then important to notice that you need to use compatible versions of Spark, Sparkling Water and H2O. So let’s start by checking the version of H2O by running,</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">packageVersion</span>(<span class="st">&quot;h2o&quot;</span>)</code></pre>
<pre><code>## [1] &#39;3.22.1.3&#39;</code></pre>
<p>Then we can explore the Spark and Sparkling Water versions that are compatible with <code>h2o_release_table()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">rsparkling<span class="op">::</span><span class="kw">h2o_release_table</span>() <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(H2O_Version <span class="op">==</span><span class="st"> </span><span class="op">!!</span><span class="kw">as.character</span>(<span class="kw">packageVersion</span>(<span class="st">&quot;h2o&quot;</span>)))</code></pre>
<pre><code># A tibble: 4 x 5
  Spark_Version Sparkling_Water_V… H2O_Version H2O_Release_Name H2O_Release_Patch…
          &lt;dbl&gt; &lt;fct&gt;              &lt;fct&gt;       &lt;fct&gt;                         &lt;int&gt;
1           2.4 2.4.5              3.22.1.3    rel-xu                            3
2           2.3 2.3.23             3.22.1.3    rel-xu                            3
3           2.2 2.2.34             3.22.1.3    rel-xu                            3
4           2.1 2.1.48             3.22.1.3    rel-xu                            3</code></pre>
<p>We can then connect with the supported Spark versions as follows, you will have to adjust the <code>master</code> parameter for your particular cluster. We also recommend increasing the connection timeout since Spark might require to download various H2O components while the connection is established for the first time:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rsparkling)
<span class="kw">library</span>(sparklyr)
<span class="kw">library</span>(h2o)

config &lt;-<span class="st"> </span><span class="kw">spark_config</span>()
config<span class="op">$</span>sparklyr.connect.timeout &lt;-<span class="st"> </span><span class="dv">3</span> <span class="op">*</span><span class="st"> </span><span class="dv">60</span>
  
sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3&quot;</span>, <span class="dt">config =</span> config)
cars &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, mtcars)</code></pre>
<p>H2O provides a web interface which can help you monitor training and access much of H2O’s functionality. The web interface can be accessed through <code>h2o_flow(sc)</code>, it is reffered to as H2O Flow and is shown in Figure <a href="extensions.html#fig:extensions-h2o-flow">10.2</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-h2o-flow"></span>
<img src="images/extensions-h2o-flow-resized.png" alt="H2O Flow Interface using Spark with R" width="1500" />
<p class="caption">
FIGURE 10.2: H2O Flow Interface using Spark with R
</p>
</div>
<p>When using H2O, you will have to convert your Spark DataFrame into and H2O DataFrame through <code>as_h2o_frame</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">cars_h2o &lt;-<span class="st"> </span><span class="kw">as_h2o_frame</span>(sc, cars)
cars_h2o</code></pre>
<pre><code>   mpg cyl disp  hp drat    wt  qsec vs am gear carb
1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1

[32 rows x 11 columns] </code></pre>
<p>Then you can use many of the modeling functions available in the <code>h2o</code> package with ease. For instance, we can fit a generalized linear model with ease:</p>
<pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">h2o.glm</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="st">&quot;wt&quot;</span>, <span class="st">&quot;cyl&quot;</span>),
                 <span class="dt">y =</span> <span class="st">&quot;mpg&quot;</span>,
                 <span class="dt">training_frame =</span> cars_h2o,
                 <span class="dt">lambda_search =</span> <span class="ot">TRUE</span>)</code></pre>
<p>H2O provides additional metrics not necessarily available in Spark’s modeling algorithms, the model that we just fit <code>Residual Deviance</code> is provided in the model while this would not be a standard metric when using Spark MLlib.</p>
<pre class="sourceCode r"><code class="sourceCode r">model</code></pre>
<pre><code>...
MSE:  6.017684
RMSE:  2.453097
MAE:  1.940985
RMSLE:  0.1114801
Mean Residual Deviance :  6.017684
R^2 :  0.8289895
Null Deviance :1126.047
Null D.o.F. :31
Residual Deviance :192.5659
Residual D.o.F. :29
AIC :156.2425</code></pre>
<p>Then you can run prediction over the generalized linear model model, a similar approach would work for many other models available in H2O:</p>
<pre class="sourceCode r"><code class="sourceCode r">predictions &lt;-<span class="st"> </span><span class="kw">as_h2o_frame</span>(sc, <span class="kw">copy_to</span>(sc, <span class="kw">data.frame</span>(<span class="dt">wt =</span> <span class="dv">2</span>, <span class="dt">cyl =</span> <span class="dv">6</span>)))
<span class="kw">h2o.predict</span>(model, predictions)</code></pre>
<pre><code>   predict
1 24.05984

[1 row x 1 column]</code></pre>
<p>H2O can also be used to perform automatic training and tuning of many models; meaning that, H2O can choose which model to use for you using <code>h2o.automl</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">automl &lt;-<span class="st"> </span><span class="kw">h2o.automl</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="st">&quot;wt&quot;</span>, <span class="st">&quot;cyl&quot;</span>), <span class="dt">y =</span> <span class="st">&quot;mpg&quot;</span>,
                     <span class="dt">training_frame =</span> cars_h2o,
                     <span class="dt">max_models =</span> <span class="dv">20</span>,
                     <span class="dt">seed =</span> <span class="dv">1</span>)</code></pre>
<p>For this particular dataset, H2O finds out that XGBoost is a better fit than GLM. Specifically, the H2O explored using XGBoost, Deep Learning, GLM and a Stacked Ensemble.</p>
<pre class="sourceCode r"><code class="sourceCode r">automl</code></pre>
<pre><code>model_id              mean_residual_deviance     rmse      mse      mae     rmsle
1 XGBoost_1_...       6.627278               2.574350 6.627278 2.066412 0.1329469
2 DeepLearning_...    6.945850               2.635498 6.945850 2.209201 0.1258008
3 XGBoost_grid_1_...  7.025614               2.650587 7.025614 2.192791 0.1339280
4 XGBoost_grid_1_...  7.266691               2.695680 7.266691 2.167930 0.1331849
5 GLM_grid_...        7.416367               2.723301 7.416367 2.184664 0.1269808
6 StackedEnsemble...  7.596133               2.756108 7.596133 2.029900 0.1340302</code></pre>
<p>Many additional examples are available under <a href="http://spark.rstudio.com/guides/h2o/">spark.rstudio.com/guides/h2o</a>, you can also request help from <a href="https://github.com/h2oai/sparkling-water/tree/master/r">github.com/h2oai/sparkling-water/tree/master/r</a>, the official GitHub repository for the <code>rsparkling</code> package.</p>
<p>The next extension we will present will allow you to process large-scale graph datasets; therefore, make sure to disconnect with <code>spark_disconnect(sc)</code> since using different extensions requires you to reconnect to Spark.</p>
</div>
<div id="graphs" class="section level2">
<h2><span class="header-section-number">10.3</span> Graphs</h2>
<p>The first paper in the history of graph theory was written by Leonhard Euler on the Seven Bridges of Königsberg in 1736. The problem was to devise a walk through the city that would cross each of those bridges once and only, the original diagram is shown in Figure <a href="extensions.html#fig:extensions-eulers-paths">10.3</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-eulers-paths"></span>
<img src="images/extensions-eulers-paths-resized.png" alt="Seven Bridges of Königsberg from the Euler Archive" width="1500" />
<p class="caption">
FIGURE 10.3: Seven Bridges of Königsberg from the Euler Archive
</p>
</div>
<p>Today, a graph is defined as an ordered pair <span class="math inline">\(G=(V,E)\)</span>, with <span class="math inline">\(V\)</span> a set of vertices (nodes or points) and <span class="math inline">\(E \subseteq \{\{x, y\} | (x, y) ∈ \mathrm{V}^2 \land x \ne y\}\)</span> a set of edges (links or lines) which are either an unordered pair for <strong>undirected graphs</strong> or an ordered pair for <strong>directed graphs</strong>. The former describing links where the direction does not matter and the latter linked where it does.</p>
<p>As a simple example, we can use the <code>highschool</code> dataset from the <code>ggraph</code> package which tracks friendship among high school boys,</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggraph)
<span class="kw">library</span>(igraph)

highschool</code></pre>
<pre><code># A tibble: 506 x 3
    from    to  year
   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
 1     1    14  1957
 2     1    15  1957
 3     1    21  1957
 4     1    54  1957
 5     1    55  1957
 6     2    21  1957
 7     2    22  1957
 8     3     9  1957
 9     3    15  1957
10     4     5  1957
# … with 496 more rows</code></pre>
<p>A graph in <a href="https://graphframes.github.io/">GraphFrames</a> is also represented as a table of edges and vertices; however, the format needs to follow an specific schema. Lets first install the <code>graphframes</code> extension,</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(graphframes)</code></pre>
<p>Followed by connecting, copying the <code>highschool</code> dataset and transforming the graph to the format that this extension expects, we will scope this dataset to the friendships of year 1957.</p>
<p>The <code>vertices_tbl</code> table is expected to have a single <code>id</code> column:</p>
<pre><code># Source: spark&lt;?&gt; [?? x 1]
   id   
   &lt;chr&gt;
 1 1    
 2 34   
 3 37   
 4 43   
 5 44   
 6 45   
 7 56   
 8 57   
 9 65   
10 71   
# … with more rows</code></pre>
<p>While the <code>edges_tbl</code> is expected to have a <code>src</code> and <code>dst</code> columns:</p>
<pre><code># Source: spark&lt;?&gt; [?? x 2]
   src   dst  
   &lt;chr&gt; &lt;chr&gt;
 1 1     14   
 2 1     15   
 3 1     21   
 4 1     54   
 5 1     55   
 6 2     21   
 7 2     22   
 8 3     9    
 9 3     15   
10 4     5    
# … with more rows</code></pre>
<p>You can now create a GraphFrame,</p>
<pre class="sourceCode r"><code class="sourceCode r">graph &lt;-<span class="st"> </span><span class="kw">gf_graphframe</span>(vertices_tbl, edges_tbl)</code></pre>
<p>We can now use this graph to start analyzing this dataset. For instance, by finding out how many friends on average every one has, this is reffered as the degree or valency of a vertex:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_degrees</span>(graph) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">friends =</span> <span class="kw">mean</span>(degree))</code></pre>
<pre><code># Source: spark&lt;?&gt; [?? x 1]
  friends
    &lt;dbl&gt;
1    6.94</code></pre>
<p>We can then find what the shortest path to some specific vertex (person for this dataset). Since the data is annonimized, we can just pick the person identified as <span class="math inline">\(33\)</span> and find how many degrees of separation exist between them:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_shortest_paths</span>(graph, <span class="dv">33</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">size</span>(distances) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">distance =</span> <span class="kw">explode</span>(<span class="kw">map_values</span>(distances))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(id, distance)</code></pre>
<pre><code># Source: spark&lt;?&gt; [?? x 2]
   id    distance
   &lt;chr&gt;    &lt;int&gt;
 1 19           5
 2 5            4
 3 27           6
 4 4            4
 5 11           6
 6 23           4
 7 36           1
 8 26           2
 9 33           0
10 18           5
# … with more rows</code></pre>
<p>Finally, we can compute PageRank over this graph, which is named after Google’s foudner Larry Page:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_graphframe</span>(vertices_tbl, edges_tbl) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_pagerank</span>(<span class="dt">reset_prob =</span> <span class="fl">0.15</span>, <span class="dt">max_iter =</span> 10L)</code></pre>
<pre><code>GraphFrame
Vertices:
  Database: spark_connection
  $ id       &lt;dbl&gt; 12, 12, 14, 14, 27, 27, 55, 55, 64, 64, 41, 41, 47, 47, 6…
  $ pagerank &lt;dbl&gt; 0.3573460, 0.3573460, 0.3893665, 0.3893665, 0.2362396, 0.…
Edges:
  Database: spark_connection
  $ src    &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 12, 12, 12,…
  $ dst    &lt;dbl&gt; 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,…
  $ weight &lt;dbl&gt; 0.25000000, 0.25000000, 0.25000000, 0.25000000, 0.25000000,…</code></pre>
<p>To give you some insights into this dataset, Figure <a href="extensions.html#fig:extensions-graph-pagerank">10.4</a> plots this chart using the <code>ggraph</code> and highlights the highest PageRank scores fot this dataset,</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-graph-pagerank"></span>
<img src="images/extensions-graph-pagerank-resized.png" alt="Highschool ggraph dataset with highest pagerank highlighted" width="1500" />
<p class="caption">
FIGURE 10.4: Highschool ggraph dataset with highest pagerank highlighted
</p>
</div>
<p>There are many more graph algorithms provided in <code>graphframes</code>, to mention some: bread depth search, connected components, label propagation for detecting communities, etc. For questions on this extension reffer to the official GitHub repo, <a href="https://github.com/rstudio/graphframes">github.com/rstudio/graphframes</a>. We will now present a popular gradient boosting framework.</p>
</div>
<div id="xgboost" class="section level2">
<h2><span class="header-section-number">10.4</span> XGBoost</h2>
<p>sparkxgb is a new sparklyr extension that can be used to train XGBoost models in Spark and is installed as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;sparkxgb&quot;</span>)</code></pre>
<p>We can then use xgboost_classifier() to train and ml_predict() to predict over large datasets with ease:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparkxgb)
<span class="kw">library</span>(sparklyr)
<span class="kw">library</span>(dplyr)

sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>)
iris &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, iris)

xgb_model &lt;-<span class="st"> </span><span class="kw">xgboost_classifier</span>(iris,
                                Species <span class="op">~</span><span class="st"> </span>.,
                                <span class="dt">num_class =</span> <span class="dv">3</span>,
                                <span class="dt">num_round =</span> <span class="dv">50</span>,
                                <span class="dt">max_depth =</span> <span class="dv">4</span>)

xgb_model <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ml_predict</span>(iris) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Species, predicted_label, <span class="kw">starts_with</span>(<span class="st">&quot;probability_&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">glimpse</span>()

<span class="kw">spark_disconnect</span>(sc)</code></pre>
<pre><code>#&gt; Observations: ??
#&gt; Variables: 5
#&gt; Database: spark_connection
#&gt; $ Species                &lt;chr&gt; &quot;setosa&quot;, &quot;setosa&quot;, &quot;setosa&quot;, &quot;setosa&quot;, &quot;…
#&gt; $ predicted_label        &lt;chr&gt; &quot;setosa&quot;, &quot;setosa&quot;, &quot;setosa&quot;, &quot;setosa&quot;, &quot;…
#&gt; $ probability_versicolor &lt;dbl&gt; 0.003566429, 0.003564076, 0.003566429, 0.…
#&gt; $ probability_virginica  &lt;dbl&gt; 0.001423170, 0.002082058, 0.001423170, 0.…
#&gt; $ probability_setosa     &lt;dbl&gt; 0.9950104, 0.9943539, 0.9950104, 0.995010…</code></pre>
</div>
<div id="deep-learning" class="section level2">
<h2><span class="header-section-number">10.5</span> Deep Learning</h2>
<p>sparktf is a new sparklyr extension allowing you to write TensorFlow records in Spark. This can be used to preprocess large amounts of data before processing them in GPU instances with Keras or TensorFlow. sparktf is now available on CRAN and can be installed as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;sparktf&quot;</span>)</code></pre>
<p>You can simply preprocess data in Spark and write it as TensorFlow records using spark_write_tf():</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparktf)
<span class="kw">library</span>(sparklyr)

sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>)

<span class="kw">copy_to</span>(sc, iris) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_string_indexer_model</span>(
    <span class="st">&quot;Species&quot;</span>, <span class="st">&quot;label&quot;</span>,
    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;setosa&quot;</span>, <span class="st">&quot;versicolor&quot;</span>, <span class="st">&quot;virginica&quot;</span>)
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spark_write_tfrecord</span>(<span class="dt">path =</span> <span class="st">&quot;tfrecord&quot;</span>)

<span class="kw">spark_disconnect</span>(sc)</code></pre>
</div>
<div id="genomics" class="section level2">
<h2><span class="header-section-number">10.6</span> Genomics</h2>
<p>VariantSpark is a framework based on scala and spark to analyze genome datasets. It is being developed by CSIRO Bioinformatics team in Australia. VariantSpark was tested on datasets with 3000 samples each one containing 80 million features in either unsupervised clustering approaches and supervised applications, like classification and regression.</p>
<p>The genome datasets are usually writing in Variant Call Format (VCF), a specific text file format used in bioinformatics for storing gene sequence variations. So, VariantSaprk is a great tool because it is able to read VCF files, run analyses and give us the output in a spark data frame.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;sparktf&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)
<span class="kw">library</span>(variantspark)

sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>)
vsc &lt;-<span class="st"> </span><span class="kw">vs_connect</span>(sc)</code></pre>
<p>We can start by loading a VCF file,</p>
<pre><code>hipster_vcf &lt;- vs_read_vcf(vsc, &quot;inst/extdata/hipster.vcf.bz2&quot;)</code></pre>
<p>VariantSpark uses Random Forest to assign an “Importance” score to each tested variant reflecting its association to the interest phenotype. A variant with higher “Importance” score implies it is more strongly associated with the phenotype of interest.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># calculate the &quot;Importance&quot;</span>
importance &lt;-<span class="st"> </span><span class="kw">vs_importance_analysis</span>(vsc, hipster_vcf, labels, <span class="dt">n_trees =</span> <span class="dv">100</span>)

<span class="co"># transform the output in a tibble spark</span>
importance_tbl &lt;-<span class="st"> </span><span class="kw">importance_tbl</span>(importance) </code></pre>
<p>You can use dplyr and ggplot2 to transform the output and plot!</p>
<pre class="sourceCode r"><code class="sourceCode r">importance_df &lt;-<span class="st"> </span>importance_tbl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="op">-</span>importance) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">head</span>(<span class="dv">20</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">collect</span>()

<span class="co"># importance barplot</span>
<span class="kw">ggplot</span>(importance_df) <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> variable, <span class="dt">y =</span> importance) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&#39;identity&#39;</span>) <span class="op">+</span><span class="st">          </span>
<span class="st">  </span><span class="kw">scale_x_discrete</span>(<span class="dt">limits =</span> importance_df[<span class="kw">order</span>(importance_df<span class="op">$</span>importance), <span class="dv">1</span>]<span class="op">$</span>variable) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre>
</div>
<div id="spatial" class="section level2">
<h2><span class="header-section-number">10.7</span> Spatial</h2>
<p><a href="https://github.com/harryprince/geospark">geospark</a> enables distributed geospatial computing with spatial index on spark in production and keeps a <a href="https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf"><code>dplyr</code></a> and <a href="https://github.com/rstudio/cheatsheets/raw/master/sf.pdf"><code>sf</code></a> style grammar.</p>
<p>You can install <code>geospark</code> from GitHub as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;remotes&quot;</span>)
remotes<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;harryprince/geospark&quot;</span>)</code></pre>
<p>In this example we will join spatial data using <code>quadrad tree indexing</code>. First, we will initialize the geospark extension and connect to Spark using sparklyr:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)
<span class="kw">library</span>(geospark)

conf &lt;-<span class="st"> </span><span class="kw">spark_config</span>()
sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">config =</span> conf)
<span class="kw">register_gis</span>(sc)</code></pre>
<p>Next we will load some spatial dataset containing as polygons and points.</p>
<pre class="sourceCode r"><code class="sourceCode r">polygons &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="kw">system.file</span>(<span class="dt">package=</span><span class="st">&quot;geospark&quot;</span>,<span class="st">&quot;examples/polygons.txt&quot;</span>), <span class="dt">sep=</span><span class="st">&quot;|&quot;</span>, <span class="dt">col.names=</span><span class="kw">c</span>(<span class="st">&quot;area&quot;</span>,<span class="st">&quot;geom&quot;</span>))
points &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="kw">system.file</span>(<span class="dt">package=</span><span class="st">&quot;geospark&quot;</span>,<span class="st">&quot;examples/points.txt&quot;</span>), <span class="dt">sep=</span><span class="st">&quot;|&quot;</span>, <span class="dt">col.names=</span><span class="kw">c</span>(<span class="st">&quot;city&quot;</span>,<span class="st">&quot;state&quot;</span>,<span class="st">&quot;geom&quot;</span>))

polygons_wkt &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, polygons)
points_wkt &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, points)</code></pre>
<p>There are various spatial operations defined in <code>geospark</code>, which Figure <a href="extensions.html#fig:extensions-geospark-operations">10.5</a> describes.</p>
<div class="figure" style="text-align: center"><span id="fig:extensions-geospark-operations"></span>
<img src="images/extensions-geospark-operations.png" alt="Spatial operations available in geospark." width="400" />
<p class="caption">
FIGURE 10.5: Spatial operations available in geospark.
</p>
</div>
<p>The following examples makes use of <code>st_contains()</code> to find the polygons that contain the given points.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
polygons_wkt &lt;-<span class="st"> </span><span class="kw">mutate</span>(polygons_wkt, <span class="dt">y =</span> <span class="kw">st_geomfromwkt</span>(geom))
points_wkt &lt;-<span class="st"> </span><span class="kw">mutate</span>(points_wkt, <span class="dt">x =</span> <span class="kw">st_geomfromwkt</span>(geom))

sc_res &lt;-<span class="st"> </span><span class="kw">st_join</span>(polygons_wkt,
                  points_wkt,
                  <span class="dt">join =</span> <span class="kw">sql</span>(<span class="st">&quot;st_contains(y,x)&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(area, state) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">cnt =</span> <span class="kw">n</span>()) 
  
sc_res <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">head</span>()</code></pre>
<pre><code>    # Source: spark&lt;?&gt; [?? x 3]
    # Groups: area
      area            state   cnt
      &lt;chr&gt;           &lt;chr&gt; &lt;dbl&gt;
    1 texas area      TX       10
    2 dakota area     SD        1
    3 dakota area     ND       10
    4 california area CA       10
    5 new york area   NY        9</code></pre>
<p>The final result can be present by leaflet, you would need to install the <code>sf</code>, <code>leaflet</code> and <code>colormap</code> packages for the following example to work:</p>
<pre class="sourceCode r"><code class="sourceCode r">Idx_df =<span class="st"> </span><span class="kw">collect</span>(sc_res) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="kw">right_join</span>(polygons,<span class="dt">by =</span> (<span class="kw">c</span>(<span class="st">&quot;area&quot;</span>=<span class="st">&quot;area&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>sf<span class="op">::</span><span class="kw">st_as_sf</span>(<span class="dt">wkt=</span><span class="st">&quot;geom&quot;</span>)

Idx_df <span class="op">%&gt;%</span><span class="st"> </span>
leaflet<span class="op">::</span><span class="kw">leaflet</span>() <span class="op">%&gt;%</span><span class="st"> </span>
leaflet<span class="op">::</span><span class="kw">addTiles</span>() <span class="op">%&gt;%</span><span class="st"> </span>
leaflet<span class="op">::</span><span class="kw">addPolygons</span>(<span class="dt">popup =</span> <span class="op">~</span><span class="kw">as.character</span>(cnt),<span class="dt">color=</span><span class="op">~</span>colormap<span class="op">::</span><span class="kw">colormap_pal</span>()(cnt))</code></pre>
<p>see more <a href="https://github.com/harryprince/geospark#spatial-join">spatial join</a>:</p>
</div>
<div id="troubleshooting" class="section level2">
<h2><span class="header-section-number">10.8</span> Troubleshooting</h2>
<p><a href="http://ant.apache.org/ivy/">Apache IVY</a> is a popular dependency manager focusing on flexibility and simplicity, which happens to be used by Apache Spark while installing extensions. When connection fails while using an extension, consider clearing your <a href="http://ant.apache.org/ivy/history/2.0.0/settings/caches.html">IVY Cache</a> by running:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">unlink</span>(<span class="st">&quot;~/.ivy2/cache&quot;</span>, <span class="dt">recursive =</span> <span class="ot">TRUE</span>)</code></pre>
</div>
<div id="recap-5" class="section level2">
<h2><span class="header-section-number">10.9</span> Recap</h2>

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-extensions-sparklyr-cran">
<p>“CRAN - Package Sparklyr.” 2019. <a href="https://cran.r-project.org/web/packages/sparklyr/index.html">https://cran.r-project.org/web/packages/sparklyr/index.html</a>.</p>
</div>
<div id="ref-extensions-higgs-challenge">
<p>“Higgs Boson Machine Learning Challenge.” 2019. <a href="https://www.kaggle.com/c/higgs-boson">https://www.kaggle.com/c/higgs-boson</a>.</p>
</div>
<div id="ref-extensions-practical-h2o">
<p>Cook, Darren. 2016. <em>Practical Machine Learning with H2o: Powerful, Scalable Techniques for Deep Learning and Ai</em>. " O’Reilly Media, Inc.".</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tuning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="distributed.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
