<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>The R in Spark: Learning Apache Spark with R</title>
  <meta name="description" content="A book to learn Apache Spark with R using the sparklyr R package.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="The R in Spark: Learning Apache Spark with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A book to learn Apache Spark with R using the sparklyr R package." />
  <meta name="github-repo" content="javierluraschi/the-r-in-spark" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="The R in Spark: Learning Apache Spark with R" />
  
  <meta name="twitter:description" content="A book to learn Apache Spark with R using the sparklyr R package." />
  



<meta name="date" content="2019-02-04">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="clusters.html">
<link rel="next" href="data.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/dagre-0.0.1/dagre.min.js"></script>
<script src="libs/lodash-3.7.0/lodash.js"></script>
<script src="libs/nomnoml-0.2.0/nomnoml.js"></script>
<script src="libs/nomnoml-binding-0.1.0/nomnoml.js"></script>
<script src="libs/r2d3-render-0.1.0/r2d3-render.js"></script>
<script src="libs/webcomponents-2.0.0/webcomponents.js"></script>
<script src="libs/r2d3-binding-0.2.3/r2d3.js"></script>
<script src="libs/d3v5-5.0.0/d3.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119986300-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119986300-1');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Learning Apache Spark with R</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#authors"><i class="fa fa-check"></i>Authors</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#formatting"><i class="fa fa-check"></i>Formatting</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#intro-background"><i class="fa fa-check"></i><b>1.1</b> Background</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#intro-hadoop"><i class="fa fa-check"></i><b>1.2</b> Hadoop</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#intro-spark"><i class="fa fa-check"></i><b>1.3</b> Spark</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#intro-r"><i class="fa fa-check"></i><b>1.4</b> R</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#intro-sparklyr"><i class="fa fa-check"></i><b>1.5</b> sparklyr</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#intro-recap"><i class="fa fa-check"></i><b>1.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="starting.html"><a href="starting.html"><i class="fa fa-check"></i><b>2</b> Getting Started</a><ul>
<li class="chapter" data-level="2.1" data-path="starting.html"><a href="starting.html#starting-prerequisites"><i class="fa fa-check"></i><b>2.1</b> Prerequisites</a></li>
<li class="chapter" data-level="2.2" data-path="starting.html"><a href="starting.html#starting-install-sparklyr"><i class="fa fa-check"></i><b>2.2</b> Installing sparklyr</a></li>
<li class="chapter" data-level="2.3" data-path="starting.html"><a href="starting.html#starting-installing-spark"><i class="fa fa-check"></i><b>2.3</b> Installing Spark</a></li>
<li class="chapter" data-level="2.4" data-path="starting.html"><a href="starting.html#starting-connect-to-spark"><i class="fa fa-check"></i><b>2.4</b> Connecting to Spark</a></li>
<li class="chapter" data-level="2.5" data-path="starting.html"><a href="starting.html#starting-sparklyr-hello-world"><i class="fa fa-check"></i><b>2.5</b> Using Spark</a><ul>
<li class="chapter" data-level="2.5.1" data-path="starting.html"><a href="starting.html#starting-spark-web-interface"><i class="fa fa-check"></i><b>2.5.1</b> Web Interface</a></li>
<li class="chapter" data-level="2.5.2" data-path="starting.html"><a href="starting.html#starting-logs"><i class="fa fa-check"></i><b>2.5.2</b> Logs</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="starting.html"><a href="starting.html#starting-disconnecting"><i class="fa fa-check"></i><b>2.6</b> Disconnecting</a></li>
<li class="chapter" data-level="2.7" data-path="starting.html"><a href="starting.html#starting-using-spark-from-rstudio"><i class="fa fa-check"></i><b>2.7</b> Using RStudio</a></li>
<li class="chapter" data-level="2.8" data-path="starting.html"><a href="starting.html#starting-resources"><i class="fa fa-check"></i><b>2.8</b> Resources</a></li>
<li class="chapter" data-level="2.9" data-path="starting.html"><a href="starting.html#starting-recap"><i class="fa fa-check"></i><b>2.9</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis.html"><a href="analysis.html"><i class="fa fa-check"></i><b>3</b> Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="analysis.html"><a href="analysis.html#background"><i class="fa fa-check"></i><b>3.1</b> Background</a><ul>
<li class="chapter" data-level="3.1.1" data-path="analysis.html"><a href="analysis.html#working-with-big-data"><i class="fa fa-check"></i><b>3.1.1</b> Working with Big Data</a></li>
<li class="chapter" data-level="3.1.2" data-path="analysis.html"><a href="analysis.html#avoid-running-r-inside-spark"><i class="fa fa-check"></i><b>3.1.2</b> Avoid running R inside Spark</a></li>
<li class="chapter" data-level="3.1.3" data-path="analysis.html"><a href="analysis.html#r-under-the-hood"><i class="fa fa-check"></i><b>3.1.3</b> R, under the hood</a></li>
<li class="chapter" data-level="3.1.4" data-path="analysis.html"><a href="analysis.html#use-r-as-an-interface-to-spark"><i class="fa fa-check"></i><b>3.1.4</b> Use R as an interface to Spark</a></li>
<li class="chapter" data-level="3.1.5" data-path="analysis.html"><a href="analysis.html#using-sparklyr-for-analysis"><i class="fa fa-check"></i><b>3.1.5</b> Using <code>sparklyr</code> for analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="analysis.html"><a href="analysis.html#basics"><i class="fa fa-check"></i><b>3.2</b> Basics</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="modeling.html"><a href="modeling.html"><i class="fa fa-check"></i><b>4</b> Modeling</a><ul>
<li class="chapter" data-level="4.1" data-path="modeling.html"><a href="modeling.html#overview"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="modeling.html"><a href="modeling.html#supervised"><i class="fa fa-check"></i><b>4.2</b> Supervised</a></li>
<li class="chapter" data-level="4.3" data-path="modeling.html"><a href="modeling.html#unsupervised"><i class="fa fa-check"></i><b>4.3</b> Unsupervised</a><ul>
<li class="chapter" data-level="4.3.1" data-path="modeling.html"><a href="modeling.html#k-means-clustering"><i class="fa fa-check"></i><b>4.3.1</b> K-Means Clustering</a></li>
<li class="chapter" data-level="4.3.2" data-path="modeling.html"><a href="modeling.html#gaussian-mixture-clustering"><i class="fa fa-check"></i><b>4.3.2</b> Gaussian Mixture Clustering</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="modeling.html"><a href="modeling.html#broom"><i class="fa fa-check"></i><b>4.4</b> Broom</a></li>
<li class="chapter" data-level="4.5" data-path="modeling.html"><a href="modeling.html#pipelines"><i class="fa fa-check"></i><b>4.5</b> Pipelines</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="clusters.html"><a href="clusters.html"><i class="fa fa-check"></i><b>5</b> Clusters</a><ul>
<li class="chapter" data-level="5.1" data-path="clusters.html"><a href="clusters.html#clusters-overview"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="clusters.html"><a href="clusters.html#clusters-manager"><i class="fa fa-check"></i><b>5.2</b> Managers</a><ul>
<li class="chapter" data-level="5.2.1" data-path="clusters.html"><a href="clusters.html#clusters-standalone"><i class="fa fa-check"></i><b>5.2.1</b> Standalone</a></li>
<li class="chapter" data-level="5.2.2" data-path="clusters.html"><a href="clusters.html#yarn"><i class="fa fa-check"></i><b>5.2.2</b> Yarn</a></li>
<li class="chapter" data-level="5.2.3" data-path="clusters.html"><a href="clusters.html#mesos"><i class="fa fa-check"></i><b>5.2.3</b> Mesos</a></li>
<li class="chapter" data-level="5.2.4" data-path="clusters.html"><a href="clusters.html#kubernetes"><i class="fa fa-check"></i><b>5.2.4</b> Kubernetes</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="clusters.html"><a href="clusters.html#on-premise"><i class="fa fa-check"></i><b>5.3</b> On-Premise</a><ul>
<li class="chapter" data-level="5.3.1" data-path="clusters.html"><a href="clusters.html#cloudera"><i class="fa fa-check"></i><b>5.3.1</b> Cloudera</a></li>
<li class="chapter" data-level="5.3.2" data-path="clusters.html"><a href="clusters.html#hortonworks"><i class="fa fa-check"></i><b>5.3.2</b> Hortonworks</a></li>
<li class="chapter" data-level="5.3.3" data-path="clusters.html"><a href="clusters.html#mapr"><i class="fa fa-check"></i><b>5.3.3</b> MapR</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="clusters.html"><a href="clusters.html#cloud"><i class="fa fa-check"></i><b>5.4</b> Cloud</a><ul>
<li class="chapter" data-level="5.4.1" data-path="clusters.html"><a href="clusters.html#clusters-amazon-emr"><i class="fa fa-check"></i><b>5.4.1</b> Amazon</a></li>
<li class="chapter" data-level="5.4.2" data-path="clusters.html"><a href="clusters.html#databricks"><i class="fa fa-check"></i><b>5.4.2</b> Databricks</a></li>
<li class="chapter" data-level="5.4.3" data-path="clusters.html"><a href="clusters.html#google"><i class="fa fa-check"></i><b>5.4.3</b> Google</a></li>
<li class="chapter" data-level="5.4.4" data-path="clusters.html"><a href="clusters.html#ibm"><i class="fa fa-check"></i><b>5.4.4</b> IBM</a></li>
<li class="chapter" data-level="5.4.5" data-path="clusters.html"><a href="clusters.html#microsoft"><i class="fa fa-check"></i><b>5.4.5</b> Microsoft</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="clusters.html"><a href="clusters.html#tools"><i class="fa fa-check"></i><b>5.5</b> Tools</a><ul>
<li class="chapter" data-level="5.5.1" data-path="clusters.html"><a href="clusters.html#rstudio"><i class="fa fa-check"></i><b>5.5.1</b> RStudio</a></li>
<li class="chapter" data-level="5.5.2" data-path="clusters.html"><a href="clusters.html#jupyter"><i class="fa fa-check"></i><b>5.5.2</b> Jupyter</a></li>
<li class="chapter" data-level="5.5.3" data-path="clusters.html"><a href="clusters.html#clusters-livy"><i class="fa fa-check"></i><b>5.5.3</b> Livy</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="clusters.html"><a href="clusters.html#recap"><i class="fa fa-check"></i><b>5.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="connections.html"><a href="connections.html"><i class="fa fa-check"></i><b>6</b> Connections</a><ul>
<li class="chapter" data-level="6.1" data-path="connections.html"><a href="connections.html#connections-overview"><i class="fa fa-check"></i><b>6.1</b> Overview</a><ul>
<li class="chapter" data-level="6.1.1" data-path="connections.html"><a href="connections.html#connections-spark-edge-nodes"><i class="fa fa-check"></i><b>6.1.1</b> Edge Nodes</a></li>
<li class="chapter" data-level="6.1.2" data-path="connections.html"><a href="connections.html#connections-spark-home"><i class="fa fa-check"></i><b>6.1.2</b> Spark Home</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="connections.html"><a href="connections.html#connections-local"><i class="fa fa-check"></i><b>6.2</b> Local</a></li>
<li class="chapter" data-level="6.3" data-path="connections.html"><a href="connections.html#connections-standalone"><i class="fa fa-check"></i><b>6.3</b> Standalone</a></li>
<li class="chapter" data-level="6.4" data-path="connections.html"><a href="connections.html#connections-yarn"><i class="fa fa-check"></i><b>6.4</b> Yarn</a><ul>
<li class="chapter" data-level="6.4.1" data-path="connections.html"><a href="connections.html#connections-yarn-client"><i class="fa fa-check"></i><b>6.4.1</b> Yarn Client</a></li>
<li class="chapter" data-level="6.4.2" data-path="connections.html"><a href="connections.html#connections-yarn-cluster"><i class="fa fa-check"></i><b>6.4.2</b> Yarn Cluster</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="connections.html"><a href="connections.html#connections-livy"><i class="fa fa-check"></i><b>6.5</b> Livy</a></li>
<li class="chapter" data-level="6.6" data-path="connections.html"><a href="connections.html#connections-mesos"><i class="fa fa-check"></i><b>6.6</b> Mesos</a></li>
<li class="chapter" data-level="6.7" data-path="connections.html"><a href="connections.html#connections-kubernetes"><i class="fa fa-check"></i><b>6.7</b> Kubernetes</a></li>
<li class="chapter" data-level="6.8" data-path="connections.html"><a href="connections.html#cloud-1"><i class="fa fa-check"></i><b>6.8</b> Cloud</a></li>
<li class="chapter" data-level="6.9" data-path="connections.html"><a href="connections.html#multiple"><i class="fa fa-check"></i><b>6.9</b> Multiple</a></li>
<li class="chapter" data-level="6.10" data-path="connections.html"><a href="connections.html#connections-troubleshooting"><i class="fa fa-check"></i><b>6.10</b> Troubleshooting</a><ul>
<li class="chapter" data-level="6.10.1" data-path="connections.html"><a href="connections.html#logging"><i class="fa fa-check"></i><b>6.10.1</b> Logging</a></li>
<li class="chapter" data-level="6.10.2" data-path="connections.html"><a href="connections.html#troubleshoot-spark-submit"><i class="fa fa-check"></i><b>6.10.2</b> Spark Submit</a></li>
<li class="chapter" data-level="6.10.3" data-path="connections.html"><a href="connections.html#windows"><i class="fa fa-check"></i><b>6.10.3</b> Windows</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="connections.html"><a href="connections.html#recap-1"><i class="fa fa-check"></i><b>6.11</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>7</b> Data</a><ul>
<li class="chapter" data-level="7.1" data-path="data.html"><a href="data.html#overview-1"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="data.html"><a href="data.html#data-frames"><i class="fa fa-check"></i><b>7.2</b> Data Frames</a><ul>
<li class="chapter" data-level="7.2.1" data-path="data.html"><a href="data.html#data-sdf-functions"><i class="fa fa-check"></i><b>7.2.1</b> Functions</a></li>
<li class="chapter" data-level="7.2.2" data-path="data.html"><a href="data.html#pivoting"><i class="fa fa-check"></i><b>7.2.2</b> Pivoting</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="data.html"><a href="data.html#formats"><i class="fa fa-check"></i><b>7.3</b> Formats</a></li>
<li class="chapter" data-level="7.4" data-path="data.html"><a href="data.html#data-types"><i class="fa fa-check"></i><b>7.4</b> Data Types</a><ul>
<li class="chapter" data-level="7.4.1" data-path="data.html"><a href="data.html#dates"><i class="fa fa-check"></i><b>7.4.1</b> Dates</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="data.html"><a href="data.html#sources"><i class="fa fa-check"></i><b>7.5</b> Sources</a><ul>
<li class="chapter" data-level="7.5.1" data-path="data.html"><a href="data.html#amazon-s3"><i class="fa fa-check"></i><b>7.5.1</b> Amazon S3</a></li>
<li class="chapter" data-level="7.5.2" data-path="data.html"><a href="data.html#azure-storage"><i class="fa fa-check"></i><b>7.5.2</b> Azure Storage</a></li>
<li class="chapter" data-level="7.5.3" data-path="data.html"><a href="data.html#cassandra"><i class="fa fa-check"></i><b>7.5.3</b> Cassandra</a></li>
<li class="chapter" data-level="7.5.4" data-path="data.html"><a href="data.html#databases"><i class="fa fa-check"></i><b>7.5.4</b> Databases</a></li>
<li class="chapter" data-level="7.5.5" data-path="data.html"><a href="data.html#hbase"><i class="fa fa-check"></i><b>7.5.5</b> HBase</a></li>
<li class="chapter" data-level="7.5.6" data-path="data.html"><a href="data.html#nested-data"><i class="fa fa-check"></i><b>7.5.6</b> Nested Data</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="data.html"><a href="data.html#troubleshooting"><i class="fa fa-check"></i><b>7.6</b> Troubleshooting</a><ul>
<li class="chapter" data-level="7.6.1" data-path="data.html"><a href="data.html#troubleshoot-csvs"><i class="fa fa-check"></i><b>7.6.1</b> Troubleshoot CSVs</a></li>
<li class="chapter" data-level="7.6.2" data-path="data.html"><a href="data.html#column-names"><i class="fa fa-check"></i><b>7.6.2</b> Column Names</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="data.html"><a href="data.html#recap-2"><i class="fa fa-check"></i><b>7.7</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tuning.html"><a href="tuning.html"><i class="fa fa-check"></i><b>8</b> Tuning</a><ul>
<li class="chapter" data-level="8.1" data-path="tuning.html"><a href="tuning.html#overview-2"><i class="fa fa-check"></i><b>8.1</b> Overview</a><ul>
<li class="chapter" data-level="8.1.1" data-path="tuning.html"><a href="tuning.html#tuning-graph-visualization"><i class="fa fa-check"></i><b>8.1.1</b> Graph Visualization</a></li>
<li class="chapter" data-level="8.1.2" data-path="tuning.html"><a href="tuning.html#tuning-event-timeline"><i class="fa fa-check"></i><b>8.1.2</b> Event Timeline</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="tuning.html"><a href="tuning.html#tuning-configuring"><i class="fa fa-check"></i><b>8.2</b> Configuring</a><ul>
<li class="chapter" data-level="8.2.1" data-path="tuning.html"><a href="tuning.html#connect-settings"><i class="fa fa-check"></i><b>8.2.1</b> Connect Settings</a></li>
<li class="chapter" data-level="8.2.2" data-path="tuning.html"><a href="tuning.html#submit-settings"><i class="fa fa-check"></i><b>8.2.2</b> Submit Settings</a></li>
<li class="chapter" data-level="8.2.3" data-path="tuning.html"><a href="tuning.html#runtime-settings"><i class="fa fa-check"></i><b>8.2.3</b> Runtime Settings</a></li>
<li class="chapter" data-level="8.2.4" data-path="tuning.html"><a href="tuning.html#sparklyr-settings"><i class="fa fa-check"></i><b>8.2.4</b> sparklyr Settings</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="tuning.html"><a href="tuning.html#tuning-partitioning"><i class="fa fa-check"></i><b>8.3</b> Partitioning</a><ul>
<li class="chapter" data-level="8.3.1" data-path="tuning.html"><a href="tuning.html#implicit"><i class="fa fa-check"></i><b>8.3.1</b> Implicit</a></li>
<li class="chapter" data-level="8.3.2" data-path="tuning.html"><a href="tuning.html#explicit"><i class="fa fa-check"></i><b>8.3.2</b> Explicit</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="tuning.html"><a href="tuning.html#tuning-caching"><i class="fa fa-check"></i><b>8.4</b> Caching</a><ul>
<li class="chapter" data-level="8.4.1" data-path="tuning.html"><a href="tuning.html#checkpointing"><i class="fa fa-check"></i><b>8.4.1</b> Checkpointing</a></li>
<li class="chapter" data-level="8.4.2" data-path="tuning.html"><a href="tuning.html#tuning-memory"><i class="fa fa-check"></i><b>8.4.2</b> Memory</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="tuning.html"><a href="tuning.html#tuning-shuffling"><i class="fa fa-check"></i><b>8.5</b> Shuffling</a></li>
<li class="chapter" data-level="8.6" data-path="tuning.html"><a href="tuning.html#tuning-serialization"><i class="fa fa-check"></i><b>8.6</b> Serialization</a></li>
<li class="chapter" data-level="8.7" data-path="tuning.html"><a href="tuning.html#configuration-files"><i class="fa fa-check"></i><b>8.7</b> Configuration Files</a></li>
<li class="chapter" data-level="8.8" data-path="tuning.html"><a href="tuning.html#recap-3"><i class="fa fa-check"></i><b>8.8</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="extensions.html"><a href="extensions.html"><i class="fa fa-check"></i><b>9</b> Extensions</a><ul>
<li class="chapter" data-level="9.1" data-path="extensions.html"><a href="extensions.html#rsparkling"><i class="fa fa-check"></i><b>9.1</b> RSparkling</a><ul>
<li class="chapter" data-level="9.1.1" data-path="extensions.html"><a href="extensions.html#troubleshooting-1"><i class="fa fa-check"></i><b>9.1.1</b> Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="extensions.html"><a href="extensions.html#graphframes"><i class="fa fa-check"></i><b>9.2</b> GraphFrames</a></li>
<li class="chapter" data-level="9.3" data-path="extensions.html"><a href="extensions.html#mleap"><i class="fa fa-check"></i><b>9.3</b> Mleap</a></li>
<li class="chapter" data-level="9.4" data-path="extensions.html"><a href="extensions.html#extensions-nested-data"><i class="fa fa-check"></i><b>9.4</b> Nested Data</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="distributed.html"><a href="distributed.html"><i class="fa fa-check"></i><b>10</b> Distributed R</a><ul>
<li class="chapter" data-level="10.1" data-path="distributed.html"><a href="distributed.html#overview-3"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="distributed.html"><a href="distributed.html#use-cases"><i class="fa fa-check"></i><b>10.2</b> Use Cases</a><ul>
<li class="chapter" data-level="10.2.1" data-path="distributed.html"><a href="distributed.html#custom-parsers"><i class="fa fa-check"></i><b>10.2.1</b> Custom Parsers</a></li>
<li class="chapter" data-level="10.2.2" data-path="distributed.html"><a href="distributed.html#partitioned-modeling"><i class="fa fa-check"></i><b>10.2.2</b> Partitioned Modeling</a></li>
<li class="chapter" data-level="10.2.3" data-path="distributed.html"><a href="distributed.html#grid-search"><i class="fa fa-check"></i><b>10.2.3</b> Grid Search</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="distributed.html"><a href="distributed.html#partitions"><i class="fa fa-check"></i><b>10.3</b> Partitions</a></li>
<li class="chapter" data-level="10.4" data-path="distributed.html"><a href="distributed.html#grouping"><i class="fa fa-check"></i><b>10.4</b> Grouping</a></li>
<li class="chapter" data-level="10.5" data-path="distributed.html"><a href="distributed.html#columns"><i class="fa fa-check"></i><b>10.5</b> Columns</a></li>
<li class="chapter" data-level="10.6" data-path="distributed.html"><a href="distributed.html#context"><i class="fa fa-check"></i><b>10.6</b> Context</a></li>
<li class="chapter" data-level="10.7" data-path="distributed.html"><a href="distributed.html#packages"><i class="fa fa-check"></i><b>10.7</b> Packages</a></li>
<li class="chapter" data-level="10.8" data-path="distributed.html"><a href="distributed.html#requirements"><i class="fa fa-check"></i><b>10.8</b> Requirements</a></li>
<li class="chapter" data-level="10.9" data-path="distributed.html"><a href="distributed.html#limitations"><i class="fa fa-check"></i><b>10.9</b> Limitations</a><ul>
<li class="chapter" data-level="10.9.1" data-path="distributed.html"><a href="distributed.html#functions"><i class="fa fa-check"></i><b>10.9.1</b> Functions</a></li>
<li class="chapter" data-level="10.9.2" data-path="distributed.html"><a href="distributed.html#livy"><i class="fa fa-check"></i><b>10.9.2</b> Livy</a></li>
<li class="chapter" data-level="10.9.3" data-path="distributed.html"><a href="distributed.html#grouping-1"><i class="fa fa-check"></i><b>10.9.3</b> Grouping</a></li>
<li class="chapter" data-level="10.9.4" data-path="distributed.html"><a href="distributed.html#packages-1"><i class="fa fa-check"></i><b>10.9.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="distributed.html"><a href="distributed.html#troubleshooting-2"><i class="fa fa-check"></i><b>10.10</b> Troubleshooting</a><ul>
<li class="chapter" data-level="10.10.1" data-path="distributed.html"><a href="distributed.html#worker-logs"><i class="fa fa-check"></i><b>10.10.1</b> Worker Logs</a></li>
<li class="chapter" data-level="10.10.2" data-path="distributed.html"><a href="distributed.html#partition-errors"><i class="fa fa-check"></i><b>10.10.2</b> Partition Errors</a></li>
<li class="chapter" data-level="10.10.3" data-path="distributed.html"><a href="distributed.html#debugging-workers"><i class="fa fa-check"></i><b>10.10.3</b> Debugging Workers</a></li>
</ul></li>
<li class="chapter" data-level="10.11" data-path="distributed.html"><a href="distributed.html#clusters-1"><i class="fa fa-check"></i><b>10.11</b> Clusters</a></li>
<li class="chapter" data-level="10.12" data-path="distributed.html"><a href="distributed.html#apache-arrow"><i class="fa fa-check"></i><b>10.12</b> Apache Arrow</a></li>
<li class="chapter" data-level="10.13" data-path="distributed.html"><a href="distributed.html#recap-4"><i class="fa fa-check"></i><b>10.13</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="streaming.html"><a href="streaming.html"><i class="fa fa-check"></i><b>11</b> Streaming</a><ul>
<li class="chapter" data-level="11.1" data-path="streaming.html"><a href="streaming.html#overview-4"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="streaming.html"><a href="streaming.html#streaming-treansform"><i class="fa fa-check"></i><b>11.2</b> Transformations</a><ul>
<li class="chapter" data-level="11.2.1" data-path="streaming.html"><a href="streaming.html#streams-dplyr"><i class="fa fa-check"></i><b>11.2.1</b> dplyr</a></li>
<li class="chapter" data-level="11.2.2" data-path="streaming.html"><a href="streaming.html#streams-pipelines"><i class="fa fa-check"></i><b>11.2.2</b> Pipelines</a></li>
<li class="chapter" data-level="11.2.3" data-path="streaming.html"><a href="streaming.html#streams-r"><i class="fa fa-check"></i><b>11.2.3</b> R Code</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="streaming.html"><a href="streaming.html#shiny"><i class="fa fa-check"></i><b>11.3</b> Shiny</a></li>
<li class="chapter" data-level="11.4" data-path="streaming.html"><a href="streaming.html#formats-1"><i class="fa fa-check"></i><b>11.4</b> Formats</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="contributing.html"><a href="contributing.html"><i class="fa fa-check"></i><b>12</b> Contributing</a><ul>
<li class="chapter" data-level="12.1" data-path="contributing.html"><a href="contributing.html#overview-5"><i class="fa fa-check"></i><b>12.1</b> Overview</a></li>
<li class="chapter" data-level="12.2" data-path="contributing.html"><a href="contributing.html#contributing-r-extension"><i class="fa fa-check"></i><b>12.2</b> R Extensions</a></li>
<li class="chapter" data-level="12.3" data-path="contributing.html"><a href="contributing.html#scala-extensions"><i class="fa fa-check"></i><b>12.3</b> Scala Extensions</a><ul>
<li class="chapter" data-level="12.3.1" data-path="contributing.html"><a href="contributing.html#scala-extension-prereq"><i class="fa fa-check"></i><b>12.3.1</b> Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="contributing.html"><a href="contributing.html#spark-extensions"><i class="fa fa-check"></i><b>12.4</b> Spark Extensions</a></li>
<li class="chapter" data-level="12.5" data-path="contributing.html"><a href="contributing.html#r-packages"><i class="fa fa-check"></i><b>12.5</b> R Packages</a><ul>
<li class="chapter" data-level="12.5.1" data-path="contributing.html"><a href="contributing.html#rstudio-projects"><i class="fa fa-check"></i><b>12.5.1</b> RStudio Projects</a></li>
<li class="chapter" data-level="12.5.2" data-path="contributing.html"><a href="contributing.html#troubleshooting-3"><i class="fa fa-check"></i><b>12.5.2</b> Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="contributing.html"><a href="contributing.html#contributing-sparklyr"><i class="fa fa-check"></i><b>12.6</b> sparklyr</a><ul>
<li class="chapter" data-level="12.6.1" data-path="contributing.html"><a href="contributing.html#compiling"><i class="fa fa-check"></i><b>12.6.1</b> Compiling</a></li>
<li class="chapter" data-level="12.6.2" data-path="contributing.html"><a href="contributing.html#serialization"><i class="fa fa-check"></i><b>12.6.2</b> Serialization</a></li>
<li class="chapter" data-level="12.6.3" data-path="contributing.html"><a href="contributing.html#invocations"><i class="fa fa-check"></i><b>12.6.3</b> Invocations</a></li>
<li class="chapter" data-level="12.6.4" data-path="contributing.html"><a href="contributing.html#r-packages-1"><i class="fa fa-check"></i><b>12.6.4</b> R Packages</a></li>
<li class="chapter" data-level="12.6.5" data-path="contributing.html"><a href="contributing.html#connections-1"><i class="fa fa-check"></i><b>12.6.5</b> Connections</a></li>
<li class="chapter" data-level="12.6.6" data-path="contributing.html"><a href="contributing.html#distributed-r"><i class="fa fa-check"></i><b>12.6.6</b> Distributed R</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="contributing.html"><a href="contributing.html#recap-5"><i class="fa fa-check"></i><b>12.7</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="12.8" data-path="appendix.html"><a href="appendix.html#appendix-prerequisites"><i class="fa fa-check"></i><b>12.8</b> Prerequisites</a><ul>
<li class="chapter" data-level="12.8.1" data-path="appendix.html"><a href="appendix.html#appendix-install-r"><i class="fa fa-check"></i><b>12.8.1</b> Installing R</a></li>
<li class="chapter" data-level="12.8.2" data-path="appendix.html"><a href="appendix.html#appendix-install-java"><i class="fa fa-check"></i><b>12.8.2</b> Installing Java</a></li>
<li class="chapter" data-level="12.8.3" data-path="appendix.html"><a href="appendix.html#appendix-install-rstudio"><i class="fa fa-check"></i><b>12.8.3</b> Installing RStudio</a></li>
<li class="chapter" data-level="12.8.4" data-path="appendix.html"><a href="appendix.html#appendix-using-rstudio"><i class="fa fa-check"></i><b>12.8.4</b> Using RStudio</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="appendix.html"><a href="appendix.html#diagrams"><i class="fa fa-check"></i><b>12.9</b> Diagrams</a><ul>
<li class="chapter" data-level="12.9.1" data-path="appendix.html"><a href="appendix.html#appendix-storage-capacity"><i class="fa fa-check"></i><b>12.9.1</b> Worlds Store Capacity</a></li>
<li class="chapter" data-level="12.9.2" data-path="appendix.html"><a href="appendix.html#appendix-cran-downloads"><i class="fa fa-check"></i><b>12.9.2</b> Daily downloads of CRAN packages</a></li>
<li class="chapter" data-level="12.9.3" data-path="appendix.html"><a href="appendix.html#appendix-cluster-trends"><i class="fa fa-check"></i><b>12.9.3</b> Google trends for mainframes, cloud computing and kubernetes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>13</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The R in Spark: Learning Apache Spark with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="connections" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Connections</h1>
<p>The previous chapter, <a href="clusters.html#clusters">Clusters</a>, presented the major cluster computing paradigms, cluster managers and cluster providers to help you choose the Spark cluster distribution and provider that best suits your needs. In contras, this chapter presents the internal components of a Spark cluster and the how to connect to any cluster running Apache Spark, including but not limitted to, any distribution and provided presented in the previous chapter.</p>
<p>In addition, this chapter provides various troubleshooting connection techniques which I hope you won’t need to use, but if you have to, you can use them as effective techniquest to resolve connectivity issues.</p>
<p>While this chapter might feel a bit dry since, connecting and troubleshooting connections is definetely not the most fun part of large-scale data analysis, it is the first chapter that will introduce the components of a Spark cluster and how they interact, this is often known as the architecture of Apache Spark. This chapter, <a href="data.html#data">Data</a> and <a href="#tunning">Tunning</a> chapter, will provide a detailed view of how Spark works, which will help you move towards becoming an intermediate Spark user that can go beyond analysis to dive into the realm of distributed computing, using Apache Spark.</p>
<div id="connections-overview" class="section level2">
<h2><span class="header-section-number">6.1</span> Overview</h2>
<p>As you know from previous chapters, a cluster is a collection of machines that work together to perform a computation. However, in distributed systems and clusters literature, we often refer to each physical machine as a compute instance, compute node, instance or node. It is helpful to remind this while reading through this chapter and making use of external resources.</p>
<p>In a Spark cluster, there are three types of compute instances that are relevant to Spark: The <strong>driver node</strong>, the <strong>worker nodes</strong> and the <strong>cluster manager</strong>. A cluster manager is a service that allows Spark to be executed in the cluster as described in the previous chapter under the <a href="clusters.html#clusters-manager">cluster managers</a> section. The <strong>driver node</strong> is tasked with delegating work to the worker nodes, but also for aggregating their results and controlling computation flow. For the most part, aggregation happens in the worker nodes; however, even after the nodes aggregate data, it is often the case that the driver node would have to collect the worker’s results. Therefore, the driver node usually has at least, but often much more, compute resources (memory, CPUs, local storage, etc.) than the worker node. The <strong>worker nodes</strong> execute compute tasks over partitioned data and communicate intermediate results to other workers or back to the driver node, worker nodes are also referred as <strong>executors</strong>.</p>
<p>Strictly speaking, the driver node and worker nodes are just names assigned to machines with particular roles, while the actual computation in the driver node is performed by the <strong>spark context</strong>. The Spark context is a Spark component tasked with scheduling tasks, managing data and so on. In the worker nodes, the actual computation is performed under a <strong>spark executor</strong>, which is also a Spark component tasked with executing subtasks against a data partition.</p>
<div class="figure" style="text-align: center"><span id="fig:connections-architecture"></span>
<div id="htmlwidget-d6f9e82a60f9fb3c1ad0" style="width:100%;height:200pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-d6f9e82a60f9fb3c1ad0">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Driver | [Spark Context]] \n[Driver]-[Cluster Manager]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.1: Apache Spark Architecture
</p>
</div>
<p>If you already have a Spark cluster in your organization, you should request from your cluster administrator the connection information to this cluster, read carefully their usage policies and follow their advice. Since a cluster may be shared among many users, you want to make sure you only request the compute resources you need, you will learn how to request resources in the <a href="#tunning">Tunning</a> chapter. Your system administrator will describe if it’s an <strong>on-premise</strong> vs <strong>cloud</strong> cluster, the <strong>cluster manager</strong> being used, supported <strong>connections</strong> and supported <strong>tools</strong>. You can use this information to jump directly to <a href="connections.html#connections-local">Local</a>, <a href="connections.html#connections-standalone">Standalone</a>, <a href="connections.html#connections-yarn">YARN</a>, <a href="connections.html#connections-mesos">Mesos</a>, <a href="connections.html#connections-livy">Livy</a> or <a href="connections.html#connections-kubernetes">Kubernetes</a> based on the information provided to you.</p>
<p><strong>Note:</strong> Once connected is performed with <code>spark_connect()</code>, you can use all techniques described in previous chapters using the <code>sc</code> connection; for instance, you can do <a href="analysis.html#analysis">data analysis</a> or <a href="modeling.html#modeling">modeling</a> with the same code previous chapters presented.</p>
<div id="connections-spark-edge-nodes" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Edge Nodes</h3>
<p>Before connecting to Apache Spark, you will first have to connect to the cluster. Usually, by connecting to an edge node within the cluster. An edge node, is a machine that can accessed from outside the cluster but which is also part of the cluster. There are two methods to connect to this edge instance:</p>
<ul>
<li><strong>Terminal</strong>: Using a <a href="https://en.wikipedia.org/wiki/Computer_terminal">computer terminal</a> application, one can use a <a href="https://en.wikipedia.org/wiki/Secure_Shell">secure shell</a> to establish a remote connection into the cluster, once you connect into the cluster, you can launch R and then use <code>sparklyr</code>. However, a terminal can be cumbersome for some tasks, like exploratory data analysis, so it’s often only used while configuring the cluster or troubleshooting issues.</li>
<li><strong>Web Browser</strong>: While using <code>sparklyr</code> from a terminal is possible, it is usually more productive to install a <strong>web server</strong> in an edge node that provides access to run R with <code>sparklyr</code> from a web browser. Most likely, you will want to consider using <a href="RStudio%20Server">RStudio</a> or Jupyter rather than connecting from the terminal.</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:connections-spark-edge"></span>
<div id="htmlwidget-084ec14d64e6832a58fe" style="width:100%;height:200pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-084ec14d64e6832a58fe">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Client|\n  [Terminal]\n  [Web Browser |\n    [RStudio]\n    [Jupyter]\n  ]\n]-[<hidden> Secure Shell / HTTP]\n\n[Secure Shell / HTTP]-[Edge|\n  [Secure Shell Server] - [R]\n  [RStudio Server] - [R]\n  [Jupyter Server] - [R]\n]","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.2: Connecting to Sparks Edge Node
</p>
</div>
</div>
<div id="connections-spark-home" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Spark Home</h3>
<p>It is important to mention that, while connecting to a Spark cluster, you will need to find out the correct <code>SPARK_HOME</code> path which contains the installation of Spark in the given instance. The <code>SPARK_HOME</code> path must be specified by your system administrator as an environment variable or by yourself explicitly specified in <code>spark_connect()</code> using the <code>spark_home</code> parameter.</p>
<p>If your cluster provider or cluster administrator already provided <code>SPARK_HOME</code> for you, the following code should return a path instead of an empty string.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" title="1"><span class="kw">Sys.getenv</span>(<span class="st">&quot;SPARK_HOME&quot;</span>)</a></code></pre></div>
<p>For system administrators, we recommend setting <code>SPARK_HOME</code> for all the users in your cluster; however, if this is not set in your cluster, you can also specify <code>SPARK_HOME</code> while using <code>spark_connect()</code> as follows:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" title="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;&lt;cluster-master&gt;&quot;</span>, <span class="dt">spark_home =</span> <span class="st">&quot;local/path/to/spark&quot;</span>)</a></code></pre></div>
<p>Where <code>&lt;cluster-master&gt;</code> is set to the correct cluster manager master for <a href="connections.html#connections-standalone">Spark Standalone</a>, <a href="connections.html#connections-yarn">YARN</a>, <a href="connections.html#connections-mesos">Mesos</a>, <a href="connections.html#connections-kubernetes">Kubernetes</a> or <a href="connections.html#connections-livy">Livy</a>.</p>
</div>
</div>
<div id="connections-local" class="section level2">
<h2><span class="header-section-number">6.2</span> Local</h2>
<p>When connecting to Spark in local mode, Spark starts as a single application simulating a cluster with a single node, this is not a proper computing cluster but is ideal to perform work offline and troubleshoot issues. A local connection to Spark is represented in the following diagram:</p>
<div class="figure" style="text-align: center"><span id="fig:connections-local"></span>
<div id="htmlwidget-32eae95afa4d3342af69" style="width:100%;height:160pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-32eae95afa4d3342af69">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Driver|\n  [R]\n  [sparklyr]\n  [spark-submit]\n  [Spark Context]\n  [Spark Executor]\n]","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.3: Local Connection Diagram
</p>
</div>
<p>Notice that in the local connections diagram, there is no cluster manager nor worker process since, in local mode, everything runs inside the driver application. It’s also worth noting that <code>sparklyr</code> starts the Spark Context through <code>spark-submit</code>, a script available in every Spark installation to enable users to submit custom application to Spark which, <code>sparklyr</code> makes use of to submit itself to Spark. For the curious reader, the <a href="contributing.html#contributing">Contributing</a> chapter explains the internal processes that takes place in <code>sparklyr</code> to submit this application and connect properly from R.</p>
<p>To perform this local connection, we can connect with the following familiar code used in previous chapters:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" title="1"><span class="co"># Connect to local Spark instance</span></a>
<a class="sourceLine" id="cb52-2" title="2">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>)</a></code></pre></div>
<p>By default, <code>sparklyr</code>, will connect using as many CPUs are available in your compute instance; however, this can be customized by connecting using <code>master="local[n]"</code>, where <code>n</code> is the desired number of cores to use. For example, we can connect using only 2 CPUs as follows:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" title="1"><span class="co"># Connect to local Spark instance using 2 cores</span></a>
<a class="sourceLine" id="cb53-2" title="2">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local[2]&quot;</span>)</a></code></pre></div>
</div>
<div id="connections-standalone" class="section level2">
<h2><span class="header-section-number">6.3</span> Standalone</h2>
<p>Connecting to a Spark Standalone cluster requires the location of the cluster manager’s master instance, this location can be found in the cluster manager web interface as described in the <a href="clusters.html#clusters-standalone">Standalone Clusters</a> section, you can find this location by looking for a URL starting with <code>spark://</code>.</p>
<p>A connection in standalone mode starts from <code>sparklyr</code> which launches <code>spark-submit</code>, submits the <code>sparklyr</code> application and creates the Spark Context, which requests executors from the Spark Standalone instance running under the given <code>master</code> address.</p>
<div class="figure" style="text-align: center"><span id="fig:connections-standalone"></span>
<div id="htmlwidget-eee71394de919447fe51" style="width:100%;height:200pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-eee71394de919447fe51">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Driver |\n  [R]\n  [sparklyr]\n  [spark-submit]\n  [Spark Context]\n] \n[Driver]-[Cluster Manager |\n  [Spark Standalone]]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.4: Spark Standalone Connection Diagram
</p>
</div>
<p>In order to connect, use <code>master = "spark://hostname:port"</code> in <code>spark_connect()</code> as follows:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" title="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;spark://hostname:port&quot;</span>)</a></code></pre></div>
</div>
<div id="connections-yarn" class="section level2">
<h2><span class="header-section-number">6.4</span> Yarn</h2>
<p>Hadoop YARN supports two connection modes: YARN Client and YARN Cluster. However, YARN Client mode is much more common that YARN Cluster since it’s more efficient and easier to set up.</p>
<div id="connections-yarn-client" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Yarn Client</h3>
<p>When connecting in YARN Client mode, the driver instance runs R, sparklyr and the Spark Context which requests worker nodes from YARN to run Spark executors as follows:</p>
<div class="figure" style="text-align: center"><span id="fig:connections-yarn"></span>
<div id="htmlwidget-ff2547721d2f9baec5a7" style="width:100%;height:250pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-ff2547721d2f9baec5a7">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Driver |\n  [R]\n  [sparklyr]\n  [spark-submit]\n  [Spark Context]\n] \n[Driver]-[Cluster Manager |\n  [Yarn]]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.5: YARN Client Connection Diagram
</p>
</div>
<p>To connect, one can simply run with <code>master = "yarn"</code> as follows:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" title="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;yarn-client&quot;</span>)</a></code></pre></div>
</div>
<div id="connections-yarn-cluster" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Yarn Cluster</h3>
<p>The main difference between YARN Cluster mode and YARN Client mode is that in YARN Cluster mode, the driver node is not required to be the node where R and sparklyr were launched; instead, the driver node remains the designated driver node which is usually a different node than the edge node where R is running. It can be helpful to consider using YARN Cluster when the edge node has too many concurrent users, is lacking computing resources or where tools (like RStudio or Jupyter) need to be managed independently of other cluster resources.</p>
<div class="figure" style="text-align: center"><span id="fig:connections-yarn-cluster"></span>
<div id="htmlwidget-b735f19feef38ab0ea47" style="width:100%;height:240pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-b735f19feef38ab0ea47">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Client |\n  [R]\n  [sparklyr]\n  [spark-submit]\n]\n[Client]-[Cluster Manager]\n[Client]-[Driver |\n  [sparklyr]\n  [Spark Context]\n] \n[Cluster Manager |\n  [Yarn]\n]\n[Driver]-[Cluster Manager]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.6: YARN Cluster Connection Diagram
</p>
</div>
<p>To connect in YARN Cluster mode, we can simple run:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" title="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;yarn-cluster&quot;</span>)</a></code></pre></div>
<p>This connection assumes that the node running <code>spark_connect()</code> is properly configured, meaning that, <code>yarn-site.xml</code> exists and the <code>YARN_CONF_DIR</code> environment variable is properly set. When using Hadoop as a file system, you will also need the <code>HADOOP_CONF_DIR</code> environment variable properly configured. This configuration is usually provided by your system administrator and is not something that you would have to manually configure.</p>
</div>
</div>
<div id="connections-livy" class="section level2">
<h2><span class="header-section-number">6.5</span> Livy</h2>
<p>As opposed to other connection methods which require using an edge node in the cluster, <a href="clusters.html#clusters-livy">Livy</a> provides a <strong>Web API</strong> that makes the Spark cluster accessible from outside the cluster and does not require a Spark installation in the client. Once connected through the Web API, the <strong>Livy Service</strong> starts the Spark context by requesting resources from the cluster manager and distributing work as usual.</p>
<div class="figure" style="text-align: center"><span id="fig:connections-livy"></span>
<div id="htmlwidget-71cfc00eeabceacdfad9" style="width:100%;height:240pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-71cfc00eeabceacdfad9">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Client |\n  [R]\n  [sparklyr]\n]\n[Client]-[<hidden> Web API]\n[Web API]-[Driver |\n  [Livy Service]\n  [Spark Context]\n] \n[Cluster Manager]\n[Driver]-[Cluster Manager]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.7: Livy Connection Diagram
</p>
</div>
<p>Connecting through Livy requires the URL to the Livy service which should be similar to <code>https://hostname:port/livy</code>. Since remote connections are allowed, connections usually requires, at the very least, basic authentication:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb57-1" title="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;https://hostname:port/livy&quot;</span>, <span class="dt">method =</span> <span class="st">&quot;livy&quot;</span>, <span class="dt">config =</span> <span class="kw">livy_config</span>(</a>
<a class="sourceLine" id="cb57-2" title="2">  <span class="dt">username=</span><span class="st">&quot;&lt;username&gt;&quot;</span>,</a>
<a class="sourceLine" id="cb57-3" title="3">  <span class="dt">password=</span><span class="st">&quot;&lt;password&gt;&quot;</span></a>
<a class="sourceLine" id="cb57-4" title="4">))</a></code></pre></div>
<p>To try out Livy in your local machine, you can install and run a Livy service as described under the <a href="clusters.html#clusters-livy">Livy Clusters</a> section and then, connect as follows:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" title="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;http://localhost:8998&quot;</span>, <span class="dt">method =</span> <span class="st">&quot;livy&quot;</span>)</a></code></pre></div>
<p>Once connected through Livy, you can make use of any <code>sparklyr</code> feature; however, Livy is not suitable for exploratory data analysis since, executing commands has a significant performance cost; that said, while running long running computations, this overhead could be considered irrelevant. In general, it is preferred to avoid using Livy and work directly within an edge node in the cluster; when this is not feasible, using Livy could be a reasonable approach.</p>
</div>
<div id="connections-mesos" class="section level2">
<h2><span class="header-section-number">6.6</span> Mesos</h2>
<p>Similar to YARN, Mesos supports client mode and a cluster mode, <code>sparklyr</code> currently only supports client mode for Mesos.</p>
<div class="figure" style="text-align: center"><span id="fig:connections-mesos"></span>
<div id="htmlwidget-5afbcc8ce92f7b18261f" style="width:100%;height:250pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-5afbcc8ce92f7b18261f">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Driver |\n  [R]\n  [sparklyr]\n  [spark-submit]\n  [Spark Context]\n] \n[Driver]-[Cluster Manager |\n  [Mesos]]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.8: Mesos Connection Diagram
</p>
</div>
<p>Connecting requires the address to the Mesos master node, usually in the form of <code>mesos://host:port</code> or <code>mesos://zk://host1:2181,host2:2181,host3:2181/mesos</code> for Mesos using ZooKeeper.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb59-1" title="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;mesos://host:port&quot;</span>)</a></code></pre></div>
</div>
<div id="connections-kubernetes" class="section level2">
<h2><span class="header-section-number">6.7</span> Kubernetes</h2>
<p>Kubernetes cluster do not support client modes similar to Mesos or YARN, instead, the connection model is similar to YARN Cluster, where the driver node is assigned by Kubernetes.</p>
<div class="figure" style="text-align: center"><span id="fig:connections-kubernetes"></span>
<div id="htmlwidget-0ed95ccfe4f509996636" style="width:100%;height:250pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-0ed95ccfe4f509996636">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Client |\n  [R]\n  [sparklyr]\n  [spark-submit]\n]\n[Client]-[Cluster Manager]\n[Client]-[Driver]\n[Driver |\n  [sparklyr]\n  [Spark Context]\n] \n[Driver]-[Cluster Manager |\n  [Kubernetes]]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.9: Kubernetes Connection Diagram
</p>
</div>
<p>Kubernetes support is scheduled to be added to <code>sparklyr</code> with <a href="https://github.com/rstudio/sparklyr/issues/1525">sparklyr/issues/1525</a>, please follow progress for this feature directly in github. Once Kubernetes becomes supported in <code>sparklyr</code>, connecting to Kubernetes will work as follows:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" title="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(</a>
<a class="sourceLine" id="cb60-2" title="2">  <span class="dt">master =</span> <span class="st">&quot;k8s://https://&lt;apiserver-host&gt;:&lt;apiserver-port&gt;&quot;</span></a>
<a class="sourceLine" id="cb60-3" title="3">  <span class="dt">config =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb60-4" title="4">    <span class="dt">spark.executor.instances =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb60-5" title="5">    <span class="dt">spark.kubernetes.container.image =</span> <span class="st">&quot;spark-image&quot;</span></a>
<a class="sourceLine" id="cb60-6" title="6">  )</a>
<a class="sourceLine" id="cb60-7" title="7">)</a></code></pre></div>
<p>If your computer is already configured to use a Kubernetes cluster, you can use the following command to find the <code>apiserver-host</code> and <code>apiserver-port</code>:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" title="1"><span class="kw">system2</span>(<span class="st">&quot;kubectl&quot;</span>, <span class="st">&quot;cluster-info&quot;</span>)</a></code></pre></div>
</div>
<div id="cloud-1" class="section level2">
<h2><span class="header-section-number">6.8</span> Cloud</h2>
<p>When working with cloud providers, there are a few connection differences. For instance, connecting from Databricks requires the following connection method:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" title="1"><span class="kw">library</span>(sparklyr)</a>
<a class="sourceLine" id="cb62-2" title="2">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">method =</span> <span class="st">&quot;databricks&quot;</span>)</a></code></pre></div>
<p>Similarly, connections to Spark when using IBM’s Watson Studio require you to connect as follows:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb63-1" title="1">kernels &lt;-<span class="st"> </span><span class="kw">load_spark_kernels</span>()</a>
<a class="sourceLine" id="cb63-2" title="2">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">config =</span> kernels[<span class="dv">2</span>])</a></code></pre></div>
<p>Under Microsoft Azure HDInsights and when using ML Services (R Server), creating an <code>sparklyr</code> connection gets initialized through:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" title="1"><span class="kw">library</span>(RevoScaleR)</a>
<a class="sourceLine" id="cb64-2" title="2">cc &lt;-<span class="st"> </span><span class="kw">rxSparkConnect</span>(<span class="dt">reset =</span> <span class="ot">TRUE</span>, <span class="dt">interop =</span> <span class="st">&quot;sparklyr&quot;</span>)</a>
<a class="sourceLine" id="cb64-3" title="3">sc &lt;-<span class="st"> </span><span class="kw">rxGetSparklyrConnection</span>(cc)</a></code></pre></div>
<p>Please reference your cloud provider documentation and their support channels if assistance is needed.</p>
</div>
<div id="multiple" class="section level2">
<h2><span class="header-section-number">6.9</span> Multiple</h2>
<p>It is common to connect once, and only once, to Spark. However, you can also open multiple connections to Spark by connecting to different clusters or by specifying the <code>app_name</code> parameter, this can be helpful to compare Spark versions or validate you analysis before submitting to the cluster. The following example opens connections to Spark 1.6.3, 2.3.0 and Spark Standalone:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb65-1" title="1"><span class="co"># Connect to local Spark 1.6.3</span></a>
<a class="sourceLine" id="cb65-2" title="2">sc_<span class="dv">1</span>_<span class="dv">6</span>_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;1.6.3&quot;</span>)</a>
<a class="sourceLine" id="cb65-3" title="3"></a>
<a class="sourceLine" id="cb65-4" title="4"><span class="co"># Connect to local Spark 2.3.0</span></a>
<a class="sourceLine" id="cb65-5" title="5">sc_<span class="dv">2</span>_<span class="dv">3</span>_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3.0&quot;</span>, <span class="dt">appName =</span> <span class="st">&quot;Spark23&quot;</span>)</a>
<a class="sourceLine" id="cb65-6" title="6"></a>
<a class="sourceLine" id="cb65-7" title="7"><span class="co"># Connect to local Spark Standalone</span></a>
<a class="sourceLine" id="cb65-8" title="8">sc_standalone &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;spark://host:port&quot;</span>)</a></code></pre></div>
<p>Finally, we can disconnect from each connection:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" title="1"><span class="kw">spark_disconnect</span>(sc_<span class="dv">1</span>_<span class="dv">6</span>_<span class="dv">3</span>)</a>
<a class="sourceLine" id="cb66-2" title="2"><span class="kw">spark_disconnect</span>(sc_<span class="dv">2</span>_<span class="dv">3</span>_<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb66-3" title="3"><span class="kw">spark_disconnect</span>(sc_standalone)</a></code></pre></div>
<p>Alternatively, you can disconnect from all connections at once:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" title="1"><span class="kw">spark_disconnect_all</span>()</a></code></pre></div>
</div>
<div id="connections-troubleshooting" class="section level2">
<h2><span class="header-section-number">6.10</span> Troubleshooting</h2>
<p>Last but not least, we will introduce the following troubleshooting techniques for: <strong>Logging</strong>, <strong>Spark Submit</strong> and <strong>Windows</strong>. When in doubt of where to start, start with the Windows section when using Windows systems, followed by Logging and closing with Spark Submit.</p>
<div id="logging" class="section level3">
<h3><span class="header-section-number">6.10.1</span> Logging</h3>
<p>One first step is to troubleshoot connections is to run in verbose to print directly to the console additional error messages:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb68-1" title="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">log =</span> <span class="st">&quot;console&quot;</span>)</a></code></pre></div>
<p>Verbose logging can also be enabled with the following option:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" title="1"><span class="kw">options</span>(<span class="dt">sparklyr.verbose =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
</div>
<div id="troubleshoot-spark-submit" class="section level3">
<h3><span class="header-section-number">6.10.2</span> Spark Submit</h3>
<p>If connections fail in <code>sparklyr</code>, first troubleshoot if this issue is specific to <code>sparklyr</code> or Spark in general. This can be accomplished by running an example <code>spark-submit</code> job and validating that no errors are thrown.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb70-1" title="1"><span class="co"># Find the spark directory using an environment variable</span></a>
<a class="sourceLine" id="cb70-2" title="2">spark_home &lt;-<span class="st"> </span><span class="kw">Sys.getenv</span>(<span class="st">&quot;SPARK_HOME&quot;</span>)</a>
<a class="sourceLine" id="cb70-3" title="3"></a>
<a class="sourceLine" id="cb70-4" title="4"><span class="co"># Or by getting the local spark installation</span></a>
<a class="sourceLine" id="cb70-5" title="5">spark_home &lt;-<span class="st"> </span>sparklyr<span class="op">::</span><span class="kw">spark_home_dir</span>()</a></code></pre></div>
<p>Then execute the sample compute Pi example by replacing <code>"local"</code> with the correct master parameter you are troubleshooting:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" title="1"><span class="co"># Launching a sample application to compute Pi</span></a>
<a class="sourceLine" id="cb71-2" title="2"><span class="kw">system2</span>(</a>
<a class="sourceLine" id="cb71-3" title="3">  <span class="kw">file.path</span>(spark_home, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;spark-submit&quot;</span>),</a>
<a class="sourceLine" id="cb71-4" title="4">  <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb71-5" title="5">    <span class="st">&quot;--master&quot;</span>, <span class="st">&quot;local&quot;</span>,</a>
<a class="sourceLine" id="cb71-6" title="6">    <span class="st">&quot;--class&quot;</span>, <span class="st">&quot;org.apache.spark.examples.SparkPi&quot;</span>,</a>
<a class="sourceLine" id="cb71-7" title="7">    <span class="kw">file.path</span>(spark_home, <span class="st">&quot;examples&quot;</span>, <span class="st">&quot;jars&quot;</span>, <span class="st">&quot;spark-examples_2.11-2.4.0.jar&quot;</span>),</a>
<a class="sourceLine" id="cb71-8" title="8">    <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb71-9" title="9">)</a></code></pre></div>
<pre><code>...
Pi is roughly 3.1415503141550314
...</code></pre>
<p>If your Spark cluster is properly configured, you should see the message above; otherwise, you will need to investigate why your Spark cluster is not properly configured, which is beyond the scope of this book.</p>
<div id="detailed" class="section level4">
<h4><span class="header-section-number">6.10.2.1</span> Detailed</h4>
<p>To troubleshoot the connection process in detail, you can manually replicate the two-step connection process, which is often very helpful to diagnose connection issues. Connecting to Spark is performed in two steps; first, <code>spark-submit</code> is triggered from R which submits the application to Spark, second, R connects to the running Spark application.</p>
<p>First, <a href="troubleshoot-spark-submit">identify the Spark installation directory</a> and the path to the correct <code>sparklyr*.jar</code> by running:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" title="1"><span class="kw">dir</span>(<span class="kw">system.file</span>(<span class="st">&quot;java&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;sparklyr&quot;</span>), <span class="dt">pattern =</span> <span class="st">&quot;sparklyr&quot;</span>, <span class="dt">full.names =</span> T)</a></code></pre></div>
<p>Make sure you identify the correct version that matches your Spark cluster, for instance <code>sparklyr-2.1-2.11.jar</code> for Spark 2.1.</p>
<p>Then, from the terminal, run:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb74-1" title="1"><span class="va">$SPARK_HOME</span><span class="ex">/bin/spark-submit</span> --class sparklyr.Shell <span class="va">$PATH_TO_SPARKLYR_JAR</span> 8880 12345</a></code></pre></div>
<pre><code>18/06/11 12:13:53 INFO sparklyr: Session (12345) found port 8880 is available
18/06/11 12:13:53 INFO sparklyr: Gateway (12345) is waiting for sparklyr client
                                 to connect to port 8880</code></pre>
<p>The parameter <code>8880</code> represents the default port to use in <code>sparklyr</code> while <code>12345</code> is the session number, this is a cryptographically secure number generated by <code>sparklyr</code>, but for troubleshooting purposes can be as simple as <code>12345</code>.</p>
<p>If this first connection step fails, it means that the cluster can’t accept the application. This usually means that there are not enough resources, there are permission restrictions, etc.</p>
<p>The second step is to connect from R as follows, notice that there is a 60 seconds timeout, so you’ll have to run the R command after running the terminal command, if needed, this timeout can be configured as described in the <a href="#tunning">Tunning</a> chapter.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" title="1"><span class="kw">library</span>(sparklyr)</a>
<a class="sourceLine" id="cb76-2" title="2">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;sparklyr://localhost:8880/12345&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3&quot;</span>)</a></code></pre></div>
<p>If this second connection step fails, it usually means that there is a connectivity problem between R and the driver node, you can try using a different connection port, for instance.</p>
</div>
</div>
<div id="windows" class="section level3">
<h3><span class="header-section-number">6.10.3</span> Windows</h3>
<p>Connecting from Windows is, in most cases, as straightforward as connecting from Linux and OS X; however, there are a few common connection issues you should be aware of:</p>
<ul>
<li>Firewalls and antivirus software might block ports for your connection. The default port used by <code>sparklyr</code> is <code>8880</code>, double check this port is not being blocked.</li>
<li>Long path names can cause issues in, specially in older Windows systems like Windows 7. When using these systems, try connecting with Spark installed with all folders using at most 8 characters and no spaces in their names.</li>
</ul>
</div>
</div>
<div id="recap-1" class="section level2">
<h2><span class="header-section-number">6.11</span> Recap</h2>
<p>This chapter presented an overview of Spark’s architecture, connection concepts and examples to connect in local mode, standalone, YARN, Mesos, Kubernetes and Livy. It also presented edge nodes and their role while connecting to Spark clusters. This should have provided you with enough information to successfully connect to any Apache Spark cluster.</p>
<p>To troubleshoot connection problems beyond the techniques described in this chpater, it is recommended to search for the connection problem in StackOverflow, the <a href="https://github.com/rstudio/sparklyr/issues">sparklyr github issues</a> and, if needed, open a <a href="https://github.com/rstudio/sparklyr/issues/new">new GitHub issue in sparklyr</a> to assist further.</p>
<p>In the next chapter, <a href="data.html#data">Data</a>, you will learn how to read and write over multiple data sources, you will understand how Spark makes use of Spark DataFrames and how to transfer data into and out of Spark clusters.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="clusters.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
