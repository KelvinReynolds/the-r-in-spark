<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>The R in Spark: Learning Apache Spark with R</title>
  <meta name="description" content="A book to learn Apache Spark with R using the sparklyr R package.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="The R in Spark: Learning Apache Spark with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A book to learn Apache Spark with R using the sparklyr R package." />
  <meta name="github-repo" content="javierluraschi/the-r-in-spark" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="The R in Spark: Learning Apache Spark with R" />
  
  <meta name="twitter:description" content="A book to learn Apache Spark with R using the sparklyr R package." />
  



<meta name="date" content="2018-12-22">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="clusters.html">
<link rel="next" href="data.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/dagre-0.0.1/dagre.min.js"></script>
<script src="libs/lodash-3.7.0/lodash.js"></script>
<script src="libs/nomnoml-0.2.0/nomnoml.js"></script>
<script src="libs/nomnoml-binding-0.1.0/nomnoml.js"></script>
<script src="libs/r2d3-render-0.1.0/r2d3-render.js"></script>
<script src="libs/webcomponents-2.0.0/webcomponents.js"></script>
<script src="libs/r2d3-binding-0.2.3/r2d3.js"></script>
<script src="libs/d3v5-5.0.0/d3.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119986300-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119986300-1');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Learning Apache Spark with R</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#structure"><i class="fa fa-check"></i>Structure</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#authors"><i class="fa fa-check"></i>Authors</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#intro-background"><i class="fa fa-check"></i><b>1.1</b> Background</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#intro-spark"><i class="fa fa-check"></i><b>1.2</b> Spark</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#intro-r"><i class="fa fa-check"></i><b>1.3</b> R</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#intro-sparklyr"><i class="fa fa-check"></i><b>1.4</b> sparklyr</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="starting.html"><a href="starting.html"><i class="fa fa-check"></i><b>2</b> Getting Started</a><ul>
<li class="chapter" data-level="2.1" data-path="starting.html"><a href="starting.html#starting-prerequisites"><i class="fa fa-check"></i><b>2.1</b> Prerequisites</a><ul>
<li class="chapter" data-level="2.1.1" data-path="starting.html"><a href="starting.html#starting-install-r"><i class="fa fa-check"></i><b>2.1.1</b> Install R</a></li>
<li class="chapter" data-level="2.1.2" data-path="starting.html"><a href="starting.html#starting-install-java"><i class="fa fa-check"></i><b>2.1.2</b> Install Java</a></li>
<li class="chapter" data-level="2.1.3" data-path="starting.html"><a href="starting.html#starting-install-rstudio"><i class="fa fa-check"></i><b>2.1.3</b> Install RStudio</a></li>
<li class="chapter" data-level="2.1.4" data-path="starting.html"><a href="starting.html#starting-install-sparklyr"><i class="fa fa-check"></i><b>2.1.4</b> Install sparklyr</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="starting.html"><a href="starting.html#starting-installing-spark"><i class="fa fa-check"></i><b>2.2</b> Installing Spark</a></li>
<li class="chapter" data-level="2.3" data-path="starting.html"><a href="starting.html#starting-connect-to-spark"><i class="fa fa-check"></i><b>2.3</b> Connecting to Spark</a></li>
<li class="chapter" data-level="2.4" data-path="starting.html"><a href="starting.html#starting-sparklyr-hello-world"><i class="fa fa-check"></i><b>2.4</b> Using Spark</a><ul>
<li class="chapter" data-level="2.4.1" data-path="starting.html"><a href="starting.html#starting-spark-web-interface"><i class="fa fa-check"></i><b>2.4.1</b> Web Interface</a></li>
<li class="chapter" data-level="2.4.2" data-path="starting.html"><a href="starting.html#starting-logs"><i class="fa fa-check"></i><b>2.4.2</b> Logs</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="starting.html"><a href="starting.html#starting-disconnecting"><i class="fa fa-check"></i><b>2.5</b> Disconnecting</a></li>
<li class="chapter" data-level="2.6" data-path="starting.html"><a href="starting.html#starting-using-spark-from-rstudio"><i class="fa fa-check"></i><b>2.6</b> RStudio</a></li>
<li class="chapter" data-level="2.7" data-path="starting.html"><a href="starting.html#starting-resources"><i class="fa fa-check"></i><b>2.7</b> Resources</a></li>
<li class="chapter" data-level="2.8" data-path="starting.html"><a href="starting.html#starting-recap"><i class="fa fa-check"></i><b>2.8</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis.html"><a href="analysis.html"><i class="fa fa-check"></i><b>3</b> Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="analysis.html"><a href="analysis.html#typical-analysis"><i class="fa fa-check"></i><b>3.1</b> Typical analysis</a></li>
<li class="chapter" data-level="3.2" data-path="analysis.html"><a href="analysis.html#working-with-big-data"><i class="fa fa-check"></i><b>3.2</b> Working with Big Data</a></li>
<li class="chapter" data-level="3.3" data-path="analysis.html"><a href="analysis.html#avoid-running-r-inside-spark"><i class="fa fa-check"></i><b>3.3</b> Avoid running R inside Spark</a></li>
<li class="chapter" data-level="3.4" data-path="analysis.html"><a href="analysis.html#use-r-as-an-interface-to-spark"><i class="fa fa-check"></i><b>3.4</b> Use R as an interface to Spark</a></li>
<li class="chapter" data-level="3.5" data-path="analysis.html"><a href="analysis.html#cut-here"><i class="fa fa-check"></i><b>3.5</b> Cut here</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="modeling.html"><a href="modeling.html"><i class="fa fa-check"></i><b>4</b> Modeling</a><ul>
<li class="chapter" data-level="4.1" data-path="modeling.html"><a href="modeling.html#overview"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="modeling.html"><a href="modeling.html#supervised"><i class="fa fa-check"></i><b>4.2</b> Supervised</a></li>
<li class="chapter" data-level="4.3" data-path="modeling.html"><a href="modeling.html#unsupervised"><i class="fa fa-check"></i><b>4.3</b> Unsupervised</a><ul>
<li class="chapter" data-level="4.3.1" data-path="modeling.html"><a href="modeling.html#k-means-clustering"><i class="fa fa-check"></i><b>4.3.1</b> K-Means Clustering</a></li>
<li class="chapter" data-level="4.3.2" data-path="modeling.html"><a href="modeling.html#gaussian-mixture-clustering"><i class="fa fa-check"></i><b>4.3.2</b> Gaussian Mixture Clustering</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="modeling.html"><a href="modeling.html#broom"><i class="fa fa-check"></i><b>4.4</b> Broom</a></li>
<li class="chapter" data-level="4.5" data-path="modeling.html"><a href="modeling.html#pipelines"><i class="fa fa-check"></i><b>4.5</b> Pipelines</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="clusters.html"><a href="clusters.html"><i class="fa fa-check"></i><b>5</b> Clusters</a><ul>
<li class="chapter" data-level="5.1" data-path="clusters.html"><a href="clusters.html#clusters-overview"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="clusters.html"><a href="clusters.html#clusters-manager"><i class="fa fa-check"></i><b>5.2</b> Managers</a><ul>
<li class="chapter" data-level="5.2.1" data-path="clusters.html"><a href="clusters.html#clusters-standalone"><i class="fa fa-check"></i><b>5.2.1</b> Standalone</a></li>
<li class="chapter" data-level="5.2.2" data-path="clusters.html"><a href="clusters.html#yarn"><i class="fa fa-check"></i><b>5.2.2</b> Yarn</a></li>
<li class="chapter" data-level="5.2.3" data-path="clusters.html"><a href="clusters.html#mesos"><i class="fa fa-check"></i><b>5.2.3</b> Mesos</a></li>
<li class="chapter" data-level="5.2.4" data-path="clusters.html"><a href="clusters.html#kubernetes"><i class="fa fa-check"></i><b>5.2.4</b> Kubernetes</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="clusters.html"><a href="clusters.html#on-premise"><i class="fa fa-check"></i><b>5.3</b> On-Premise</a><ul>
<li class="chapter" data-level="5.3.1" data-path="clusters.html"><a href="clusters.html#cloudera"><i class="fa fa-check"></i><b>5.3.1</b> Cloudera</a></li>
<li class="chapter" data-level="5.3.2" data-path="clusters.html"><a href="clusters.html#hortonworks"><i class="fa fa-check"></i><b>5.3.2</b> Hortonworks</a></li>
<li class="chapter" data-level="5.3.3" data-path="clusters.html"><a href="clusters.html#mapr"><i class="fa fa-check"></i><b>5.3.3</b> MapR</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="clusters.html"><a href="clusters.html#cloud"><i class="fa fa-check"></i><b>5.4</b> Cloud</a><ul>
<li class="chapter" data-level="5.4.1" data-path="clusters.html"><a href="clusters.html#clusters-amazon-emr"><i class="fa fa-check"></i><b>5.4.1</b> Amazon</a></li>
<li class="chapter" data-level="5.4.2" data-path="clusters.html"><a href="clusters.html#databricks"><i class="fa fa-check"></i><b>5.4.2</b> Databricks</a></li>
<li class="chapter" data-level="5.4.3" data-path="clusters.html"><a href="clusters.html#google"><i class="fa fa-check"></i><b>5.4.3</b> Google</a></li>
<li class="chapter" data-level="5.4.4" data-path="clusters.html"><a href="clusters.html#ibm"><i class="fa fa-check"></i><b>5.4.4</b> IBM</a></li>
<li class="chapter" data-level="5.4.5" data-path="clusters.html"><a href="clusters.html#microsoft"><i class="fa fa-check"></i><b>5.4.5</b> Microsoft</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="clusters.html"><a href="clusters.html#tools"><i class="fa fa-check"></i><b>5.5</b> Tools</a><ul>
<li class="chapter" data-level="5.5.1" data-path="clusters.html"><a href="clusters.html#rstudio"><i class="fa fa-check"></i><b>5.5.1</b> RStudio</a></li>
<li class="chapter" data-level="5.5.2" data-path="clusters.html"><a href="clusters.html#jupyter"><i class="fa fa-check"></i><b>5.5.2</b> Jupyter</a></li>
<li class="chapter" data-level="5.5.3" data-path="clusters.html"><a href="clusters.html#clusters-livy"><i class="fa fa-check"></i><b>5.5.3</b> Livy</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="clusters.html"><a href="clusters.html#recap"><i class="fa fa-check"></i><b>5.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="connections.html"><a href="connections.html"><i class="fa fa-check"></i><b>6</b> Connections</a><ul>
<li class="chapter" data-level="6.1" data-path="connections.html"><a href="connections.html#connections-overview"><i class="fa fa-check"></i><b>6.1</b> Overview</a><ul>
<li class="chapter" data-level="6.1.1" data-path="connections.html"><a href="connections.html#connections-spark-edge-nodes"><i class="fa fa-check"></i><b>6.1.1</b> Edge Nodes</a></li>
<li class="chapter" data-level="6.1.2" data-path="connections.html"><a href="connections.html#connections-spark-home"><i class="fa fa-check"></i><b>6.1.2</b> Spark Home</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="connections.html"><a href="connections.html#connections-local"><i class="fa fa-check"></i><b>6.2</b> Local</a></li>
<li class="chapter" data-level="6.3" data-path="connections.html"><a href="connections.html#connections-standalone"><i class="fa fa-check"></i><b>6.3</b> Standalone</a></li>
<li class="chapter" data-level="6.4" data-path="connections.html"><a href="connections.html#connections-yarn"><i class="fa fa-check"></i><b>6.4</b> Yarn</a><ul>
<li class="chapter" data-level="6.4.1" data-path="connections.html"><a href="connections.html#connections-yarn-client"><i class="fa fa-check"></i><b>6.4.1</b> Yarn Client</a></li>
<li class="chapter" data-level="6.4.2" data-path="connections.html"><a href="connections.html#connections-yarn-cluster"><i class="fa fa-check"></i><b>6.4.2</b> Yarn Cluster</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="connections.html"><a href="connections.html#connections-livy"><i class="fa fa-check"></i><b>6.5</b> Livy</a></li>
<li class="chapter" data-level="6.6" data-path="connections.html"><a href="connections.html#connections-mesos"><i class="fa fa-check"></i><b>6.6</b> Mesos</a></li>
<li class="chapter" data-level="6.7" data-path="connections.html"><a href="connections.html#connections-kubernetes"><i class="fa fa-check"></i><b>6.7</b> Kubernetes</a></li>
<li class="chapter" data-level="6.8" data-path="connections.html"><a href="connections.html#cloud-1"><i class="fa fa-check"></i><b>6.8</b> Cloud</a></li>
<li class="chapter" data-level="6.9" data-path="connections.html"><a href="connections.html#multiple"><i class="fa fa-check"></i><b>6.9</b> Multiple</a></li>
<li class="chapter" data-level="6.10" data-path="connections.html"><a href="connections.html#troubleshooting"><i class="fa fa-check"></i><b>6.10</b> Troubleshooting</a><ul>
<li class="chapter" data-level="6.10.1" data-path="connections.html"><a href="connections.html#logging"><i class="fa fa-check"></i><b>6.10.1</b> Logging</a></li>
<li class="chapter" data-level="6.10.2" data-path="connections.html"><a href="connections.html#troubleshoot-spark-submit"><i class="fa fa-check"></i><b>6.10.2</b> Spark Submit</a></li>
<li class="chapter" data-level="6.10.3" data-path="connections.html"><a href="connections.html#windows"><i class="fa fa-check"></i><b>6.10.3</b> Windows</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="connections.html"><a href="connections.html#recap-1"><i class="fa fa-check"></i><b>6.11</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>7</b> Data</a><ul>
<li class="chapter" data-level="7.1" data-path="data.html"><a href="data.html#overview-1"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="data.html"><a href="data.html#data-frames"><i class="fa fa-check"></i><b>7.2</b> Data Frames</a><ul>
<li class="chapter" data-level="7.2.1" data-path="data.html"><a href="data.html#data-sdf-functions"><i class="fa fa-check"></i><b>7.2.1</b> Functions</a></li>
<li class="chapter" data-level="7.2.2" data-path="data.html"><a href="data.html#pivoting"><i class="fa fa-check"></i><b>7.2.2</b> Pivoting</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="data.html"><a href="data.html#formats"><i class="fa fa-check"></i><b>7.3</b> Formats</a></li>
<li class="chapter" data-level="7.4" data-path="data.html"><a href="data.html#data-types"><i class="fa fa-check"></i><b>7.4</b> Data Types</a><ul>
<li class="chapter" data-level="7.4.1" data-path="data.html"><a href="data.html#dates"><i class="fa fa-check"></i><b>7.4.1</b> Dates</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="data.html"><a href="data.html#sources"><i class="fa fa-check"></i><b>7.5</b> Sources</a><ul>
<li class="chapter" data-level="7.5.1" data-path="data.html"><a href="data.html#amazon-s3"><i class="fa fa-check"></i><b>7.5.1</b> Amazon S3</a></li>
<li class="chapter" data-level="7.5.2" data-path="data.html"><a href="data.html#azure-storage"><i class="fa fa-check"></i><b>7.5.2</b> Azure Storage</a></li>
<li class="chapter" data-level="7.5.3" data-path="data.html"><a href="data.html#cassandra"><i class="fa fa-check"></i><b>7.5.3</b> Cassandra</a></li>
<li class="chapter" data-level="7.5.4" data-path="data.html"><a href="data.html#databases"><i class="fa fa-check"></i><b>7.5.4</b> Databases</a></li>
<li class="chapter" data-level="7.5.5" data-path="data.html"><a href="data.html#hbase"><i class="fa fa-check"></i><b>7.5.5</b> HBase</a></li>
<li class="chapter" data-level="7.5.6" data-path="data.html"><a href="data.html#nested-data"><i class="fa fa-check"></i><b>7.5.6</b> Nested Data</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="data.html"><a href="data.html#troubleshooting-1"><i class="fa fa-check"></i><b>7.6</b> Troubleshooting</a><ul>
<li class="chapter" data-level="7.6.1" data-path="data.html"><a href="data.html#troubleshoot-csvs"><i class="fa fa-check"></i><b>7.6.1</b> Troubleshoot CSVs</a></li>
<li class="chapter" data-level="7.6.2" data-path="data.html"><a href="data.html#column-names"><i class="fa fa-check"></i><b>7.6.2</b> Column Names</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="data.html"><a href="data.html#recap-2"><i class="fa fa-check"></i><b>7.7</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tuning.html"><a href="tuning.html"><i class="fa fa-check"></i><b>8</b> Tuning</a><ul>
<li class="chapter" data-level="8.1" data-path="tuning.html"><a href="tuning.html#overview-2"><i class="fa fa-check"></i><b>8.1</b> Overview</a><ul>
<li class="chapter" data-level="8.1.1" data-path="tuning.html"><a href="tuning.html#tunning-graph-visualization"><i class="fa fa-check"></i><b>8.1.1</b> Graph Visualization</a></li>
<li class="chapter" data-level="8.1.2" data-path="tuning.html"><a href="tuning.html#tunning-event-timeline"><i class="fa fa-check"></i><b>8.1.2</b> Event Timeline</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="tuning.html"><a href="tuning.html#tunning-configuring"><i class="fa fa-check"></i><b>8.2</b> Configuring</a><ul>
<li class="chapter" data-level="8.2.1" data-path="tuning.html"><a href="tuning.html#submit-settings"><i class="fa fa-check"></i><b>8.2.1</b> Submit Settings</a></li>
<li class="chapter" data-level="8.2.2" data-path="tuning.html"><a href="tuning.html#runtime-settings"><i class="fa fa-check"></i><b>8.2.2</b> Runtime Settings</a></li>
<li class="chapter" data-level="8.2.3" data-path="tuning.html"><a href="tuning.html#sparklyr-settings"><i class="fa fa-check"></i><b>8.2.3</b> sparklyr Settings</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="tuning.html"><a href="tuning.html#tunning-partitioning"><i class="fa fa-check"></i><b>8.3</b> Partitioning</a><ul>
<li class="chapter" data-level="8.3.1" data-path="tuning.html"><a href="tuning.html#implicit"><i class="fa fa-check"></i><b>8.3.1</b> Implicit</a></li>
<li class="chapter" data-level="8.3.2" data-path="tuning.html"><a href="tuning.html#explicit"><i class="fa fa-check"></i><b>8.3.2</b> Explicit</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="tuning.html"><a href="tuning.html#tunning-caching"><i class="fa fa-check"></i><b>8.4</b> Caching</a><ul>
<li class="chapter" data-level="8.4.1" data-path="tuning.html"><a href="tuning.html#checkpointing"><i class="fa fa-check"></i><b>8.4.1</b> Checkpointing</a></li>
<li class="chapter" data-level="8.4.2" data-path="tuning.html"><a href="tuning.html#tunning-memory"><i class="fa fa-check"></i><b>8.4.2</b> Memory</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="tuning.html"><a href="tuning.html#tunning-shuffling"><i class="fa fa-check"></i><b>8.5</b> Shuffling</a></li>
<li class="chapter" data-level="8.6" data-path="tuning.html"><a href="tuning.html#tunning-serialization"><i class="fa fa-check"></i><b>8.6</b> Serialization</a></li>
<li class="chapter" data-level="8.7" data-path="tuning.html"><a href="tuning.html#recap-3"><i class="fa fa-check"></i><b>8.7</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="extensions.html"><a href="extensions.html"><i class="fa fa-check"></i><b>9</b> Extensions</a><ul>
<li class="chapter" data-level="9.1" data-path="extensions.html"><a href="extensions.html#rsparkling"><i class="fa fa-check"></i><b>9.1</b> RSparkling</a><ul>
<li class="chapter" data-level="9.1.1" data-path="extensions.html"><a href="extensions.html#troubleshooting-2"><i class="fa fa-check"></i><b>9.1.1</b> Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="extensions.html"><a href="extensions.html#graphframes"><i class="fa fa-check"></i><b>9.2</b> GraphFrames</a></li>
<li class="chapter" data-level="9.3" data-path="extensions.html"><a href="extensions.html#mleap"><i class="fa fa-check"></i><b>9.3</b> Mleap</a></li>
<li class="chapter" data-level="9.4" data-path="extensions.html"><a href="extensions.html#extensions-nested-data"><i class="fa fa-check"></i><b>9.4</b> Nested Data</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="distributed.html"><a href="distributed.html"><i class="fa fa-check"></i><b>10</b> Distributed R</a><ul>
<li class="chapter" data-level="10.1" data-path="distributed.html"><a href="distributed.html#use-cases"><i class="fa fa-check"></i><b>10.1</b> Use Cases</a><ul>
<li class="chapter" data-level="10.1.1" data-path="distributed.html"><a href="distributed.html#embarrassingly-parallel"><i class="fa fa-check"></i><b>10.1.1</b> Embarrassingly Parallel</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="distributed.html"><a href="distributed.html#columns"><i class="fa fa-check"></i><b>10.2</b> Columns</a><ul>
<li class="chapter" data-level="10.2.1" data-path="distributed.html"><a href="distributed.html#inference"><i class="fa fa-check"></i><b>10.2.1</b> Inference</a></li>
<li class="chapter" data-level="10.2.2" data-path="distributed.html"><a href="distributed.html#excplicit"><i class="fa fa-check"></i><b>10.2.2</b> Excplicit</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="distributed.html"><a href="distributed.html#grouping"><i class="fa fa-check"></i><b>10.3</b> Grouping</a></li>
<li class="chapter" data-level="10.4" data-path="distributed.html"><a href="distributed.html#packages"><i class="fa fa-check"></i><b>10.4</b> Packages</a></li>
<li class="chapter" data-level="10.5" data-path="distributed.html"><a href="distributed.html#context"><i class="fa fa-check"></i><b>10.5</b> Context</a></li>
<li class="chapter" data-level="10.6" data-path="distributed.html"><a href="distributed.html#restrictions"><i class="fa fa-check"></i><b>10.6</b> Restrictions</a><ul>
<li class="chapter" data-level="10.6.1" data-path="distributed.html"><a href="distributed.html#troubleshooting-3"><i class="fa fa-check"></i><b>10.6.1</b> Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="distributed.html"><a href="distributed.html#clusters-1"><i class="fa fa-check"></i><b>10.7</b> Clusters</a></li>
<li class="chapter" data-level="10.8" data-path="distributed.html"><a href="distributed.html#apache-arrow"><i class="fa fa-check"></i><b>10.8</b> Apache Arrow</a></li>
<li class="chapter" data-level="10.9" data-path="distributed.html"><a href="distributed.html#recap-4"><i class="fa fa-check"></i><b>10.9</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="streaming.html"><a href="streaming.html"><i class="fa fa-check"></i><b>11</b> Streaming</a><ul>
<li class="chapter" data-level="11.1" data-path="streaming.html"><a href="streaming.html#overview-3"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="streaming.html"><a href="streaming.html#streaming-treansform"><i class="fa fa-check"></i><b>11.2</b> Transformations</a><ul>
<li class="chapter" data-level="11.2.1" data-path="streaming.html"><a href="streaming.html#streams-dplyr"><i class="fa fa-check"></i><b>11.2.1</b> dplyr</a></li>
<li class="chapter" data-level="11.2.2" data-path="streaming.html"><a href="streaming.html#streams-pipelines"><i class="fa fa-check"></i><b>11.2.2</b> Pipelines</a></li>
<li class="chapter" data-level="11.2.3" data-path="streaming.html"><a href="streaming.html#streams-r"><i class="fa fa-check"></i><b>11.2.3</b> R Code</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="streaming.html"><a href="streaming.html#shiny"><i class="fa fa-check"></i><b>11.3</b> Shiny</a></li>
<li class="chapter" data-level="11.4" data-path="streaming.html"><a href="streaming.html#formats-1"><i class="fa fa-check"></i><b>11.4</b> Formats</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="contributing.html"><a href="contributing.html"><i class="fa fa-check"></i><b>12</b> Contributing</a><ul>
<li class="chapter" data-level="12.1" data-path="contributing.html"><a href="contributing.html#overview-4"><i class="fa fa-check"></i><b>12.1</b> Overview</a></li>
<li class="chapter" data-level="12.2" data-path="contributing.html"><a href="contributing.html#contributing-r-extension"><i class="fa fa-check"></i><b>12.2</b> R Extensions</a></li>
<li class="chapter" data-level="12.3" data-path="contributing.html"><a href="contributing.html#scala-extensions"><i class="fa fa-check"></i><b>12.3</b> Scala Extensions</a><ul>
<li class="chapter" data-level="12.3.1" data-path="contributing.html"><a href="contributing.html#scala-extension-prereq"><i class="fa fa-check"></i><b>12.3.1</b> Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="contributing.html"><a href="contributing.html#spark-extensions"><i class="fa fa-check"></i><b>12.4</b> Spark Extensions</a></li>
<li class="chapter" data-level="12.5" data-path="contributing.html"><a href="contributing.html#r-packages"><i class="fa fa-check"></i><b>12.5</b> R Packages</a><ul>
<li class="chapter" data-level="12.5.1" data-path="contributing.html"><a href="contributing.html#rstudio-projects"><i class="fa fa-check"></i><b>12.5.1</b> RStudio Projects</a></li>
<li class="chapter" data-level="12.5.2" data-path="contributing.html"><a href="contributing.html#troubleshooting-4"><i class="fa fa-check"></i><b>12.5.2</b> Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="contributing.html"><a href="contributing.html#contributing-sparklyr"><i class="fa fa-check"></i><b>12.6</b> sparklyr</a><ul>
<li class="chapter" data-level="12.6.1" data-path="contributing.html"><a href="contributing.html#compiling"><i class="fa fa-check"></i><b>12.6.1</b> Compiling</a></li>
<li class="chapter" data-level="12.6.2" data-path="contributing.html"><a href="contributing.html#serialization"><i class="fa fa-check"></i><b>12.6.2</b> Serialization</a></li>
<li class="chapter" data-level="12.6.3" data-path="contributing.html"><a href="contributing.html#invocations"><i class="fa fa-check"></i><b>12.6.3</b> Invocations</a></li>
<li class="chapter" data-level="12.6.4" data-path="contributing.html"><a href="contributing.html#r-packages-1"><i class="fa fa-check"></i><b>12.6.4</b> R Packages</a></li>
<li class="chapter" data-level="12.6.5" data-path="contributing.html"><a href="contributing.html#connections-1"><i class="fa fa-check"></i><b>12.6.5</b> Connections</a></li>
<li class="chapter" data-level="12.6.6" data-path="contributing.html"><a href="contributing.html#distributed-r"><i class="fa fa-check"></i><b>12.6.6</b> Distributed R</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="contributing.html"><a href="contributing.html#recap-5"><i class="fa fa-check"></i><b>12.7</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>13</b> Appendix</a><ul>
<li class="chapter" data-level="13.1" data-path="appendix.html"><a href="appendix.html#diagrams"><i class="fa fa-check"></i><b>13.1</b> Diagrams</a><ul>
<li class="chapter" data-level="13.1.1" data-path="appendix.html"><a href="appendix.html#appendix-storage-capacity"><i class="fa fa-check"></i><b>13.1.1</b> Worlds Store Capacity</a></li>
<li class="chapter" data-level="13.1.2" data-path="appendix.html"><a href="appendix.html#appendix-cran-downloads"><i class="fa fa-check"></i><b>13.1.2</b> Daily downloads of CRAN packages</a></li>
<li class="chapter" data-level="13.1.3" data-path="appendix.html"><a href="appendix.html#appendix-cluster-trends"><i class="fa fa-check"></i><b>13.1.3</b> Google trends for mainframes, cloud computing and kubernetes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>14</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The R in Spark: Learning Apache Spark with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="connections" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Connections</h1>
<p>The previous chapter, <a href="clusters.html#clusters">Clusters</a>, presented the major cluster computing paradigms, cluster managers and cluster providers; this section presents the internal components of a Spark cluster and the how to perform connections to any cluster running Apache Spark.</p>
<div id="connections-overview" class="section level2">
<h2><span class="header-section-number">6.1</span> Overview</h2>
<p>Before explaining how to connect to Spark clusters, we will introduce the components of a Spark cluster and how they interact, this is often known as the architecture of Apache Spark.</p>
<p>First, lets go over a couple definitions. As you know from previous chapters, a cluster is a collection of machines to perform analysis beyond a single computer. However, in distributed systems and clusters literature, we often refer to each physical machine as a compute instance, compute node, or simply instance or node for short. It is helpful to remind this while reading through this chapter and making use of external resource.</p>
<p>In a Spark cluster, there are three types of compute instances that are relevant to Spark: The <strong>driver node</strong>, the <strong>worker nodes</strong> and the <strong>cluster manager</strong>. A cluster manager is a service that allows Spark to be executed in the cluster as described in the previous <a href="clusters.html#clusters-manager">Cluster Managers</a> section. The <strong>driver node</strong> is tasked with delegating work to the worker nodes, but also for aggregating their results and controlling computation flow. For the most part, aggregation happens in the worker nodes; however, even after the nodes aggregate data, it is often the case that the driver node would have to collect the worker’s results. Therefore, the driver node usually has at least, but often much more, compute resources (read RAM, CPU, Local Storage, etc.) than the worker node. The <strong>worker nodes</strong> execute compute tasks over partitioned data and communicate intermediate results to other workers or back to the driver node, worker nodes are also referred as <strong>executors</strong>.</p>
<p>Strictly speaking, the driver node and worker nodes are just names assigned to machines with particular roles, while the actual computation in the driver node is performed by the <strong>spark context</strong>. The Spark context is a Spark component tasked with scheduling tasks, managing data and so on. In the worker nodes, the actual computation is performed under a <strong>spark executor</strong>, which is also a Spark component tasked with executing subtasks against a data partition.</p>
<div class="figure" style="text-align: center"><span id="fig:connections-architecture"></span>
<div id="htmlwidget-968506fa0f0d62ccdca3" style="width:100%;height:200pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-968506fa0f0d62ccdca3">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Driver | [Spark Context]] \n[Driver]-[Cluster Manager]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.1: Apache Spark Architecture
</p>
</div>
<p>If you already have a Spark cluster in your organization, you should request from your cluster administrator the connection information to this cluster, read carefully their usage policies and follow their advice. Since a cluster may be shared among many users, you want to make sure to request only the compute resources you need, choosing resources will be detailed in the <a href="#tunning">Tunning</a> chapter. Your system administrator will describe if it’s an <strong>on-premise</strong> vs <strong>cloud</strong> cluster, the <strong>cluster manager</strong> being used, supported <strong>connections</strong> and supported <strong>tools</strong>. You can use this information to jump directly to <a href="connections.html#connections-local">Local</a>, <a href="connections.html#connections-standalone">Standalone</a>, <a href="connections.html#connections-yarn">YARN</a>, <a href="connections.html#connections-mesos">Mesos</a>, <a href="connections.html#connections-livy">Livy</a> or <a href="connections.html#connections-kubernetes">Kubernetes</a> based on the information provided to you.</p>
<div id="connections-spark-edge-nodes" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Edge Nodes</h3>
<p>Before connecting to Apache Spark, you will first have to connect to the cluster. Usually, by connecting to an edge node within the cluster. An edge node, is a machine that can accessed from outside the cluster but which is also part of the cluster. There are two methods to connect to this edge instance:</p>
<ul>
<li><strong>Terminal</strong>: Using a <a href="https://en.wikipedia.org/wiki/Computer_terminal">computer terminal</a> application, one can use a <a href="https://en.wikipedia.org/wiki/Secure_Shell">secure shell</a> to establish a remote connection into the cluster, once you connect into the cluster, you can launch R and then use <code>sparklyr</code>. However, using only a terminal is cumbersome for many tasks and is often only used while configuring or troubleshooting issues.</li>
<li><strong>Web Browser</strong>: While using <code>sparklyr</code> from a terminal is possible, it is usually more productive to install a <strong>web server</strong> in an edge node that provides access to run R with <code>sparklyr</code> from a web browser. Most likely, you will want to consider using <a href="RStudio%20Server">RStudio</a> or Jupyter rather than connecting from the terminal.</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:connections-spark-edge"></span>
<div id="htmlwidget-1a3364b001a3a4fda14a" style="width:100%;height:200pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-1a3364b001a3a4fda14a">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Client|\n  [Terminal]\n  [Web Browser |\n    [RStudio]\n    [Jupyter]\n  ]\n]-[<hidden> Secure Shell / HTTP]\n\n[Secure Shell / HTTP]-[Edge|\n  [Secure Shell Server] - [R]\n  [RStudio Server] - [R]\n  [Jupyter Server] - [R]\n]","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.2: Connecting to Sparks Edge Node
</p>
</div>
</div>
<div id="connections-spark-home" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Spark Home</h3>
<p>It is important to mention that, while connecting to a Spark cluster, you will need to find out the correct <code>SPARK_HOME</code> path which contains the installation of Spark in the given instance. The <code>SPARK_HOME</code> path must be specified by your system administrator as an environment variable or by yourself explicitly specified in <code>spark_connect()</code> using the <code>spark_home</code> parameter.</p>
<p>If your cluster provider or cluster administrator already provided <code>SPARK_HOME</code> for you, the following code should return a path instead of an empty string.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" data-line-number="1"><span class="kw">Sys.getenv</span>(<span class="st">&quot;SPARK_HOME&quot;</span>)</a></code></pre></div>
<pre><code>[1] &quot;&quot;</code></pre>
<p>For system administrators, we recommend setting <code>SPARK_HOME</code> for all the users in your cluster; however, if this is not set in your cluster, you can also specify <code>SPARK_HOME</code> while using <code>spark_connect()</code> as follows:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;cluster-master&quot;</span>, <span class="dt">spark_home =</span> <span class="st">&quot;local/path/to/spark&quot;</span>)</a></code></pre></div>
<p>Where <code>cluster-master</code> is set to the correct cluster manager master for <a href="Standalone">Spark Standalone</a>, <a href="Yarn">YARN</a>, <a href="connections.html#connections-mesos">Mesos</a>, etc.</p>
</div>
</div>
<div id="connections-local" class="section level2">
<h2><span class="header-section-number">6.2</span> Local</h2>
<p>When connecting to Spark in local mode, Spark starts as a single application simulating a cluster with a single node, this is not a proper computing cluster but is ideal to perform work offline and troubleshoot issues. A local connection to Spark is represented in the following diagram:</p>
<div class="figure" style="text-align: center"><span id="fig:connections-local"></span>
<div id="htmlwidget-367551ddcbfd3eb07a0d" style="width:100%;height:160pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-367551ddcbfd3eb07a0d">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Driver|\n  [R]\n  [sparklyr]\n  [spark-submit]\n  [Spark Context]\n  [Spark Executor]\n]","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.3: Local Connection Diagram
</p>
</div>
<p>Notice that in the local connections diagram, there is no cluster manager nor worker process since, in local mode, everything runs inside the driver application. It’s also worth pointing out that <code>sparklyr</code> starts the Spark Context through <code>spark-submit</code>, a script available in every Spark installation to enable users to submit custom application to Spark which <code>sparklyr</code> makes use of to submit itself to Spark. For the curious reader, the <a href="contributing.html#contributing">Contributing</a> chapter explains the internal processes that take place in <code>sparklyr</code> to submit this application and connect properly from R.</p>
<p>To perform this local connection, we can connect with the following familiar code used in previous chapters:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" data-line-number="1"><span class="co"># Connect to local Spark instance</span></a>
<a class="sourceLine" id="cb44-2" data-line-number="2">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>)</a></code></pre></div>
<p>By default, <code>sparklyr</code>, will connect using as many CPU cores are available in your compute instance; however, this can be customized by connecting using <code>master=&quot;local[n]&quot;</code>, where <code>n</code> is the desired number of cores to use. For example, we can connect using only 2 CPU cores as follows:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1"><span class="co"># Connect to local Spark instance using 2 cores</span></a>
<a class="sourceLine" id="cb45-2" data-line-number="2">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local[2]&quot;</span>)</a></code></pre></div>
</div>
<div id="connections-standalone" class="section level2">
<h2><span class="header-section-number">6.3</span> Standalone</h2>
<p>Connecting to a Spark Standalone cluster requires the location of the cluster manager’s master instance, this location can be found in the cluster manager web interface as described in the <a href="standalone%20cluster">clusters-standalone</a> section, you can find this location by looking for a URL starting with <code>spark://</code>.</p>
<p>A connection in standalone mode starts from <code>sparklyr</code> launching <code>spark-submit</code> to submit the <code>sparklyr</code> application and creating the Spark Context, this requests executors from the Spark Standalone instance running under the <code>master</code> URL location:</p>
<div class="figure" style="text-align: center"><span id="fig:connections-standalone"></span>
<div id="htmlwidget-abd738e3d2ce456a6c9a" style="width:100%;height:200pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-abd738e3d2ce456a6c9a">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Driver |\n  [R]\n  [sparklyr]\n  [spark-submit]\n  [Spark Context]\n] \n[Driver]-[Cluster Manager |\n  [Spark Standalone]]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.4: Spark Standalone Connection Diagram
</p>
</div>
<p>In order to connect, use <code>master=&quot;spark://hostname:port&quot;</code> in <code>spark_connect()</code> as follows:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;spark://hostname:port&quot;</span>)</a></code></pre></div>
</div>
<div id="connections-yarn" class="section level2">
<h2><span class="header-section-number">6.4</span> Yarn</h2>
<p>Hadoop YARN supports two connection modes: YARN Client and YARN Cluster. However, YARN Client mode is much more common that YARN Cluster since it’s more efficient and easier to set up.</p>
<div id="connections-yarn-client" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Yarn Client</h3>
<p>When connecting in YARN Client mode, the driver instance runs R, sparklyr and the Spark Context which requests worker nodes from YARN to run Spark executors as follows:</p>
<div class="figure" style="text-align: center"><span id="fig:connections-yarn"></span>
<div id="htmlwidget-3c05c185044264b047c1" style="width:100%;height:250pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-3c05c185044264b047c1">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Driver |\n  [R]\n  [sparklyr]\n  [spark-submit]\n  [Spark Context]\n] \n[Driver]-[Cluster Manager |\n  [Yarn]]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.5: YARN Client Connection Diagram
</p>
</div>
<p>To connect, one can simply run with <code>master = &quot;yarn&quot;</code> as follows:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" data-line-number="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;yarn-client&quot;</span>)</a></code></pre></div>
<p>Once connected, you can use all techniques described in previous chapters using the <code>sc</code> connection; for instances, you can do <a href="analysis">data analysis</a> or <a href="modeling.html#modeling">modeling</a>.</p>
</div>
<div id="connections-yarn-cluster" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Yarn Cluster</h3>
<p>The main difference between YARN Cluster mode and YARN Client mode is that in YARN Cluster mode, the driver node is not required to be the node where R and sparklyr get started; instead, the driver node remains the designated driver node which is usually a different node than the edge node where R is running. It can be helpful to consider using YARN Cluster when the edge node has too many concurrent users, is lacking computing resources or where tools (like RStudio) need to be managed independently of other cluster resources.</p>
<div class="figure" style="text-align: center"><span id="fig:connections-yarn-cluster"></span>
<div id="htmlwidget-9d415fe85a2fb31f62e4" style="width:100%;height:240pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-9d415fe85a2fb31f62e4">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Client |\n  [R]\n  [sparklyr]\n  [spark-submit]\n]\n[Client]-[Cluster Manager]\n[Client]-[Driver |\n  [sparklyr]\n  [Spark Context]\n] \n[Cluster Manager |\n  [Yarn]\n]\n[Driver]-[Cluster Manager]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.6: YARN Cluster Connection Diagram
</p>
</div>
<p>To connect in YARN Cluster mode, we can simple run:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;yarn-cluster&quot;</span>)</a></code></pre></div>
<p>This connection assumes that the node running <code>spark_connect()</code> is properly configured, meaning that, <code>yarn-site.xml</code> exists and the <code>YARN_CONF_DIR</code> environment variable is properly set. When using Hadoop as a file system, one would also need the <code>HADOOP_CONF_DIR</code> environment variable properly configured. This configuration is usually provided by your system administrator and is not something that you would have to manually configure.</p>
</div>
</div>
<div id="connections-livy" class="section level2">
<h2><span class="header-section-number">6.5</span> Livy</h2>
<p>As opposed to other connection methods which require using an edge node in the cluster, <a href="clusters-livy">Livy</a> Livy provides a <strong>Web API</strong> that makes the Spark cluster accessible from outside the cluster and neither requires a local installation in the client. Once connected through the Web API, the <strong>Livy Service</strong> starts the Spark context by requesting resources from the cluster manager and distributing work as usual.</p>
<div class="figure" style="text-align: center"><span id="fig:connections-livy"></span>
<div id="htmlwidget-43075dd3729308e1c3e8" style="width:100%;height:240pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-43075dd3729308e1c3e8">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Client |\n  [R]\n  [sparklyr]\n]\n[Client]-[<hidden> Web API]\n[Web API]-[Driver |\n  [Livy Service]\n  [Spark Context]\n] \n[Cluster Manager]\n[Driver]-[Cluster Manager]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.7: Livy Connection Diagram
</p>
</div>
<p>Connecting through Livy requires the URL to the Livy service which should be similar to <code>https://hostname:port/livy</code>. Since remote connections are allowed, connections usually requires, at the very least, basic authentication:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" data-line-number="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;https://hostname:port/livy&quot;</span>, <span class="dt">method =</span> <span class="st">&quot;livy&quot;</span>, <span class="dt">config =</span> <span class="kw">livy_config</span>(</a>
<a class="sourceLine" id="cb49-2" data-line-number="2">  <span class="dt">username=</span><span class="st">&quot;&lt;username&gt;&quot;</span>,</a>
<a class="sourceLine" id="cb49-3" data-line-number="3">  <span class="dt">password=</span><span class="st">&quot;&lt;password&gt;&quot;</span></a>
<a class="sourceLine" id="cb49-4" data-line-number="4">))</a></code></pre></div>
<p>Once connected through Livy, operations you can make use of an other <code>sparklyr</code> feature; however, Livy is not suitable for experimental data analysis, since executing commands have a significant delay; that said, while running long running computations, this overhead could be considered irrelevant. In general, it is preferred to avoid using Livy and work directly within an edge node in the cluster; if this is not feasible, using Livy could be a reasonable approach.</p>
</div>
<div id="connections-mesos" class="section level2">
<h2><span class="header-section-number">6.6</span> Mesos</h2>
<p>Similar to YARN, Mesos supports client mode and a cluster mode. However, <code>sparklyr</code> currently only supports client mode for Mesos.</p>
<div class="figure" style="text-align: center"><span id="fig:connections-mesos"></span>
<div id="htmlwidget-a2bf7366cab1703f7696" style="width:100%;height:250pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-a2bf7366cab1703f7696">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Driver |\n  [R]\n  [sparklyr]\n  [spark-submit]\n  [Spark Context]\n] \n[Driver]-[Cluster Manager |\n  [Mesos]]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.8: Mesos Connection Diagram
</p>
</div>
<p>Connecting requires the address to the Mesos master node, usually in the form of <code>mesos://host:port</code> or <code>mesos://zk://host1:2181,host2:2181,host3:2181/mesos</code> for Mesos using ZooKeeper.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" data-line-number="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;mesos://host:port&quot;</span>)</a></code></pre></div>
</div>
<div id="connections-kubernetes" class="section level2">
<h2><span class="header-section-number">6.7</span> Kubernetes</h2>
<p>Kubernetes cluster do not support client modes similar to Mesos or YARN, instead, the connection model is similar to YARN Cluster, where the driver node is assigned by Kubernetes.</p>
<div class="figure" style="text-align: center"><span id="fig:connections-kubernetes"></span>
<div id="htmlwidget-1375b4d6c7aef4780668" style="width:100%;height:250pt;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-1375b4d6c7aef4780668">{"x":{"code":"\n  #fill: #FEFEFF\n  #lineWidth: 2\n  #zoom: 4\n   \n#padding: 16\n#fontSize: 18\n#direction: right\n#lineWidth:2\n#leading:1\n#spacing: 20\n#.hidden: visual=hidden\n\n\n[Client |\n  [R]\n  [sparklyr]\n  [spark-submit]\n]\n[Client]-[Cluster Manager]\n[Client]-[Driver]\n[Driver |\n  [sparklyr]\n  [Spark Context]\n] \n[Driver]-[Cluster Manager |\n  [Kubernetes]]\n[Cluster Manager]-[Worker (1) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (2) | [Spark Executor(s)]]\n[Cluster Manager]-[Worker (3) | [Spark Executor(s)]]\n","className":null,"svg":false},"evals":[],"jsHooks":[]}</script>
<p class="caption">
FIGURE 6.9: Kubernetes Connection Diagram
</p>
</div>
<p>Kubernetes support is scheduled to be added to <code>sparklyr</code> with <a href="https://github.com/rstudio/sparklyr/issues/1525">sparklyr/issues/1525</a>, please follow progress for this feature directly in github. Once Kubernetes becomes supported in <code>sparklyr</code>, connecting to Kubernetes will work as follows:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" data-line-number="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(</a>
<a class="sourceLine" id="cb51-2" data-line-number="2">  <span class="dt">master =</span> <span class="st">&quot;k8s://https://&lt;apiserver-host&gt;:&lt;apiserver-port&gt;&quot;</span></a>
<a class="sourceLine" id="cb51-3" data-line-number="3">  <span class="dt">config =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb51-4" data-line-number="4">    <span class="dt">spark.executor.instances =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb51-5" data-line-number="5">    <span class="dt">spark.kubernetes.container.image =</span> <span class="st">&quot;spark-image&quot;</span></a>
<a class="sourceLine" id="cb51-6" data-line-number="6">  )</a>
<a class="sourceLine" id="cb51-7" data-line-number="7">)</a></code></pre></div>
<p>If your computer is already configured to use a Kubernetes cluster, you can use the following command to find the <code>apiserver-host</code> and <code>apiserver-port</code>:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" data-line-number="1"><span class="kw">system2</span>(<span class="st">&quot;kubectl&quot;</span>, <span class="st">&quot;cluster-info&quot;</span>)</a></code></pre></div>
</div>
<div id="cloud-1" class="section level2">
<h2><span class="header-section-number">6.8</span> Cloud</h2>
<p>Connections to Spark from Databricks requires the following custom connection method:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" data-line-number="1"><span class="kw">library</span>(sparklyr)</a>
<a class="sourceLine" id="cb53-2" data-line-number="2">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">method =</span> <span class="st">&quot;databricks&quot;</span>)</a></code></pre></div>
<p>Similarly, connections to Spark when using IBM’s Watson Studio require a custom connection method:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" data-line-number="1">kernels &lt;-<span class="st"> </span><span class="kw">load_spark_kernels</span>()</a>
<a class="sourceLine" id="cb54-2" data-line-number="2">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">config =</span> kernels[<span class="dv">2</span>])</a></code></pre></div>
<p>Under Microsoft Azure HDInsights and when using ML Services (R Server), creating an <code>sparklyr</code> connection looks like the following:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" data-line-number="1"><span class="kw">library</span>(RevoScaleR)</a>
<a class="sourceLine" id="cb55-2" data-line-number="2">cc &lt;-<span class="st"> </span><span class="kw">rxSparkConnect</span>(<span class="dt">reset =</span> <span class="ot">TRUE</span>, <span class="dt">interop =</span> <span class="st">&quot;sparklyr&quot;</span>)</a>
<a class="sourceLine" id="cb55-3" data-line-number="3">sc &lt;-<span class="st"> </span><span class="kw">rxGetSparklyrConnection</span>(cc)</a></code></pre></div>
<p>In general, please reference your cloud provider documentation and their support channels if assistance is needed.</p>
</div>
<div id="multiple" class="section level2">
<h2><span class="header-section-number">6.9</span> Multiple</h2>
<p>It is common to connect once, and only once, to Spark. However, you can also open multiple connections to Spark by connecting to different clusters or by specifying the <code>app_name</code> parameter, this can be helpful to compare Spark versions or validate you analysis before submitting to the cluster. The following example opens connections to Spark 1.6.3, 2.3.0 and Spark Standalone:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" data-line-number="1"><span class="co"># Connect to local Spark 1.6.3</span></a>
<a class="sourceLine" id="cb56-2" data-line-number="2">sc_<span class="dv">1</span>_<span class="dv">6</span>_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;1.6.3&quot;</span>)</a>
<a class="sourceLine" id="cb56-3" data-line-number="3"></a>
<a class="sourceLine" id="cb56-4" data-line-number="4"><span class="co"># Connect to local Spark 2.3.0</span></a>
<a class="sourceLine" id="cb56-5" data-line-number="5">sc_<span class="dv">2</span>_<span class="dv">3</span>_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3.0&quot;</span>, <span class="dt">appName =</span> <span class="st">&quot;Spark23&quot;</span>)</a>
<a class="sourceLine" id="cb56-6" data-line-number="6"></a>
<a class="sourceLine" id="cb56-7" data-line-number="7"><span class="co"># Connect to local Spark Standalone</span></a>
<a class="sourceLine" id="cb56-8" data-line-number="8">sc_standalone &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;spark://host:port&quot;</span>)</a></code></pre></div>
<p>Finally, we can disconnect from each connection:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb57-1" data-line-number="1"><span class="kw">spark_disconnect</span>(sc_<span class="dv">1</span>_<span class="dv">6</span>_<span class="dv">3</span>)</a>
<a class="sourceLine" id="cb57-2" data-line-number="2"><span class="kw">spark_disconnect</span>(sc_<span class="dv">2</span>_<span class="dv">3</span>_<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb57-3" data-line-number="3"><span class="kw">spark_disconnect</span>(sc_standalone)</a></code></pre></div>
<p>Alternatively, you can disconnect from all connections at once:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" data-line-number="1"><span class="kw">spark_disconnect_all</span>()</a></code></pre></div>
</div>
<div id="troubleshooting" class="section level2">
<h2><span class="header-section-number">6.10</span> Troubleshooting</h2>
<div id="logging" class="section level3">
<h3><span class="header-section-number">6.10.1</span> Logging</h3>
<p>One first step is to troubleshoot connections is to run in verbose to print directly to the console additional error messages:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb59-1" data-line-number="1">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">log =</span> <span class="st">&quot;console&quot;</span>)</a></code></pre></div>
<p>Verbose logging can also be enabled with the following option:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" data-line-number="1"><span class="kw">options</span>(<span class="dt">sparklyr.verbose =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
</div>
<div id="troubleshoot-spark-submit" class="section level3">
<h3><span class="header-section-number">6.10.2</span> Spark Submit</h3>
<p>If connections fail in <code>sparklyr</code>, first troubleshoot if this issue is specific to <code>sparklyr</code> or Spark in general. This can be accomplished by running an example <code>spark-submit</code> job and validating that no errors are thrown:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" data-line-number="1"><span class="co"># Find the spark directory using an environment variable</span></a>
<a class="sourceLine" id="cb61-2" data-line-number="2"><span class="kw">Sys.getenv</span>(<span class="st">&quot;SPARK_HOME&quot;</span>)</a>
<a class="sourceLine" id="cb61-3" data-line-number="3"></a>
<a class="sourceLine" id="cb61-4" data-line-number="4"><span class="co"># Or by getting the local spark installation</span></a>
<a class="sourceLine" id="cb61-5" data-line-number="5">sparklyr<span class="op">::</span><span class="kw">spark_home_dir</span>()</a></code></pre></div>
<p>From the terminal run:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb62-1" data-line-number="1"><span class="bu">cd</span> path/to/spark/</a>
<a class="sourceLine" id="cb62-2" data-line-number="2"><span class="ex">bin/spark-submit</span> </a></code></pre></div>
<div id="detailed" class="section level4">
<h4><span class="header-section-number">6.10.2.1</span> Detailed</h4>
<p>To troubleshoot the connection process in detail, you can manually replicate the two-step connection process, which is often very helpful to diagnose connection issues. Connecting to Spark is performed in two steps; first, <code>spark-submit</code> is triggered from R which submits the application to Spark, second, R connects to the running Spark application.</p>
<p>First, <a href="troubleshoot-spark-submit">identify the Spark installation directory</a> and the path to the correct <code>sparklyr*.jar</code> by running:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb63-1" data-line-number="1"><span class="kw">dir</span>(<span class="kw">system.file</span>(<span class="st">&quot;java&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;sparklyr&quot;</span>), <span class="dt">pattern =</span> <span class="st">&quot;sparklyr&quot;</span>, <span class="dt">full.names =</span> T)</a></code></pre></div>
<p>Make sure you identify the correct version that matches your Spark cluster, for instance <code>sparklyr-2.1-2.11.jar</code> for Spark 2.1.</p>
<p>Then, from the terminal, run:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb64-1" data-line-number="1"><span class="va">$SPARK_HOME</span><span class="ex">/bin/spark-submit</span> --class sparklyr.Shell <span class="va">$PATH_TO_SPARKLYR_JAR</span> 8880 12345</a></code></pre></div>
<pre><code>18/06/11 12:13:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/06/11 12:13:53 INFO sparklyr: Session (12345) is starting under 127.0.0.1 port 8880
18/06/11 12:13:53 INFO sparklyr: Session (12345) found port 8880 is available
18/06/11 12:13:53 INFO sparklyr: Gateway (12345) is waiting for sparklyr client to connect to port 8880</code></pre>
<p>The parameter <code>8880</code> represents the default port to use in <code>sparklyr</code> while <code>12345</code> is the session number, this is a cryptographically secure number generated by <code>sparklyr</code>, but for troubleshooting purposes can be as simple as <code>12345</code>.</p>
<p>If this first connection step fails, it means that the cluster can’t accept the application. This usually means that there are not enough resources, there are permission restrictions, etc.</p>
<p>The second step is to connect from R as follows, notice that there is a 60 seconds timeout, so you’ll have to run the R command after running the terminal command, if needed, this timeout can be configured as described in the <a href="#tunning">Tunning</a> chapter.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" data-line-number="1"><span class="kw">library</span>(sparklyr)</a>
<a class="sourceLine" id="cb66-2" data-line-number="2">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;sparklyr://localhost:8880/12345&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3&quot;</span>)</a></code></pre></div>
<p>If this second connection step fails, it usually means that there is a connectivity problem between R and the Driver node, you can try using a different connection port, for instance.</p>
</div>
</div>
<div id="windows" class="section level3">
<h3><span class="header-section-number">6.10.3</span> Windows</h3>
<p>Connecting from Windows is, in most cases, as straightforward as connecting from Linux or OS X; however, there are a few common connection issues you might hit t</p>
<ul>
<li>Firewalls and antivirus software might block ports for your connection. The default port used by <code>sparklyr</code> is <code>8880</code>, double check this port is not being blocked.</li>
<li>Long path names can cause issues in, specially, older Windows systems like Windows 7. When using these systems, try connecting with Spark installed with all folders using 8 characters or less.</li>
</ul>
</div>
</div>
<div id="recap-1" class="section level2">
<h2><span class="header-section-number">6.11</span> Recap</h2>
<p>This chapter presented an overview of Spark’s architecture, connection concepts and examples to connect in local mode, standalone, YARN, Mesos, Kubernetes and Livy. It also presented edge nodes and their role while connecting to Spark clusters. This should have provided you with enough information to successfully connect to any Apache Spark cluster.</p>
<p>To troubleshoot connection problems, it is recommended to search for the connection problem in StackOverflow, the <a href="https://github.com/rstudio/sparklyr/issues">sparklyr github issues</a> and, if needed, open a <a href="https://github.com/rstudio/sparklyr/issues/new">new GitHub issue in sparklyr</a> to assist further.</p>
<p>In the next chapter, <a href="data.html#data">Data</a>, you will learn how to read and write over multiple data sources, you will understand how Spark stores stores data as Spark DataFrames and how to transfer data into and out of Spark clusters.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="clusters.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
