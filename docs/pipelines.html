<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 5 Pipelines | Mastering Apache Spark with R</title>
  <meta name="description" content="The complete guide to large-scale analysis and modeling.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 5 Pipelines | Mastering Apache Spark with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The complete guide to large-scale analysis and modeling." />
  <meta name="github-repo" content="javierluraschi/the-r-in-spark" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Pipelines | Mastering Apache Spark with R" />
  
  <meta name="twitter:description" content="The complete guide to large-scale analysis and modeling." />
  

<meta name="author" content="Javier Luraschi, Kevin Kuo, Edgar Ruiz">


<meta name="date" content="2019-06-10">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="modeling.html">
<link rel="next" href="clusters.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/dagre-0.0.1/dagre.min.js"></script>
<script src="libs/lodash-3.7.0/lodash.js"></script>
<script src="libs/nomnoml-0.2.0/nomnoml.js"></script>
<script src="libs/nomnoml-binding-0.1.0/nomnoml.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119986300-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119986300-1');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Learning Apache Spark with R</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#intro-background"><i class="fa fa-check"></i><b>1.1</b> Information</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#intro-hadoop"><i class="fa fa-check"></i><b>1.2</b> Hadoop</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#intro-spark"><i class="fa fa-check"></i><b>1.3</b> Spark</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#intro-r"><i class="fa fa-check"></i><b>1.4</b> R</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#intro-sparklyr"><i class="fa fa-check"></i><b>1.5</b> sparklyr</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#intro-recap"><i class="fa fa-check"></i><b>1.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="starting.html"><a href="starting.html"><i class="fa fa-check"></i><b>2</b> Getting Started</a><ul>
<li class="chapter" data-level="2.1" data-path="starting.html"><a href="starting.html#starting-prerequisites"><i class="fa fa-check"></i><b>2.1</b> Prerequisites</a></li>
<li class="chapter" data-level="2.2" data-path="starting.html"><a href="starting.html#starting-install-sparklyr"><i class="fa fa-check"></i><b>2.2</b> Installing sparklyr</a></li>
<li class="chapter" data-level="2.3" data-path="starting.html"><a href="starting.html#starting-installing-spark"><i class="fa fa-check"></i><b>2.3</b> Installing Spark</a></li>
<li class="chapter" data-level="2.4" data-path="starting.html"><a href="starting.html#starting-connect-to-spark"><i class="fa fa-check"></i><b>2.4</b> Connecting to Spark</a></li>
<li class="chapter" data-level="2.5" data-path="starting.html"><a href="starting.html#starting-sparklyr-hello-world"><i class="fa fa-check"></i><b>2.5</b> Using Spark</a><ul>
<li class="chapter" data-level="2.5.1" data-path="starting.html"><a href="starting.html#starting-spark-web-interface"><i class="fa fa-check"></i><b>2.5.1</b> Web Interface</a></li>
<li class="chapter" data-level="2.5.2" data-path="starting.html"><a href="starting.html#starting-analysis"><i class="fa fa-check"></i><b>2.5.2</b> Analysis</a></li>
<li class="chapter" data-level="2.5.3" data-path="starting.html"><a href="starting.html#starting-modeling"><i class="fa fa-check"></i><b>2.5.3</b> Modeling</a></li>
<li class="chapter" data-level="2.5.4" data-path="starting.html"><a href="starting.html#starting-data"><i class="fa fa-check"></i><b>2.5.4</b> Data</a></li>
<li class="chapter" data-level="2.5.5" data-path="starting.html"><a href="starting.html#starting-extensions"><i class="fa fa-check"></i><b>2.5.5</b> Extensions</a></li>
<li class="chapter" data-level="2.5.6" data-path="starting.html"><a href="starting.html#starting-distributed-r"><i class="fa fa-check"></i><b>2.5.6</b> Distributed R</a></li>
<li class="chapter" data-level="2.5.7" data-path="starting.html"><a href="starting.html#starting-streaming"><i class="fa fa-check"></i><b>2.5.7</b> Streaming</a></li>
<li class="chapter" data-level="2.5.8" data-path="starting.html"><a href="starting.html#starting-logs"><i class="fa fa-check"></i><b>2.5.8</b> Logs</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="starting.html"><a href="starting.html#starting-disconnecting"><i class="fa fa-check"></i><b>2.6</b> Disconnecting</a></li>
<li class="chapter" data-level="2.7" data-path="starting.html"><a href="starting.html#starting-using-spark-from-rstudio"><i class="fa fa-check"></i><b>2.7</b> Using RStudio</a></li>
<li class="chapter" data-level="2.8" data-path="starting.html"><a href="starting.html#starting-resources"><i class="fa fa-check"></i><b>2.8</b> Resources</a></li>
<li class="chapter" data-level="2.9" data-path="starting.html"><a href="starting.html#starting-recap"><i class="fa fa-check"></i><b>2.9</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis.html"><a href="analysis.html"><i class="fa fa-check"></i><b>3</b> Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="analysis.html"><a href="analysis.html#r-as-an-interface-to-spark"><i class="fa fa-check"></i><b>3.1</b> R as an Interface to Spark</a><ul>
<li class="chapter" data-level="3.1.1" data-path="analysis.html"><a href="analysis.html#exercise"><i class="fa fa-check"></i><b>3.1.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="analysis.html"><a href="analysis.html#import-access"><i class="fa fa-check"></i><b>3.2</b> Import / Access</a></li>
<li class="chapter" data-level="3.3" data-path="analysis.html"><a href="analysis.html#wrangle"><i class="fa fa-check"></i><b>3.3</b> Wrangle</a><ul>
<li class="chapter" data-level="3.3.1" data-path="analysis.html"><a href="analysis.html#correlations"><i class="fa fa-check"></i><b>3.3.1</b> Correlations</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="analysis.html"><a href="analysis.html#visualize"><i class="fa fa-check"></i><b>3.4</b> Visualize</a><ul>
<li class="chapter" data-level="3.4.1" data-path="analysis.html"><a href="analysis.html#recommended-approach"><i class="fa fa-check"></i><b>3.4.1</b> Recommended approach</a></li>
<li class="chapter" data-level="3.4.2" data-path="analysis.html"><a href="analysis.html#simple-plots"><i class="fa fa-check"></i><b>3.4.2</b> Simple Plots</a></li>
<li class="chapter" data-level="3.4.3" data-path="analysis.html"><a href="analysis.html#histograms"><i class="fa fa-check"></i><b>3.4.3</b> Histograms</a></li>
<li class="chapter" data-level="3.4.4" data-path="analysis.html"><a href="analysis.html#scatter-vs-raster-plots"><i class="fa fa-check"></i><b>3.4.4</b> Scatter vs Raster Plots</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="analysis.html"><a href="analysis.html#model"><i class="fa fa-check"></i><b>3.5</b> Model</a><ul>
<li class="chapter" data-level="3.5.1" data-path="analysis.html"><a href="analysis.html#cache-model-data"><i class="fa fa-check"></i><b>3.5.1</b> Cache model data</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="analysis.html"><a href="analysis.html#communicate"><i class="fa fa-check"></i><b>3.6</b> Communicate</a><ul>
<li class="chapter" data-level="3.6.1" data-path="analysis.html"><a href="analysis.html#reports"><i class="fa fa-check"></i><b>3.6.1</b> Reports</a></li>
<li class="chapter" data-level="3.6.2" data-path="analysis.html"><a href="analysis.html#presentation-decks"><i class="fa fa-check"></i><b>3.6.2</b> Presentation decks</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="analysis.html"><a href="analysis.html#recap"><i class="fa fa-check"></i><b>3.7</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="modeling.html"><a href="modeling.html"><i class="fa fa-check"></i><b>4</b> Modeling</a><ul>
<li class="chapter" data-level="4.1" data-path="modeling.html"><a href="modeling.html#overview"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="modeling.html"><a href="modeling.html#the-data"><i class="fa fa-check"></i><b>4.2</b> The Data</a></li>
<li class="chapter" data-level="4.3" data-path="modeling.html"><a href="modeling.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>4.3</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="4.4" data-path="modeling.html"><a href="modeling.html#feature-engineering"><i class="fa fa-check"></i><b>4.4</b> Feature Engineering</a></li>
<li class="chapter" data-level="4.5" data-path="modeling.html"><a href="modeling.html#model-building"><i class="fa fa-check"></i><b>4.5</b> Model Building</a><ul>
<li class="chapter" data-level="4.5.1" data-path="modeling.html"><a href="modeling.html#logistic-regression-as-a-generalized-linear-regression"><i class="fa fa-check"></i><b>4.5.1</b> Logistic Regression as a Generalized Linear Regression</a></li>
<li class="chapter" data-level="4.5.2" data-path="modeling.html"><a href="modeling.html#more-machine-learning-algorithms"><i class="fa fa-check"></i><b>4.5.2</b> More Machine Learning Algorithms</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="modeling.html"><a href="modeling.html#working-with-textual-data"><i class="fa fa-check"></i><b>4.6</b> Working with Textual Data</a><ul>
<li class="chapter" data-level="4.6.1" data-path="modeling.html"><a href="modeling.html#data-prep"><i class="fa fa-check"></i><b>4.6.1</b> Data Prep</a></li>
<li class="chapter" data-level="4.6.2" data-path="modeling.html"><a href="modeling.html#topic-modeling"><i class="fa fa-check"></i><b>4.6.2</b> Topic Modeling</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="modeling.html"><a href="modeling.html#conclusion"><i class="fa fa-check"></i><b>4.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="pipelines.html"><a href="pipelines.html"><i class="fa fa-check"></i><b>5</b> Pipelines</a><ul>
<li class="chapter" data-level="5.1" data-path="pipelines.html"><a href="pipelines.html#estimators-and-transformers"><i class="fa fa-check"></i><b>5.1</b> Estimators and Transformers</a></li>
<li class="chapter" data-level="5.2" data-path="pipelines.html"><a href="pipelines.html#pipelines-and-pipeline-models"><i class="fa fa-check"></i><b>5.2</b> Pipelines and Pipeline Models</a></li>
<li class="chapter" data-level="5.3" data-path="pipelines.html"><a href="pipelines.html#applying-pipelines-to-okcupid-data"><i class="fa fa-check"></i><b>5.3</b> Applying Pipelines to OKCupid Data</a><ul>
<li class="chapter" data-level="5.3.1" data-path="pipelines.html"><a href="pipelines.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>5.3.1</b> Hyperparameter Tuning</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="pipelines.html"><a href="pipelines.html#operating-modes-of-pipelines-functions"><i class="fa fa-check"></i><b>5.4</b> Operating Modes of Pipelines Functions</a></li>
<li class="chapter" data-level="5.5" data-path="pipelines.html"><a href="pipelines.html#model-persistence-and-interoperability"><i class="fa fa-check"></i><b>5.5</b> Model Persistence and Interoperability</a></li>
<li class="chapter" data-level="5.6" data-path="pipelines.html"><a href="pipelines.html#model-deployment"><i class="fa fa-check"></i><b>5.6</b> Model Deployment</a><ul>
<li class="chapter" data-level="5.6.1" data-path="pipelines.html"><a href="pipelines.html#batch-scoring-with-ml-pipelines"><i class="fa fa-check"></i><b>5.6.1</b> Batch Scoring With ML Pipelines</a></li>
<li class="chapter" data-level="5.6.2" data-path="pipelines.html"><a href="pipelines.html#real-time-scoring-with-mleap"><i class="fa fa-check"></i><b>5.6.2</b> Real-Time Scoring with MLeap</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="pipelines.html"><a href="pipelines.html#conclusion-1"><i class="fa fa-check"></i><b>5.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="clusters.html"><a href="clusters.html"><i class="fa fa-check"></i><b>6</b> Clusters</a><ul>
<li class="chapter" data-level="6.1" data-path="clusters.html"><a href="clusters.html#clusters-overview"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="clusters.html"><a href="clusters.html#on-premise"><i class="fa fa-check"></i><b>6.2</b> On-Premise</a><ul>
<li class="chapter" data-level="6.2.1" data-path="clusters.html"><a href="clusters.html#clusters-manager"><i class="fa fa-check"></i><b>6.2.1</b> Managers</a></li>
<li class="chapter" data-level="6.2.2" data-path="clusters.html"><a href="clusters.html#distributions"><i class="fa fa-check"></i><b>6.2.2</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="clusters.html"><a href="clusters.html#cloud"><i class="fa fa-check"></i><b>6.3</b> Cloud</a><ul>
<li class="chapter" data-level="6.3.1" data-path="clusters.html"><a href="clusters.html#clusters-amazon-emr"><i class="fa fa-check"></i><b>6.3.1</b> Amazon</a></li>
<li class="chapter" data-level="6.3.2" data-path="clusters.html"><a href="clusters.html#databricks"><i class="fa fa-check"></i><b>6.3.2</b> Databricks</a></li>
<li class="chapter" data-level="6.3.3" data-path="clusters.html"><a href="clusters.html#google"><i class="fa fa-check"></i><b>6.3.3</b> Google</a></li>
<li class="chapter" data-level="6.3.4" data-path="clusters.html"><a href="clusters.html#ibm"><i class="fa fa-check"></i><b>6.3.4</b> IBM</a></li>
<li class="chapter" data-level="6.3.5" data-path="clusters.html"><a href="clusters.html#microsoft"><i class="fa fa-check"></i><b>6.3.5</b> Microsoft</a></li>
<li class="chapter" data-level="6.3.6" data-path="clusters.html"><a href="clusters.html#qubole"><i class="fa fa-check"></i><b>6.3.6</b> Qubole</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="clusters.html"><a href="clusters.html#kubernetes"><i class="fa fa-check"></i><b>6.4</b> Kubernetes</a></li>
<li class="chapter" data-level="6.5" data-path="clusters.html"><a href="clusters.html#tools"><i class="fa fa-check"></i><b>6.5</b> Tools</a><ul>
<li class="chapter" data-level="6.5.1" data-path="clusters.html"><a href="clusters.html#rstudio"><i class="fa fa-check"></i><b>6.5.1</b> RStudio</a></li>
<li class="chapter" data-level="6.5.2" data-path="clusters.html"><a href="clusters.html#jupyter"><i class="fa fa-check"></i><b>6.5.2</b> Jupyter</a></li>
<li class="chapter" data-level="6.5.3" data-path="clusters.html"><a href="clusters.html#clusters-livy"><i class="fa fa-check"></i><b>6.5.3</b> Livy</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="clusters.html"><a href="clusters.html#recap-1"><i class="fa fa-check"></i><b>6.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="connections.html"><a href="connections.html"><i class="fa fa-check"></i><b>7</b> Connections</a><ul>
<li class="chapter" data-level="7.1" data-path="connections.html"><a href="connections.html#connections-overview"><i class="fa fa-check"></i><b>7.1</b> Overview</a><ul>
<li class="chapter" data-level="7.1.1" data-path="connections.html"><a href="connections.html#connections-spark-edge-nodes"><i class="fa fa-check"></i><b>7.1.1</b> Edge Nodes</a></li>
<li class="chapter" data-level="7.1.2" data-path="connections.html"><a href="connections.html#connections-spark-home"><i class="fa fa-check"></i><b>7.1.2</b> Spark Home</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="connections.html"><a href="connections.html#connections-local"><i class="fa fa-check"></i><b>7.2</b> Local</a></li>
<li class="chapter" data-level="7.3" data-path="connections.html"><a href="connections.html#connections-standalone"><i class="fa fa-check"></i><b>7.3</b> Standalone</a></li>
<li class="chapter" data-level="7.4" data-path="connections.html"><a href="connections.html#connections-yarn"><i class="fa fa-check"></i><b>7.4</b> Yarn</a><ul>
<li class="chapter" data-level="7.4.1" data-path="connections.html"><a href="connections.html#connections-yarn-client"><i class="fa fa-check"></i><b>7.4.1</b> Yarn Client</a></li>
<li class="chapter" data-level="7.4.2" data-path="connections.html"><a href="connections.html#connections-yarn-cluster"><i class="fa fa-check"></i><b>7.4.2</b> Yarn Cluster</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="connections.html"><a href="connections.html#connections-livy"><i class="fa fa-check"></i><b>7.5</b> Livy</a></li>
<li class="chapter" data-level="7.6" data-path="connections.html"><a href="connections.html#connections-mesos"><i class="fa fa-check"></i><b>7.6</b> Mesos</a></li>
<li class="chapter" data-level="7.7" data-path="connections.html"><a href="connections.html#connections-kubernetes"><i class="fa fa-check"></i><b>7.7</b> Kubernetes</a></li>
<li class="chapter" data-level="7.8" data-path="connections.html"><a href="connections.html#cloud-1"><i class="fa fa-check"></i><b>7.8</b> Cloud</a></li>
<li class="chapter" data-level="7.9" data-path="connections.html"><a href="connections.html#batches"><i class="fa fa-check"></i><b>7.9</b> Batches</a></li>
<li class="chapter" data-level="7.10" data-path="connections.html"><a href="connections.html#tools-1"><i class="fa fa-check"></i><b>7.10</b> Tools</a></li>
<li class="chapter" data-level="7.11" data-path="connections.html"><a href="connections.html#multiple"><i class="fa fa-check"></i><b>7.11</b> Multiple</a></li>
<li class="chapter" data-level="7.12" data-path="connections.html"><a href="connections.html#connections-troubleshooting"><i class="fa fa-check"></i><b>7.12</b> Troubleshooting</a><ul>
<li class="chapter" data-level="7.12.1" data-path="connections.html"><a href="connections.html#logging"><i class="fa fa-check"></i><b>7.12.1</b> Logging</a></li>
<li class="chapter" data-level="7.12.2" data-path="connections.html"><a href="connections.html#troubleshoot-spark-submit"><i class="fa fa-check"></i><b>7.12.2</b> Spark Submit</a></li>
<li class="chapter" data-level="7.12.3" data-path="connections.html"><a href="connections.html#windows"><i class="fa fa-check"></i><b>7.12.3</b> Windows</a></li>
</ul></li>
<li class="chapter" data-level="7.13" data-path="connections.html"><a href="connections.html#recap-2"><i class="fa fa-check"></i><b>7.13</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>8</b> Data</a><ul>
<li class="chapter" data-level="8.1" data-path="data.html"><a href="data.html#source-types-and-file-systems"><i class="fa fa-check"></i><b>8.1</b> Source types and file systems</a><ul>
<li class="chapter" data-level="8.1.1" data-path="data.html"><a href="data.html#default-packages"><i class="fa fa-check"></i><b>8.1.1</b> Default packages</a></li>
<li class="chapter" data-level="8.1.2" data-path="data.html"><a href="data.html#source-types"><i class="fa fa-check"></i><b>8.1.2</b> Source types</a></li>
<li class="chapter" data-level="8.1.3" data-path="data.html"><a href="data.html#file-systems"><i class="fa fa-check"></i><b>8.1.3</b> File systems</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="data.html"><a href="data.html#reading-data"><i class="fa fa-check"></i><b>8.2</b> Reading data</a><ul>
<li class="chapter" data-level="8.2.1" data-path="data.html"><a href="data.html#folders-as-a-table"><i class="fa fa-check"></i><b>8.2.1</b> Folders as a table</a></li>
<li class="chapter" data-level="8.2.2" data-path="data.html"><a href="data.html#file-layout"><i class="fa fa-check"></i><b>8.2.2</b> File layout</a></li>
<li class="chapter" data-level="8.2.3" data-path="data.html"><a href="data.html#spark-memory"><i class="fa fa-check"></i><b>8.2.3</b> Spark memory</a></li>
<li class="chapter" data-level="8.2.4" data-path="data.html"><a href="data.html#column-names"><i class="fa fa-check"></i><b>8.2.4</b> Column Names</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="data.html"><a href="data.html#writing-data"><i class="fa fa-check"></i><b>8.3</b> Writing Data</a><ul>
<li class="chapter" data-level="8.3.1" data-path="data.html"><a href="data.html#spark-not-r-as-pass-through"><i class="fa fa-check"></i><b>8.3.1</b> Spark, not R, as pass-through</a></li>
<li class="chapter" data-level="8.3.2" data-path="data.html"><a href="data.html#practical-approach"><i class="fa fa-check"></i><b>8.3.2</b> Practical approach</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="data.html"><a href="data.html#date-time"><i class="fa fa-check"></i><b>8.4</b> Date &amp; time</a></li>
<li class="chapter" data-level="8.5" data-path="data.html"><a href="data.html#specific-types-and-protocols"><i class="fa fa-check"></i><b>8.5</b> Specific types and protocols</a><ul>
<li class="chapter" data-level="8.5.1" data-path="data.html"><a href="data.html#amazon-s3"><i class="fa fa-check"></i><b>8.5.1</b> Amazon S3</a></li>
<li class="chapter" data-level="8.5.2" data-path="data.html"><a href="data.html#sql"><i class="fa fa-check"></i><b>8.5.2</b> SQL</a></li>
<li class="chapter" data-level="8.5.3" data-path="data.html"><a href="data.html#hive"><i class="fa fa-check"></i><b>8.5.3</b> Hive</a></li>
<li class="chapter" data-level="8.5.4" data-path="data.html"><a href="data.html#comma-delimited-values-csv"><i class="fa fa-check"></i><b>8.5.4</b> Comma Delimited Values (CSV)</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="data.html"><a href="data.html#recap-3"><i class="fa fa-check"></i><b>8.6</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="tuning.html"><a href="tuning.html"><i class="fa fa-check"></i><b>9</b> Tuning</a><ul>
<li class="chapter" data-level="9.1" data-path="tuning.html"><a href="tuning.html#overview-1"><i class="fa fa-check"></i><b>9.1</b> Overview</a><ul>
<li class="chapter" data-level="9.1.1" data-path="tuning.html"><a href="tuning.html#tuning-graph-visualization"><i class="fa fa-check"></i><b>9.1.1</b> Graph</a></li>
<li class="chapter" data-level="9.1.2" data-path="tuning.html"><a href="tuning.html#tuning-event-timeline"><i class="fa fa-check"></i><b>9.1.2</b> Timeline</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="tuning.html"><a href="tuning.html#tuning-configuring"><i class="fa fa-check"></i><b>9.2</b> Configuring</a><ul>
<li class="chapter" data-level="9.2.1" data-path="tuning.html"><a href="tuning.html#connect-settings"><i class="fa fa-check"></i><b>9.2.1</b> Connect Settings</a></li>
<li class="chapter" data-level="9.2.2" data-path="tuning.html"><a href="tuning.html#submit-settings"><i class="fa fa-check"></i><b>9.2.2</b> Submit Settings</a></li>
<li class="chapter" data-level="9.2.3" data-path="tuning.html"><a href="tuning.html#runtime-settings"><i class="fa fa-check"></i><b>9.2.3</b> Runtime Settings</a></li>
<li class="chapter" data-level="9.2.4" data-path="tuning.html"><a href="tuning.html#sparklyr-settings"><i class="fa fa-check"></i><b>9.2.4</b> sparklyr Settings</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="tuning.html"><a href="tuning.html#tuning-partitioning"><i class="fa fa-check"></i><b>9.3</b> Partitioning</a><ul>
<li class="chapter" data-level="9.3.1" data-path="tuning.html"><a href="tuning.html#implicit"><i class="fa fa-check"></i><b>9.3.1</b> Implicit</a></li>
<li class="chapter" data-level="9.3.2" data-path="tuning.html"><a href="tuning.html#explicit"><i class="fa fa-check"></i><b>9.3.2</b> Explicit</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="tuning.html"><a href="tuning.html#tuning-caching"><i class="fa fa-check"></i><b>9.4</b> Caching</a><ul>
<li class="chapter" data-level="9.4.1" data-path="tuning.html"><a href="tuning.html#checkpointing"><i class="fa fa-check"></i><b>9.4.1</b> Checkpointing</a></li>
<li class="chapter" data-level="9.4.2" data-path="tuning.html"><a href="tuning.html#tuning-memory"><i class="fa fa-check"></i><b>9.4.2</b> Memory</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="tuning.html"><a href="tuning.html#tuning-shuffling"><i class="fa fa-check"></i><b>9.5</b> Shuffling</a></li>
<li class="chapter" data-level="9.6" data-path="tuning.html"><a href="tuning.html#tuning-serialization"><i class="fa fa-check"></i><b>9.6</b> Serialization</a></li>
<li class="chapter" data-level="9.7" data-path="tuning.html"><a href="tuning.html#configuration-files"><i class="fa fa-check"></i><b>9.7</b> Configuration Files</a></li>
<li class="chapter" data-level="9.8" data-path="tuning.html"><a href="tuning.html#recap-4"><i class="fa fa-check"></i><b>9.8</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="extensions.html"><a href="extensions.html"><i class="fa fa-check"></i><b>10</b> Extensions</a><ul>
<li class="chapter" data-level="10.1" data-path="extensions.html"><a href="extensions.html#overview-2"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="extensions.html"><a href="extensions.html#h2o"><i class="fa fa-check"></i><b>10.2</b> H2O</a></li>
<li class="chapter" data-level="10.3" data-path="extensions.html"><a href="extensions.html#graphs"><i class="fa fa-check"></i><b>10.3</b> Graphs</a></li>
<li class="chapter" data-level="10.4" data-path="extensions.html"><a href="extensions.html#xgboost"><i class="fa fa-check"></i><b>10.4</b> XGBoost</a></li>
<li class="chapter" data-level="10.5" data-path="extensions.html"><a href="extensions.html#deep-learning"><i class="fa fa-check"></i><b>10.5</b> Deep Learning</a></li>
<li class="chapter" data-level="10.6" data-path="extensions.html"><a href="extensions.html#genomics"><i class="fa fa-check"></i><b>10.6</b> Genomics</a></li>
<li class="chapter" data-level="10.7" data-path="extensions.html"><a href="extensions.html#spatial"><i class="fa fa-check"></i><b>10.7</b> Spatial</a></li>
<li class="chapter" data-level="10.8" data-path="extensions.html"><a href="extensions.html#troubleshooting"><i class="fa fa-check"></i><b>10.8</b> Troubleshooting</a></li>
<li class="chapter" data-level="10.9" data-path="extensions.html"><a href="extensions.html#recap-5"><i class="fa fa-check"></i><b>10.9</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="distributed.html"><a href="distributed.html"><i class="fa fa-check"></i><b>11</b> Distributed R</a><ul>
<li class="chapter" data-level="11.1" data-path="distributed.html"><a href="distributed.html#overview-3"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="distributed.html"><a href="distributed.html#use-cases"><i class="fa fa-check"></i><b>11.2</b> Use Cases</a><ul>
<li class="chapter" data-level="11.2.1" data-path="distributed.html"><a href="distributed.html#custom-parsers"><i class="fa fa-check"></i><b>11.2.1</b> Custom Parsers</a></li>
<li class="chapter" data-level="11.2.2" data-path="distributed.html"><a href="distributed.html#partitioned-modeling"><i class="fa fa-check"></i><b>11.2.2</b> Partitioned Modeling</a></li>
<li class="chapter" data-level="11.2.3" data-path="distributed.html"><a href="distributed.html#distributed-grid-search"><i class="fa fa-check"></i><b>11.2.3</b> Grid Search</a></li>
<li class="chapter" data-level="11.2.4" data-path="distributed.html"><a href="distributed.html#web-apis"><i class="fa fa-check"></i><b>11.2.4</b> Web APIs</a></li>
<li class="chapter" data-level="11.2.5" data-path="distributed.html"><a href="distributed.html#intensive-computations"><i class="fa fa-check"></i><b>11.2.5</b> Intensive Computations</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="distributed.html"><a href="distributed.html#partitions"><i class="fa fa-check"></i><b>11.3</b> Partitions</a></li>
<li class="chapter" data-level="11.4" data-path="distributed.html"><a href="distributed.html#grouping"><i class="fa fa-check"></i><b>11.4</b> Grouping</a></li>
<li class="chapter" data-level="11.5" data-path="distributed.html"><a href="distributed.html#columns"><i class="fa fa-check"></i><b>11.5</b> Columns</a></li>
<li class="chapter" data-level="11.6" data-path="distributed.html"><a href="distributed.html#context"><i class="fa fa-check"></i><b>11.6</b> Context</a></li>
<li class="chapter" data-level="11.7" data-path="distributed.html"><a href="distributed.html#functions"><i class="fa fa-check"></i><b>11.7</b> Functions</a></li>
<li class="chapter" data-level="11.8" data-path="distributed.html"><a href="distributed.html#packages"><i class="fa fa-check"></i><b>11.8</b> Packages</a></li>
<li class="chapter" data-level="11.9" data-path="distributed.html"><a href="distributed.html#cluster-requirements"><i class="fa fa-check"></i><b>11.9</b> Cluster Requirements</a><ul>
<li class="chapter" data-level="11.9.1" data-path="distributed.html"><a href="distributed.html#installing-r"><i class="fa fa-check"></i><b>11.9.1</b> Installing R</a></li>
<li class="chapter" data-level="11.9.2" data-path="distributed.html"><a href="distributed.html#apache-arrow"><i class="fa fa-check"></i><b>11.9.2</b> Apache Arrow</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="distributed.html"><a href="distributed.html#troubleshooting-1"><i class="fa fa-check"></i><b>11.10</b> Troubleshooting</a><ul>
<li class="chapter" data-level="11.10.1" data-path="distributed.html"><a href="distributed.html#worker-logs"><i class="fa fa-check"></i><b>11.10.1</b> Worker Logs</a></li>
<li class="chapter" data-level="11.10.2" data-path="distributed.html"><a href="distributed.html#resolving-timeouts"><i class="fa fa-check"></i><b>11.10.2</b> Resolving Timeouts</a></li>
<li class="chapter" data-level="11.10.3" data-path="distributed.html"><a href="distributed.html#inspecting-partition"><i class="fa fa-check"></i><b>11.10.3</b> Inspecting Partition</a></li>
<li class="chapter" data-level="11.10.4" data-path="distributed.html"><a href="distributed.html#debugging-workers"><i class="fa fa-check"></i><b>11.10.4</b> Debugging Workers</a></li>
</ul></li>
<li class="chapter" data-level="11.11" data-path="distributed.html"><a href="distributed.html#recap-6"><i class="fa fa-check"></i><b>11.11</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="streaming.html"><a href="streaming.html"><i class="fa fa-check"></i><b>12</b> Streaming</a><ul>
<li class="chapter" data-level="12.1" data-path="streaming.html"><a href="streaming.html#spark-streaming"><i class="fa fa-check"></i><b>12.1</b> Spark Streaming</a></li>
<li class="chapter" data-level="12.2" data-path="streaming.html"><a href="streaming.html#working-with-spark-streams"><i class="fa fa-check"></i><b>12.2</b> Working with Spark Streams</a></li>
<li class="chapter" data-level="12.3" data-path="streaming.html"><a href="streaming.html#sparklyr-extras"><i class="fa fa-check"></i><b>12.3</b> <code>sparklyr</code> extras</a><ul>
<li class="chapter" data-level="12.3.1" data-path="streaming.html"><a href="streaming.html#stream-monitor"><i class="fa fa-check"></i><b>12.3.1</b> Stream monitor</a></li>
<li class="chapter" data-level="12.3.2" data-path="streaming.html"><a href="streaming.html#stream-generator"><i class="fa fa-check"></i><b>12.3.2</b> Stream generator</a></li>
<li class="chapter" data-level="12.3.3" data-path="streaming.html"><a href="streaming.html#shiny-reactive"><i class="fa fa-check"></i><b>12.3.3</b> Shiny reactive</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="streaming.html"><a href="streaming.html#intro-example"><i class="fa fa-check"></i><b>12.4</b> Intro example</a></li>
<li class="chapter" data-level="12.5" data-path="streaming.html"><a href="streaming.html#transformations"><i class="fa fa-check"></i><b>12.5</b> Transformations</a><ul>
<li class="chapter" data-level="12.5.1" data-path="streaming.html"><a href="streaming.html#dplyr"><i class="fa fa-check"></i><b>12.5.1</b> dplyr</a></li>
<li class="chapter" data-level="12.5.2" data-path="streaming.html"><a href="streaming.html#transformer-functions"><i class="fa fa-check"></i><b>12.5.2</b> Transformer functions</a></li>
<li class="chapter" data-level="12.5.3" data-path="streaming.html"><a href="streaming.html#r-code"><i class="fa fa-check"></i><b>12.5.3</b> R code</a></li>
<li class="chapter" data-level="12.5.4" data-path="streaming.html"><a href="streaming.html#ml-pipelines"><i class="fa fa-check"></i><b>12.5.4</b> ML Pipelines</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="streaming.html"><a href="streaming.html#shiny-integration"><i class="fa fa-check"></i><b>12.6</b> Shiny integration</a></li>
<li class="chapter" data-level="12.7" data-path="streaming.html"><a href="streaming.html#kafka"><i class="fa fa-check"></i><b>12.7</b> Kafka</a><ul>
<li class="chapter" data-level="12.7.1" data-path="streaming.html"><a href="streaming.html#workflow"><i class="fa fa-check"></i><b>12.7.1</b> Workflow</a></li>
<li class="chapter" data-level="12.7.2" data-path="streaming.html"><a href="streaming.html#spark-integration"><i class="fa fa-check"></i><b>12.7.2</b> Spark integration</a></li>
<li class="chapter" data-level="12.7.3" data-path="streaming.html"><a href="streaming.html#r-integration"><i class="fa fa-check"></i><b>12.7.3</b> R integration</a></li>
<li class="chapter" data-level="12.7.4" data-path="streaming.html"><a href="streaming.html#example"><i class="fa fa-check"></i><b>12.7.4</b> Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="contributing.html"><a href="contributing.html"><i class="fa fa-check"></i><b>13</b> Contributing</a><ul>
<li class="chapter" data-level="13.1" data-path="contributing.html"><a href="contributing.html#contributing-overview"><i class="fa fa-check"></i><b>13.1</b> Overview</a></li>
<li class="chapter" data-level="13.2" data-path="contributing.html"><a href="contributing.html#contributing-spark-api"><i class="fa fa-check"></i><b>13.2</b> Spark API</a></li>
<li class="chapter" data-level="13.3" data-path="contributing.html"><a href="contributing.html#spark-extensions"><i class="fa fa-check"></i><b>13.3</b> Spark Extensions</a></li>
<li class="chapter" data-level="13.4" data-path="contributing.html"><a href="contributing.html#scala-code"><i class="fa fa-check"></i><b>13.4</b> Scala Code</a></li>
<li class="chapter" data-level="13.5" data-path="contributing.html"><a href="contributing.html#recap-7"><i class="fa fa-check"></i><b>13.5</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>14</b> Appendix</a><ul>
<li class="chapter" data-level="14.1" data-path="appendix.html"><a href="appendix.html#appendix-prerequisites"><i class="fa fa-check"></i><b>14.1</b> Prerequisites</a><ul>
<li class="chapter" data-level="14.1.1" data-path="appendix.html"><a href="appendix.html#appendix-install-r"><i class="fa fa-check"></i><b>14.1.1</b> Installing R</a></li>
<li class="chapter" data-level="14.1.2" data-path="appendix.html"><a href="appendix.html#appendix-install-java"><i class="fa fa-check"></i><b>14.1.2</b> Installing Java</a></li>
<li class="chapter" data-level="14.1.3" data-path="appendix.html"><a href="appendix.html#appendix-install-rstudio"><i class="fa fa-check"></i><b>14.1.3</b> Installing RStudio</a></li>
<li class="chapter" data-level="14.1.4" data-path="appendix.html"><a href="appendix.html#appendix-using-rstudio"><i class="fa fa-check"></i><b>14.1.4</b> Using RStudio</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="appendix.html"><a href="appendix.html#diagrams"><i class="fa fa-check"></i><b>14.2</b> Diagrams</a><ul>
<li class="chapter" data-level="14.2.1" data-path="appendix.html"><a href="appendix.html#appendix-storage-capacity"><i class="fa fa-check"></i><b>14.2.1</b> Worlds Store Capacity</a></li>
<li class="chapter" data-level="14.2.2" data-path="appendix.html"><a href="appendix.html#appendix-cran-downloads"><i class="fa fa-check"></i><b>14.2.2</b> Daily downloads of CRAN packages</a></li>
<li class="chapter" data-level="14.2.3" data-path="appendix.html"><a href="appendix.html#appendix-cluster-trends"><i class="fa fa-check"></i><b>14.2.3</b> Google trends for mainframes, cloud computing and kubernetes</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="appendix.html"><a href="appendix.html#appendix-ggplot2-theme"><i class="fa fa-check"></i><b>14.3</b> Formatting</a></li>
<li class="chapter" data-level="14.4" data-path="appendix.html"><a href="appendix.html#ml-functionlist"><i class="fa fa-check"></i><b>14.4</b> List of ML Functions</a><ul>
<li class="chapter" data-level="14.4.1" data-path="appendix.html"><a href="appendix.html#classification"><i class="fa fa-check"></i><b>14.4.1</b> Classification</a></li>
<li class="chapter" data-level="14.4.2" data-path="appendix.html"><a href="appendix.html#regression"><i class="fa fa-check"></i><b>14.4.2</b> Regression</a></li>
<li class="chapter" data-level="14.4.3" data-path="appendix.html"><a href="appendix.html#clustering"><i class="fa fa-check"></i><b>14.4.3</b> Clustering</a></li>
<li class="chapter" data-level="14.4.4" data-path="appendix.html"><a href="appendix.html#recommendation"><i class="fa fa-check"></i><b>14.4.4</b> Recommendation</a></li>
<li class="chapter" data-level="14.4.5" data-path="appendix.html"><a href="appendix.html#frequent-pattern-mining"><i class="fa fa-check"></i><b>14.4.5</b> Frequent Pattern Mining</a></li>
<li class="chapter" data-level="14.4.6" data-path="appendix.html"><a href="appendix.html#feature-transformers"><i class="fa fa-check"></i><b>14.4.6</b> Feature Transformers</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="appendix.html"><a href="appendix.html#kafka-1"><i class="fa fa-check"></i><b>14.5</b> Kafka</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>15</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mastering Apache Spark with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pipelines" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Pipelines</h1>
<p>In this chapter, we dive into ML Pipelines, which are the engine that powers the machine learning functionality we saw in the <a href="modeling.html#modeling">Modeling</a> chapter. When you invoke an ML function via the formula interface, for example <code>ml_logistic_regression(mtcars, am ~ .)</code>, sparklyr actually constructs a <em>pipeline</em> for you under the hood. The Pipelines API is a lower level interface that enables advanced data processing and modeling workflows. In addition, it also facilitates the <em>deployment</em> of ML models. We wil begin with a few definitions and move on to specific examples.</p>
<div id="estimators-and-transformers" class="section level2">
<h2><span class="header-section-number">5.1</span> Estimators and Transformers</h2>
<p>The building blocks of pipelines are objects called transformers and estimators, which are collectively referred to as <strong>pipeline stages</strong>. A <strong>transformer</strong> can be used to apply transformations to a data frame and return another data frame; the resulting data frame often comprises the original data frame with new columns appended to it. An <strong>estimator</strong>, on the other hand, can be used to create a transformer giving some training data. Consider the following example to illustrate this relationship: a “center and scale” estimator can learn the mean and standard deviation of some data and store the statistics in a resulting transformer object; this transformer can then be used to normalize the data it was trained on and also any new, yet unseen, data.</p>
<p>Here is an example of how to define an estimator:</p>
<pre class="sourceCode r"><code class="sourceCode r">scaler &lt;-<span class="st"> </span><span class="kw">ft_standard_scaler</span>(
  sc,
  <span class="dt">input_col =</span> <span class="st">&quot;features&quot;</span>,
  <span class="dt">output_col =</span> <span class="st">&quot;features_scaled&quot;</span>,
  <span class="dt">with_mean =</span> <span class="ot">TRUE</span>
)

scaler</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## StandardScaler (Estimator)</span>
<span class="co">## &lt;standard_scaler_7f6d46f452a1&gt; </span>
<span class="co">##  (Parameters -- Column Names)</span>
<span class="co">##   input_col: features</span>
<span class="co">##   output_col: features_scaled</span>
<span class="co">##  (Parameters)</span>
<span class="co">##   with_mean: TRUE</span>
<span class="co">##   with_std: TRUE</span></code></pre>
<p>We can now create some data (for which we know the mean and standard deviation) then fit our scaling model to it using the <code>ml_fit()</code> function.</p>
<pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, <span class="kw">data.frame</span>(<span class="dt">value =</span> <span class="kw">rnorm</span>(<span class="dv">100000</span>))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ft_vector_assembler</span>(<span class="dt">input_cols =</span> <span class="st">&quot;value&quot;</span>, <span class="dt">output_col =</span> <span class="st">&quot;features&quot;</span>)

scaler_model &lt;-<span class="st"> </span>scaler <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ml_fit</span>(df)
scaler_model</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## StandardScalerModel (Transformer)</span>
<span class="co">## &lt;standard_scaler_7f6d46f452a1&gt; </span>
<span class="co">##  (Parameters -- Column Names)</span>
<span class="co">##   input_col: features</span>
<span class="co">##   output_col: features_scaled</span>
<span class="co">##  (Transformer Info)</span>
<span class="co">##   mean:  num 0.00421 </span>
<span class="co">##   std:  num 0.999 </span></code></pre>
<p><strong>Note:</strong> In Spark ML, many algorithms and feature transformers require that the input be a vector column. The function <code>ft_vector_assembler()</code> performs this task. The function can also be used to initialize a transformer to be used in a pipeline.</p>
<p>We see that the mean and standard deviation are very close to <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, respectively, which is what we expect. We can then use the transformer to <em>transform</em> a data frame, using the <code>ml_transform()</code> function:</p>
<pre class="sourceCode r"><code class="sourceCode r">scaler_model <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ml_transform</span>(df) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## Observations: ??</span>
<span class="co">## Variables: 3</span>
<span class="co">## Database: spark_connection</span>
<span class="co">## $ value           &lt;dbl&gt; 0.75373300, -0.84207731, 0.59365113, -…</span>
<span class="co">## $ features        &lt;list&gt; [0.753733, -0.8420773, 0.5936511, -0.…</span>
<span class="co">## $ features_scaled &lt;list&gt; [0.7502211, -0.8470762, 0.58999, -0.4…</span></code></pre>
</div>
<div id="pipelines-and-pipeline-models" class="section level2">
<h2><span class="header-section-number">5.2</span> Pipelines and Pipeline Models</h2>
<p>A <strong>pipeline</strong> is simply a sequence of transformers and estimators, and a <strong>pipeline model</strong> is a pipeline that has been trained on data so all of its components have been converted to transformers. Note that Spark ML internals dictate that pipelines are always estimators, even if they comprise only of transformers.</p>
<p>There are a couple ways to construct a pipeline in sparklyr, both of which uses the <code>ml_pipeline()</code> function.</p>
<p>We can initialize an empty pipeline with <code>ml_pipeline(sc)</code> and append stages to it:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ml_pipeline</span>(sc) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ft_standard_scaler</span>(
    <span class="dt">input_col =</span> <span class="st">&quot;features&quot;</span>,
    <span class="dt">output_col =</span> <span class="st">&quot;features_scaled&quot;</span>, 
    <span class="dt">with_mean =</span> <span class="ot">TRUE</span>
  )</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## Pipeline (Estimator) with 1 stage</span>
<span class="co">## &lt;pipeline_7f6d6a6a38ee&gt; </span>
<span class="co">##   Stages </span>
<span class="co">##   |--1 StandardScaler (Estimator)</span>
<span class="co">##   |    &lt;standard_scaler_7f6d63bfc7d6&gt; </span>
<span class="co">##   |     (Parameters -- Column Names)</span>
<span class="co">##   |      input_col: features</span>
<span class="co">##   |      output_col: features_scaled</span>
<span class="co">##   |     (Parameters)</span>
<span class="co">##   |      with_mean: TRUE</span>
<span class="co">##   |      with_std: TRUE</span></code></pre>
<p>Alternatively, we can pass stages directly to <code>ml_pipeline()</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">pipeline &lt;-<span class="st"> </span><span class="kw">ml_pipeline</span>(scaler)</code></pre>
<p>We fit a pipeline as we would fit an estimator:</p>
<pre class="sourceCode r"><code class="sourceCode r">pipeline_model &lt;-<span class="st"> </span>pipeline <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ml_fit</span>(df)
pipeline_model</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## PipelineModel (Transformer) with 1 stage</span>
<span class="co">## &lt;pipeline_7f6d64df6e45&gt; </span>
<span class="co">##   Stages </span>
<span class="co">##   |--1 StandardScalerModel (Transformer)</span>
<span class="co">##   |    &lt;standard_scaler_7f6d46f452a1&gt; </span>
<span class="co">##   |     (Parameters -- Column Names)</span>
<span class="co">##   |      input_col: features</span>
<span class="co">##   |      output_col: features_scaled</span>
<span class="co">##   |     (Transformer Info)</span>
<span class="co">##   |      mean:  num 0.00421 </span>
<span class="co">##   |      std:  num 0.999 </span></code></pre>
<pre><code>pipeline </code></pre>
</div>
<div id="applying-pipelines-to-okcupid-data" class="section level2">
<h2><span class="header-section-number">5.3</span> Applying Pipelines to OKCupid Data</h2>
<p>Now that we have an understanding of the rudimentary concepts for ML Pipelines, let us apply them to the predictive modeling problem from the previous chapter, where we are trying to predict whether people are currently employed by looking at their profiles. Our starting point is the <code>okc_train</code> data frame with the relevant columns.</p>
<pre class="sourceCode r"><code class="sourceCode r">okc_train &lt;-<span class="st"> </span>okc_train <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(not_working, age, sex, drinks, drugs, essay1<span class="op">:</span>essay9)</code></pre>
<p>We first exhibit the pipeline, which includes feature engineering and modeling steps, then walk through it.</p>
<pre class="sourceCode r"><code class="sourceCode r">pipeline &lt;-<span class="st"> </span><span class="kw">ml_pipeline</span>(sc) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_string_indexer</span>(<span class="dt">input_col =</span> <span class="st">&quot;sex&quot;</span>, <span class="dt">output_col =</span> <span class="st">&quot;sex_indexed&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_string_indexer</span>(<span class="dt">input_col =</span> <span class="st">&quot;drinks&quot;</span>, <span class="dt">output_col =</span> <span class="st">&quot;drinks_indexed&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_string_indexer</span>(<span class="dt">input_col =</span> <span class="st">&quot;drugs&quot;</span>, <span class="dt">output_col =</span> <span class="st">&quot;drugs_indexed&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_one_hot_encoder_estimator</span>(
    <span class="dt">input_cols =</span> <span class="kw">c</span>(<span class="st">&quot;sex_indexed&quot;</span>, <span class="st">&quot;drinks_indexed&quot;</span>, <span class="st">&quot;drugs_indexed&quot;</span>),
    <span class="dt">output_cols =</span> <span class="kw">c</span>(<span class="st">&quot;sex_encoded&quot;</span>, <span class="st">&quot;drinks_encoded&quot;</span>, <span class="st">&quot;drugs_encoded&quot;</span>)
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_vector_assembler</span>(
    <span class="dt">input_cols =</span> <span class="kw">c</span>(<span class="st">&quot;age&quot;</span>, <span class="st">&quot;sex_encoded&quot;</span>, <span class="st">&quot;drinks_encoded&quot;</span>, 
                   <span class="st">&quot;drugs_encoded&quot;</span>, <span class="st">&quot;essay_length&quot;</span>), 
    <span class="dt">output_col =</span> <span class="st">&quot;features&quot;</span>
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_standard_scaler</span>(<span class="dt">input_col =</span> <span class="st">&quot;features&quot;</span>, <span class="dt">output_col =</span> <span class="st">&quot;features_scaled&quot;</span>, 
                     <span class="dt">with_mean =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ml_logistic_regression</span>(<span class="dt">features_col =</span> <span class="st">&quot;features_scaled&quot;</span>, 
                         <span class="dt">label_col =</span> <span class="st">&quot;not_working&quot;</span>)</code></pre>
<p>The first three stages index the <code>sex</code>, <code>drinks</code>, and <code>drugs</code> columns, which are character, into numeric indicies via <code>ft_string_indexer()</code>. This is necessary for the <code>ft_one_hot_encoder_estimator()</code> that comes next which requires numeric column inputs. Once all of our predictor variables are of numeric type (recall that <code>age</code> is numeric already), we can create our features vector using <code>ft_vector_assembler()</code> which concatenates all of its inputs together into one column of vectors. We can then use <code>ft_standard_scaler()</code> to normalize all elements of the features column (including the one-hot encoded 0/1 values of the categorical variables), and finally apply a logistic regression via <code>ml_logistic_regression()</code>.</p>
<p>During prototyping, you may want to execute these transformations <em>eagerly</em> on a small subset of the data, by passing the data frame to the <code>ft_</code> and <code>ml_</code> functions, and inspecting the transformed data frame. For example, you can do the following:</p>
<pre class="sourceCode r"><code class="sourceCode r">okc_train <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_string_indexer</span>(<span class="st">&quot;sex&quot;</span>, <span class="st">&quot;sex_indexed&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(sex_indexed)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## # Source: spark&lt;?&gt; [?? x 1]</span>
<span class="co">##    sex_indexed</span>
<span class="co">##          &lt;dbl&gt;</span>
<span class="co">##  1           0</span>
<span class="co">##  2           0</span>
<span class="co">##  3           1</span>
<span class="co">##  4           0</span>
<span class="co">##  5           1</span>
<span class="co">##  6           0</span>
<span class="co">##  7           0</span>
<span class="co">##  8           1</span>
<span class="co">##  9           1</span>
<span class="co">## 10           0</span>
<span class="co">## # … with more rows</span></code></pre>
<p>Once you have found the right transformations for your dataset, you can then replace the data frame input with <code>ml_pipeline(sc)</code>, and the result will be a pipeline that you can apply to any data frame with the appropriate schema.</p>
<div id="hyperparameter-tuning" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Hyperparameter Tuning</h3>
<p>Going back to the pipeline we have created above, we can use <code>ml_cross_validator()</code> to perform the cross validation workflow we demonstrated in the previous chapter and easily test different hyperparameter combinations. In this example, we test whether centering the variables improve predictions together with various regularization values for the logistic regression. We define the cross validator as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r">cv &lt;-<span class="st"> </span><span class="kw">ml_cross_validator</span>(
  sc,
  <span class="dt">estimator =</span> pipeline,
  <span class="dt">estimator_param_maps =</span> <span class="kw">list</span>(
    <span class="dt">standard_scaler =</span> <span class="kw">list</span>(<span class="dt">with_mean =</span> <span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>)),
    <span class="dt">logistic_regression =</span> <span class="kw">list</span>(
      <span class="dt">elastic_net_param =</span> <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.75</span>),
      <span class="dt">reg_param =</span> <span class="kw">c</span>(<span class="fl">1e-2</span>, <span class="fl">1e-3</span>)
    )
  ),
  <span class="dt">evaluator =</span> <span class="kw">ml_binary_classification_evaluator</span>(sc, <span class="dt">label_col =</span> <span class="st">&quot;not_working&quot;</span>),
  <span class="dt">num_folds =</span> <span class="dv">10</span>
)</code></pre>
<p>The <code>estimator</code> argument is simply the estimator we want to tune, and in this case it is the <code>pipeline</code> that we defined. We provide the hyperparameter values we are interested in via the <code>estimator_param_maps</code> parameter, which takes a nested named list. The names at the first level correspond to UIDs of the stages we want to tune (if a partial UID is provided sparklyr will attempt to match it to a pipeline stage) and the names at the second level correspond to parameters of each stage. In the snippet above, we are specifying that we want to test</p>
<ul>
<li>Standard scaler: the values <code>TRUE</code> and <code>FALSE</code> for <code>with_mean</code>, which denotes whether predictor values are centered</li>
<li>Logistic regression: The values <code>0.25</code> and <code>0.75</code> for <span class="math inline">\(\alpha\)</span>, and the values <code>1e-2</code> and <code>1e-3</code> for <span class="math inline">\(\lambda\)</span></li>
</ul>
<p>We expect this to give rise to <span class="math inline">\(2 \times 2 \times 2 = 8\)</span> hyperparameter combinations, which we can confirm by printing the <code>cv</code> object:</p>
<pre class="sourceCode r"><code class="sourceCode r">cv</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## CrossValidator (Estimator)</span>
<span class="co">## &lt;cross_validator_d5676ac6f5&gt; </span>
<span class="co">##  (Parameters -- Tuning)</span>
<span class="co">##   estimator: Pipeline</span>
<span class="co">##              &lt;pipeline_d563b0cba31&gt; </span>
<span class="co">##   evaluator: BinaryClassificationEvaluator</span>
<span class="co">##              &lt;binary_classification_evaluator_d561d90b53d&gt; </span>
<span class="co">##     with metric areaUnderROC </span>
<span class="co">##   num_folds: 10 </span>
<span class="co">##   [Tuned over 8 hyperparameter sets]</span></code></pre>
<p>As with any other estimator, we can fit the cross validator using <code>ml_fit()</code></p>
<pre class="sourceCode r"><code class="sourceCode r">cv_model &lt;-<span class="st"> </span>cv <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ml_fit</span>(okc_train)</code></pre>
<p>and inspect the results:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ml_validation_metrics</span>(cv_model) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="op">-</span>areaUnderROC)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">##   areaUnderROC elastic_net_param_1 reg_param_1 with_mean_2</span>
<span class="co">## 1    0.7722700                0.75       0.001        TRUE</span>
<span class="co">## 2    0.7718431                0.75       0.010       FALSE</span>
<span class="co">## 3    0.7718350                0.75       0.010        TRUE</span>
<span class="co">## 4    0.7717677                0.25       0.001        TRUE</span>
<span class="co">## 5    0.7716070                0.25       0.010        TRUE</span>
<span class="co">## 6    0.7715972                0.25       0.010       FALSE</span>
<span class="co">## 7    0.7713816                0.75       0.001       FALSE</span>
<span class="co">## 8    0.7703913                0.25       0.001       FALSE</span></code></pre>
</div>
</div>
<div id="operating-modes-of-pipelines-functions" class="section level2">
<h2><span class="header-section-number">5.4</span> Operating Modes of Pipelines Functions</h2>
<p>By now, you have likely noticed that the pipeline stage functions, such as <code>ft_string_indexer()</code> and <code>ml_logistic_regression()</code> behave differently depending on the first argument passed to them<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>. The full pattern is as follows:</p>
<table>
<colgroup>
<col width="27%" />
<col width="28%" />
<col width="43%" />
</colgroup>
<thead>
<tr class="header">
<th>First argument</th>
<th>Returns</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Spark connection</td>
<td>Estimator or transformer object</td>
<td><code>ft_string_indexer(sc)</code></td>
</tr>
<tr class="even">
<td>Pipeline</td>
<td>Pipeline</td>
<td><code>ml_pipeline(sc) %&gt;% ft_string_indexer()</code></td>
</tr>
<tr class="odd">
<td>Data frame, without formula</td>
<td>Data frame</td>
<td><code>ft_string_indexer(iris, "Species", "indexed")</code></td>
</tr>
<tr class="even">
<td>Data frame, with formula</td>
<td>sparklyr ML model object</td>
<td><code>ml_logistic_regression(iris, Species ~ .)</code></td>
</tr>
</tbody>
</table>
<ul>
<li>If a Spark connection is provided, the function returns a transformer or estimator object, which can be utilized directly using <code>ml_fit()</code> or <code>ml_transform()</code> or be included in a pipeline.</li>
<li>If a pipeline is provided, the function returns a pipeline object with the stage appended to it.</li>
<li>If a data frame is provided to a feature transformer function (those with prefix <code>ft_</code>), or an ML algorithm without also providing a formula, the function instantiates the pipeline stage object, fit it to the data if necessary (if the stage is an estimator), then transforms the data frame returning a data frame.</li>
<li>If a data frame and a formula are provided to an ML algorithm that supports the formula interface, sparklyr builds a pipeline model under the hood and returns an ML model object which contains additional metadata information.</li>
</ul>
<p>The formula interface approach is what we studied in the <a href="modeling.html#modeling">Modeling</a> section, and is what we recommend new users to Spark start with, since its syntax is similar to existing R modeling packages and abstracts away some Spark ML peculiarities. However, to take advantage of the full power of Spark ML and leverage pipelines for workflow organization and interoperability, it is worthwhile to learn the ML Pipelines API.</p>
</div>
<div id="model-persistence-and-interoperability" class="section level2">
<h2><span class="header-section-number">5.5</span> Model Persistence and Interoperability</h2>
<p>One of the most powerful aspects of pipelines is that they can be serialized to disk and are fully interoperable with the other Spark APIs, such as Python and Scala. To save a pipeline model, call <code>ml_save()</code> and provide a path.</p>
<pre class="sourceCode r"><code class="sourceCode r">model_dir &lt;-<span class="st"> </span><span class="kw">file.path</span>(<span class="st">&quot;spark_model&quot;</span>)
<span class="kw">ml_save</span>(cv_model<span class="op">$</span>best_model, model_dir, <span class="dt">overwrite =</span> <span class="ot">TRUE</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## Model successfully saved.</span></code></pre>
<p>Let us take a look at the directory we just wrote to.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">list.dirs</span>(model_dir,<span class="dt">full.names =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">head</span>(<span class="dv">10</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">##  [1] &quot;&quot;                                             </span>
<span class="co">##  [2] &quot;metadata&quot;                                     </span>
<span class="co">##  [3] &quot;stages&quot;                                       </span>
<span class="co">##  [4] &quot;stages/0_string_indexer_5b42c72817b&quot;          </span>
<span class="co">##  [5] &quot;stages/0_string_indexer_5b42c72817b/data&quot;     </span>
<span class="co">##  [6] &quot;stages/0_string_indexer_5b42c72817b/metadata&quot; </span>
<span class="co">##  [7] &quot;stages/1_string_indexer_5b423192b89f&quot;         </span>
<span class="co">##  [8] &quot;stages/1_string_indexer_5b423192b89f/data&quot;    </span>
<span class="co">##  [9] &quot;stages/1_string_indexer_5b423192b89f/metadata&quot;</span>
<span class="co">## [10] &quot;stages/2_string_indexer_5b421796e826&quot;    </span></code></pre>
<p>We can dive into a couple of the files to see what type of data was saved.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">spark_read_json</span>(sc, <span class="kw">file.path</span>(
  model_dir, <span class="st">&quot;stages/1_string_indexer_5b423192b89f/metadata&quot;</span>
)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## Observations: ??</span>
<span class="co">## Variables: 6</span>
<span class="co">## Database: spark_connection</span>
<span class="co">## $ class           &lt;chr&gt; &quot;org.apache.spark.ml.feature.StringIndexerModel&quot;</span>
<span class="co">## $ defaultParamMap &lt;list&gt; [[&quot;error&quot;, &quot;string_indexer_5b423192b89f__output&quot;, &quot;frequencyDesc&quot;]]</span>
<span class="co">## $ paramMap        &lt;list&gt; [[&quot;error&quot;, &quot;drinks&quot;, &quot;drinks_indexed&quot;, &quot;frequencyDesc&quot;]]</span>
<span class="co">## $ sparkVersion    &lt;chr&gt; &quot;2.4.0&quot;</span>
<span class="co">## $ timestamp       &lt;dbl&gt; 1.559467e+12</span>
<span class="co">## $ uid             &lt;chr&gt; &quot;string_indexer_5b423192b89f&quot;</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">spark_read_parquet</span>(sc, <span class="kw">file.path</span>(
  model_dir, <span class="st">&quot;stages/6_logistic_regression_5b423b539d0f/data&quot;</span>
))</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## # Source: spark&lt;data&gt; [?? x 5]</span>
<span class="co">##   numClasses numFeatures interceptVector coefficientMatr… isMultinomial</span>
<span class="co">##        &lt;int&gt;       &lt;int&gt; &lt;list&gt;          &lt;list&gt;           &lt;lgl&gt;        </span>
<span class="co">## 1          2          12 &lt;dbl [1]&gt;       &lt;-1.27950828662… FALSE        </span></code></pre>
<p>We see that quite a bit of information has been exported, from the SQL statement in the dplyr transformer to the fitted coefficient estimates of the logistic regression. We can then (in a new Spark session) reconstruct the model by using <code>ml_load()</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">model_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">ml_load</span>(sc, model_dir)</code></pre>
<p>Let us see if we can retrieve the logistic regression stage from this pipeline model:</p>
<pre class="sourceCode r"><code class="sourceCode r">model_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ml_stage</span>(<span class="st">&quot;logistic_regression&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## LogisticRegressionModel (Transformer)</span>
<span class="co">## &lt;logistic_regression_5b423b539d0f&gt; </span>
<span class="co">##  (Parameters -- Column Names)</span>
<span class="co">##   features_col: features_scaled</span>
<span class="co">##   label_col: not_working</span>
<span class="co">##   prediction_col: prediction</span>
<span class="co">##   probability_col: probability</span>
<span class="co">##   raw_prediction_col: rawPrediction</span>
<span class="co">##  (Transformer Info)</span>
<span class="co">##   coefficient_matrix:  num [1, 1:12] -1.2795 -0.0915 0 0.126 -0.0324 ... </span>
<span class="co">##   coefficients:  num [1:12] -1.2795 -0.0915 0 0.126 -0.0324 ... </span>
<span class="co">##   intercept:  num -2.79 </span>
<span class="co">##   intercept_vector:  num -2.79 </span>
<span class="co">##   num_classes:  int 2 </span>
<span class="co">##   num_features:  int 12 </span>
<span class="co">##   threshold:  num 0.5 </span>
<span class="co">##   thresholds:  num [1:2] 0.5 0.5 </span></code></pre>
<p>Note that the exported JSON and parquet files are agnostic of the API that exported them. This means that in a multilingual machine learning engineering team, you can pick up a data preprocessing pipeline from a data engineer working in Python, build a prediction model on top of it, then hand off the final pipeline off to a deployment engineering working in Scala.</p>
<p><strong>Note:</strong> When <code>ml_save()</code> is called for sparklyr ML models (created using the formula interface), the associated pipeline model is saved, but any sparklyr specific metadata, such as index labels, are not. In other words, saving a sparklyr <code>ml_model</code> object then loading it will yield a pipeline model object, as if you created it via the ML Pipelines API. What we gain from this tradeoff of loss information is interoperability with other languages.</p>
</div>
<div id="model-deployment" class="section level2">
<h2><span class="header-section-number">5.6</span> Model Deployment</h2>
<p>What we have just demonstrated bears emphasizing: by collaborating within the framework of ML pipelines, we reduce friction among different personas in a data science team. In particular, we can cut down on the time from modeling to deployment.</p>
<p>In many cases, a data science project does not end with just a slide deck with insights and recommendations. Instead, the business problem at hand may require scoring new data points on a schedule or on-demand in real time. For example, a bank might want to evaluate its mortgage portfolio risk nightly, or to provide instant decisions on credit card applications. This process of taking a model and turning it into a service that others can consume is usually referred to as <em>deployment</em> or <em>productionization</em>. Historically, there was a large gap between the analyst who built the model and the engineer who deployed it: the former might work in R and develop extensive documentation on the scoring mechanism, so the latter can re-implement the model in C++ or Java. This practice, which may easily take months in some organizations, is less prevalent today, but is almost always unnecessary in Spark ML workflows.</p>
<p>The nightly portfolio risk and credit application scoring examples we mention above represent two modes of ML deployment known as <em>batch</em> and <em>real-time</em>. Loosely, batch processing implies processing many records at the same time and that execution time is not important as long it is reasonable (often on the scale of minutes to hours.) On the other hand, real-time processing implies scoring one or a few records at a time but the latency is crucial (on the scale of &lt;1 second.) We will now see how we can take our OKCupid pipeline model to “production.”</p>
<div id="batch-scoring-with-ml-pipelines" class="section level3">
<h3><span class="header-section-number">5.6.1</span> Batch Scoring With ML Pipelines</h3>
<p>For both cases, we will expose our model as web services, in the form of an API over the Hypertext Transfer Protocol (HTTP). This is the primary medium over which software communicates. By providing an API, other services or end users can utilize our model without any knowledge of R or Spark. The plumber<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> R package enables us to do this very easily by annotating our prediction function.</p>
<p>In the batch scoring use case, we simply initiate a Spark connection and load the saved model. Save the following script as <code>plumber/spark-plumber.R</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)
sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3.0&quot;</span>)
spark_model &lt;-<span class="st"> </span><span class="kw">ml_load</span>(sc, <span class="st">&quot;spark_model&quot;</span>)

<span class="co">#* @post /predict</span>
score_spark &lt;-<span class="st"> </span><span class="cf">function</span>(age, sex, drinks, drugs, essay_length) {
  new_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
    <span class="dt">age =</span> age,
    <span class="dt">sex =</span> sex,
    <span class="dt">drinks =</span> drinks,
    <span class="dt">drugs =</span> drugs,
    <span class="dt">essay_length =</span> essay_length,
    <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>
  )
  new_data_tbl &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, new_data, <span class="dt">overwrite =</span> <span class="ot">TRUE</span>)
  
  <span class="kw">ml_transform</span>(spark_model, pred_data_tbl) <span class="op">%&gt;%</span>
<span class="st">    </span>dplyr<span class="op">::</span><span class="kw">pull</span>(prediction)
}</code></pre>
<p>We can then initialize the service by executing the following:</p>
<pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span>plumber<span class="op">::</span><span class="kw">plumb</span>(<span class="st">&quot;plumber/spark-plumber.R&quot;</span>)
p<span class="op">$</span><span class="kw">run</span>(<span class="dt">port =</span> <span class="dv">8000</span>)</code></pre>
<p>This should start the web service locally and emit a message similar to</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## Starting server to listen on port 8000</span>
<span class="co">## Running the swagger UI at http://127.0.0.1:8000/__swagger__/</span></code></pre>
<p>In a separate R session, we can try to query the service with new data to be scored:</p>
<pre class="sourceCode r"><code class="sourceCode r">httr<span class="op">::</span><span class="kw">POST</span>(
  <span class="st">&quot;http://127.0.0.1:8000/predict&quot;</span>,
  <span class="dt">body =</span> <span class="st">&#39;{&quot;age&quot;: [42], &quot;sex&quot;: &quot;m&quot;, &quot;drinks&quot;: &quot;not at all&quot;, </span>
<span class="st">           &quot;drugs&quot;: &quot;never&quot;, &quot;essay_length&quot;: [99]}&#39;</span>
) <span class="op">%&gt;%</span>
<span class="st">  </span>httr<span class="op">::</span><span class="kw">content</span>()</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## [[1]]</span>
<span class="co">## [1] 0</span></code></pre>
<p>If we were to time this operation (e.g. with <code>system.time()</code>), we see that the latency is on the order of hundreds of milliseconds, which may be appropriate for batch applications but insufficient for real-time. The main bottleneck is the serialization of the R data frame to a Spark data frame and back. Also, it also requires an active Spark session which is a heavy runtime requirement.</p>
</div>
<div id="real-time-scoring-with-mleap" class="section level3">
<h3><span class="header-section-number">5.6.2</span> Real-Time Scoring with MLeap</h3>
<p>For real-time production, we want to keep dependencies as light as possible so we can target more platforms for deployment. We now show how we can use the mleap<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> package, which provides an interface to the MLeap<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> library, to serialize and serve Spark ML models. At run time, the only prerequisites for the environment are the Java Virtual Machine (JVM) and the MLeap runtime library. This avoids both the Spark binaries and expensive overhead in converting data to and from Spark data frames.</p>
<p>Since mleap is a sparklyr extension, it must be loaded when <code>spark_connect()</code> is called. We can start a new R session and establish a new Spark connection<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>, and load the pipeline model that we previously saved.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)
<span class="kw">library</span>(mleap)
sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>, <span class="dt">version =</span> <span class="st">&quot;2.3.0&quot;</span>)

spark_model &lt;-<span class="st"> </span><span class="kw">ml_load</span>(sc, <span class="st">&quot;spark_model&quot;</span>)</code></pre>
<p>The way we save a model to MLeap bundle format is very similar to saving a model using the Spark ML Pipelines API; the only additional argument is <code>sample_input</code>, which is a Spark data frame with schema that we expect new data to be scored to have.</p>
<pre class="sourceCode r"><code class="sourceCode r">sample_input &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">sex =</span> <span class="st">&quot;m&quot;</span>,
  <span class="dt">drinks =</span> <span class="st">&quot;not at all&quot;</span>,
  <span class="dt">drugs =</span> <span class="st">&quot;never&quot;</span>,
  <span class="dt">essay_length =</span> <span class="dv">99</span>,
  <span class="dt">age =</span> <span class="dv">25</span>,
  <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>
)

sample_input_tbl &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, sample_input)

<span class="kw">ml_write_bundle</span>(spark_model, <span class="dt">sample_input =</span> sample_input_tbl, <span class="dt">path =</span> <span class="st">&quot;mleap_model.zip&quot;</span>)</code></pre>
<p>The artifact we just created, <code>mleap_model.zip</code>, can now be deployed in any device that runs Java and has the open source MLeap runtime dependencies, without needing Spark. To test this model, we can create a new plumber API to expose it. The script <code>plumber/mleap-plumber.R</code> is very similar to the previous example:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mleap)
<span class="co"># install_maven()</span>
<span class="co"># install_mleap()</span>

mleap_model &lt;-<span class="st"> </span><span class="kw">mleap_load_bundle</span>(<span class="st">&quot;mleap_model.zip&quot;</span>)

<span class="co">#* @post /predict</span>
score_spark &lt;-<span class="st"> </span><span class="cf">function</span>(age, sex, drinks, drugs, essay_length) {
  new_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
    <span class="dt">age =</span> <span class="kw">as.double</span>(age),
    <span class="dt">sex =</span> sex,
    <span class="dt">drinks =</span> drinks,
    <span class="dt">drugs =</span> drugs,
    <span class="dt">essay_length =</span> <span class="kw">as.double</span>(essay_length),
    <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>
  )
  <span class="kw">mleap_transform</span>(mleap_model, new_data)<span class="op">$</span>prediction
}</code></pre>
<p>And the way we launch the service is exactly the same:</p>
<pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span>plumber<span class="op">::</span><span class="kw">plumb</span>(<span class="st">&quot;plumber/mleap-plumber.R&quot;</span>)
p<span class="op">$</span><span class="kw">run</span>(<span class="dt">port =</span> <span class="dv">8000</span>)</code></pre>
<p>Again, in a separate session, we can run the exact same code we did previously to test this new service:</p>
<pre class="sourceCode r"><code class="sourceCode r">httr<span class="op">::</span><span class="kw">POST</span>(
  <span class="st">&quot;http://127.0.0.1:8000/predict&quot;</span>,
  <span class="dt">body =</span> <span class="st">&#39;{&quot;age&quot;: [42], &quot;sex&quot;: &quot;m&quot;, &quot;drinks&quot;: &quot;not at all&quot;, </span>
<span class="st">           &quot;drugs&quot;: &quot;never&quot;, &quot;essay_length&quot;: [99]}&#39;</span>
) <span class="op">%&gt;%</span>
<span class="st">  </span>httr<span class="op">::</span><span class="kw">content</span>()</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## [[1]]</span>
<span class="co">## [1] 0</span></code></pre>
<p>If we were to time this operation, we will see that the service now returns predictions in tens of milliseconds!</p>
</div>
</div>
<div id="conclusion-1" class="section level2">
<h2><span class="header-section-number">5.7</span> Conclusion</h2>
<p>In this chapter, we discuss the Spark ML Pipelines API which is the engine behind the modeling functions covered in the previous chapter. We show how to tidy up our sparklyr predictive modeling workflow by organize data processing and machine learning routines into pipelines. Pipelines also facilitate collaboration among members of a multilingual data science and engineering team by sharing a language agnostic serialization format. Model deployment is examined, and paths to productionization for both batch and real-time settings are demonstrated.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p><a href="https://www.rplumber.io/" class="uri">https://www.rplumber.io/</a><a href="pipelines.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p><a href="https://www.rplumber.io/" class="uri">https://www.rplumber.io/</a><a href="pipelines.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p><a href="https://github.com/rstudio/mleap">https://github.com/rstudio/mleap</a><a href="pipelines.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p><a href="https://github.com/combust/mleap">https://github.com/combust/mleap</a><a href="pipelines.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>Note that, as of the writing of this book, MLeap does not yet support Spark 2.4, so we use Spark 2.3 instead.<a href="pipelines.html#fnref7" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modeling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="clusters.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
