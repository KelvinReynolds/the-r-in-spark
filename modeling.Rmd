```{r include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
source("r/render.R")
```
```{r echo=FALSE, eval=TRUE}
library(tidyverse)
library(sparklyr)
library(dbplot)
config <- spark_config()
config["sparklyr.shell.driver-memory"] <- "4G"
sc <- spark_connect(master = "local", config = config)
```

# Modeling {#modeling}

In this chapter, we discover how Spark can be used to scale up predictive modeling workflows to big data. We build off of the ideas presented in the Analysis chapter and introduce the machine learning (ML) aspects. Spark MLlib is the component of Spark that allows one to write high level code to perform machine learning tasks on distributed data. Sparklyr provides an interface to the ML algorithms that should be familiar to R users. For example, you can run a logistic regression as follows:

```{r eval = FALSE}
ml_logistic_regression(big_dataset, response ~ .)
```

As can be seen in [List of ML functions](#functionlist), Spark provides a wide range of algorithms and feature transformers, and we will touch on a representative portion of the functionality. A complete treatment of predictive modeling concepts is outside the scope of this book, so we recommend complementing with @intro-r-for-data-science and @kuhn-fes, from which we take inspiration for many examples in this chapter.

## The Data

The examples in this chapter will utilize the OkCupid dataset, available at [^1]. The dataset consists of user profile data from an online dating site, and contains a diverse set of features, including biographical characteristics such as gender and profession, and free text fields related to personal interests. There are about 60,000 profiles in the dataset, which fits comfortably into memory on a modern laptop and wouldn't be considered "big data", so you can easily follow along running Spark local mode. In a later chapter, we'll discuss specific considerations for dealing with distributed datasets on clusters.

[^1]: [https://github.com/rudeboybert/JSE_OkCupid](https://github.com/rudeboybert/JSE_OkCupid)

To motivate the examples, we will consider the following problem:

> Predict whether someone is actively working, i.e. not retired, a student, or unemployed.

**Note**: The examples in this chapter utilize small datasets so readers can easily follow along in local mode. In practice, if your dataset fits comfortably in memory on your local machine, you may be better off using an efficient non-distributed implementation of the ML algorithm. For example, you may want to use the ranger package instead of `ml_random_forest_classifier()`.

## Exploratory Data Analysis (EDA)

We'll first read in the data, assuming `profiles.csv` is in the `data/` folder.

```{r}
okc <- spark_read_csv(sc, "data/profiles.csv", escape = "\"", options = list(multiline = TRUE)) %>%
  mutate(
    height = as.numeric(height),
    income = ifelse(income == "-1", NA, as.numeric(income))
  ) %>%
  mutate_if(is.character, list(~ ifelse(is.na(.), "missing", .)))
```

Note that we specify `escape = "\""` and `options = list(multiline = TRUE)` here to accommodate for embedded quote characters and newlines in the essay fields. We also convert the `height` and `income` columns to numeric types, and recode missing values in the string columns.

We can take a quick look at the data with `glimpse()`:

```{r}
glimpse(okc)
```

```r
## Observations: ??
## Variables: 31
## Database: spark_connection
## $ age         <int> 22, 35, 38, 23, 29, 29, 32, 31, 24, 37, 35, 28, 24, 30, 29, 3…
## $ body_type   <chr> "a little extra", "average", "thin", "thin", "athletic", "ave…
## $ diet        <chr> "strictly anything", "mostly other", "anything", "vegetarian"…
## $ drinks      <chr> "socially", "often", "socially", "socially", "socially", "soc…
## $ drugs       <chr> "never", "sometimes", "missing", "missing", "never", "missing…
## $ education   <chr> "working on college/university", "working on space camp", "gr…
## $ essay0      <chr> "about me:<br />\n<br />\ni would love to think that i was so…
## $ essay1      <chr> "currently working as an international agent for a freight\nf…
## $ essay2      <chr> "making people laugh.<br />\nranting about a good salting.<br…
## $ essay3      <chr> "the way i look. i am a six foot half asian, half caucasian m…
## $ essay4      <chr> "books:<br />\nabsurdistan, the republic, of mice and men (on…
## $ essay5      <chr> "food.<br />\nwater.<br />\ncell phone.<br />\nshelter.", "de…
## $ essay6      <chr> "duality and humorous things", "missing", "missing", "cats an…
## $ essay7      <chr> "trying to find someone to hang out with. i am down for anyth…
## $ essay8      <chr> "i am new to california and looking for someone to wisper my …
## $ essay9      <chr> "you want to be swept off your feet!<br />\nyou are tired of …
## $ ethnicity   <chr> "asian, white", "white", "missing", "white", "asian, black, o…
## $ height      <dbl> 75, 70, 68, 71, 66, 67, 65, 65, 67, 65, 70, 72, 72, 66, 62, 6…
## $ income      <dbl> NaN, 80000, NaN, 20000, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 40…
## $ job         <chr> "transportation", "hospitality / travel", "missing", "student…
## $ last_online <chr> "2012-06-28-20-30", "2012-06-29-21-41", "2012-06-27-09-10", "…
## $ location    <chr> "south san francisco, california", "oakland, california", "sa…
## $ offspring   <chr> "doesn&rsquo;t have kids, but might want them", "doesn&rsquo;…
## $ orientation <chr> "straight", "straight", "straight", "straight", "straight", "…
## $ pets        <chr> "likes dogs and likes cats", "likes dogs and likes cats", "ha…
## $ religion    <chr> "agnosticism and very serious about it", "agnosticism but not…
## $ sex         <chr> "m", "m", "m", "m", "m", "m", "f", "f", "f", "m", "m", "m", "…
## $ sign        <chr> "gemini", "cancer", "pisces but it doesn&rsquo;t matter", "pi…
## $ smokes      <chr> "sometimes", "no", "no", "no", "no", "no", "missing", "no", "…
## $ speaks      <chr> "english", "english (fluently), spanish (poorly), french (poo…
## $ status      <chr> "single", "single", "available", "single", "single", "single"…
```

Now we will add our response variable as a column in the dataset.

```{r}
okc <- okc %>%
  filter(!is.na(job)) %>%
  mutate(not_working = ifelse(job %in% c("student", "unemployed", "retired"), 1 , 0))
```

Before we proceed further, let us perform an initial split of our data into a training set and a testing set. In practice, this is a crucial step because we would like to have a holdout set that we set aside at the end of the modeling process to evaluate model performance. This can be done easily by using the `sdf_partition()` function:

```{r}
data_splits <- sdf_partition(okc, training = 0.8, testing = 0.2)
okc_train <- data_splits$training
okc_test <- data_splits$testing
```

We can quickly look at the distribution of our response variable:

```{r}
okc_train %>%
  group_by(not_working) %>%
  tally() %>%
  mutate(frac = n / sum(n, na.rm = TRUE))
```

```r
## # Source: spark<?> [?? x 3]
##   not_working     n   frac
##         <dbl> <dbl>  <dbl>
## 1           0 43593 0.909 
## 2           1  4342 0.0906
```

Using the `sdf_describe()` function, we can obtain numerical summaries of specific columns:

```{r}
sdf_describe(okc_train, cols = c("age", "income"))
```

```r
## # Source: spark<?> [?? x 3]
##   summary age               income            
##   <chr>   <chr>             <chr>             
## 1 count   47935             9196              
## 2 mean    32.31519766350266 104385.60243584168
## 3 stddev  9.426466867310086 201771.7144657046 
## 4 min     18                20000.0           
## 5 max     109               1000000.0 
```

Like we saw in the Analysis chapter, we can also utilize the dbplot package to plot distributions of these variables:

```{r echo = FALSE}
p <- okc_train %>% dbplot_histogram(age) + theme_bw()
ggsave("images/modeling-okc-histogram-age.png", plot = p, device = "png")
```

```r
okc_train %>%
  dbplot_histogram(age)
```

```{r, echo = FALSE, eval = TRUE}
render_image("images/modeling-okc-histogram-age.png", "Distribution of age.")
```

A common EDA exercise is to look at the relationship between the response and the individual predictors. For example, we can explore the `religion` variable:

```{r}
prop_data <- okc_train %>%
  mutate(religion = regexp_extract(religion, "^\\\\w+", 0)) %>% 
  group_by(religion, not_working) %>%
  tally() %>%
  group_by(religion) %>%
  summarize(
    count = sum(n, na.rm = TRUE),
    prop = sum(not_working * n, na.rm = TRUE) / sum(n, na.rm = TRUE)
  ) %>%
  mutate(se = sqrt(prop * (1 - prop) / count)) %>%
  collect()

prop_data
```

```{r echo = FALSE}
saveRDS(prop_data, "data/modeling-okc-prop-data.rds")
```

```r
## # A tibble: 10 x 4
##    religion     count   prop      se
##    <chr>        <dbl>  <dbl>   <dbl>
##  1 judaism       2489 0.0836 0.00557
##  2 atheism       5561 0.120  0.00436
##  3 christianity  4645 0.114  0.00469
##  4 hinduism       375 0.0907 0.0148 
##  5 islam          114 0.193  0.0370 
##  6 agnosticism   7048 0.0989 0.00361
##  7 other         6184 0.0881 0.00361
##  8 missing      16124 0.0710 0.002  
##  9 buddhism      1562 0.0883 0.00721
## 10 catholicism   3833 0.0931 0.00469
```

Note that `prop_data` is a small data frame that has been collected into memory in our R session, we can take advantage of ggplot2 to create an informative visualization.

```{r, echo = FALSE, eval=TRUE}
prop_data <- readRDS("data/modeling-okc-prop-data.rds")
prop_data %>%
  ggplot(aes(x = religion, y = prop)) + 
  geom_errorbar(aes(ymin = prop - 1.96 * se, ymax = prop + 1.96 * se), width = .1) +
  geom_point(size = 2) +
  geom_hline(yintercept = sum(prop_data$prop * prop_data$count) / sum(prop_data$count), linetype = "dashed", color = "red") +
  theme_bw()
```

Next, we take a look at the relationship between a couple of predictors: alcohol use and drug use. We would expect there to be some correlation between them. You can compute a contingency table via `sdf_crosstab()`:

```{r}
contingency_tbl <- okc_train %>% 
  sdf_crosstab("drinks", "drugs") %>%
  collect()

contingency_tbl
```

```r
## # A tibble: 7 x 5
##   drinks_drugs missing never often sometimes
##   <chr>          <dbl> <dbl> <dbl>     <dbl>
## 1 very often        50   142    48       137
## 2 socially        8138 21048   132      4100
## 3 not at all       166  2343    12        91
## 4 desperately       71    98    23        68
## 5 often           1054  1692    68      1294
## 6 missing         1114  1229     9        65
## 7 rarely           630  3637    40       436
```

```{r echo = FALSE}
saveRDS(contingency_tbl, "data/modeling-okc-contingency-table.rds")
```

We can visualize this contingency table using a mosaic plot.

```{r echo = FALSE, eval=TRUE}
library(ggmosaic)

contingency_tbl <- readRDS("data/modeling-okc-contingency-table.rds")

contingency_tbl %>%
  rename(drinks = drinks_drugs) %>%
  gather("drugs", "count", missing:sometimes) %>%
  mutate(
    drinks = as_factor(drinks) %>% 
      fct_relevel("missing", "not at all", "rarely", "socially", "very often", "desperately"),
    drugs = as_factor(drugs) %>%
      fct_relevel("missing", "never", "sometimes", "often")
  ) %>%
  ggplot() +
  geom_mosaic(aes(x = product(drinks, drugs), fill = drinks, weight = count)) +
  theme_bw() + 
  guides(fill = FALSE) +
  xlab("Drugs") +
  ylab("Drinks") +
  theme(
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)#,
    # axis.text.y = element_text(angle = 45, vjust = 1, hjust = 1)
  )

```

To further explore the relationship between this two variables, we can perform correspondence analysis using the FactoMineR package and visualize the results.

```{r eval=TRUE, echo = FALSE}
# From FES
dd_obj <- contingency_tbl %>% 
  column_to_rownames(var = "drinks_drugs") %>%
  as.matrix() %>%
  as.table() %>%
  FactoMineR::CA(graph = FALSE)

dd_drugs <-
  dd_obj$row$coord %>%
  as.data.frame() %>%
  mutate(
    label = gsub("_", " ", rownames(dd_obj$row$coord)),
    Variable = "Drugs"
  )

dd_drinks <-
  dd_obj$col$coord %>%
  as.data.frame() %>%
  mutate(
    label = gsub("_", " ", rownames(dd_obj$col$coord)),
    Variable = "Alcohol"
  )

# ------------------------------------------------------------------------------

dd_rng <- extendrange(c(dd_drinks$`Dim 1`, dd_drinks$`Dim 2`))
dd_x <- paste0("Dimension #1 (",
               round(dd_obj$eig["dim 1", "percentage of variance"], 0),
               "%)")
dd_y <- paste0("Dimension #2 (",
               round(dd_obj$eig["dim 2", "percentage of variance"], 0),
               "%)")

ca_coord <- rbind(dd_drugs, dd_drinks)

# ------------------------------------------------------------------------------

ggplot(ca_coord, aes(x = `Dim 1`, y = `Dim 2`, col = Variable)) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  geom_text(aes(label = label)) +
  xlim(dd_rng) + ylim(dd_rng) +
  xlab(dd_x) + ylab(dd_y) +
  coord_equal() +
  theme_bw()
```

Correspondence analysis transforms the factors into variables called *principal coordinates*, which correspond to the axes in the plot and represent how much information in the contingency table they contain. We can, for example, interpret the proximity of "drinking often" and "using drugs very often" as indicating association.

## Feature Engineering

Since some of the profile feature are multiple-select, we need to process them before we can build meaningful models. If we take a look at the ethnicity column, for example, we see that there are many different combinations:

```{r}
okc_train %>%
  group_by(ethnicity) %>%
  tally()
```

```r
## # Source: spark<?> [?? x 2]
##    ethnicity                                     n
##    <chr>                                     <dbl>
##  1 hispanic / latin, white                    1039
##  2 black, pacific islander, hispanic / latin     4
##  3 black, native american, indian, white         1
##  4 asian, black, pacific islander                5
##  5 black, native american, white                94
##  6 middle eastern, white, other                 32
##  7 asian, other                                 77
##  8 asian, black, white                          15
##  9 indian, hispanic / latin                      5
## 10 asian, hispanic / latin, white, other         7
# … with more rows
```

For our model, we create indicator variables for each race, as follows:

```{r}
ethnicities <- c("asian", "middle eastern", "black", "native american", "indian", 
                 "pacific islander", "hispanic / latin", "white", "other")
ethnicity_vars <- ethnicities %>% 
  map(~ expr(ifelse(like(ethnicity, !!.x), 1, 0))) %>%
  set_names(paste0("ethnicity_", gsub("\\s|/", "", ethnicities)))
okc_train <- mutate(okc_train, !!!ethnicity_vars)
okc_train %>% 
  select(starts_with("ethnicity_")) %>%
  glimpse()
```

```r
## Observations: ??
## Variables: 9
## Database: spark_connection
## $ ethnicity_asian           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ ethnicity_middleeastern   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…
## $ ethnicity_black           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ ethnicity_nativeamerican  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ ethnicity_indian          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,…
## $ ethnicity_pacificislander <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ ethnicity_hispaniclatin   <dbl> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,…
## $ ethnicity_white           <dbl> 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,…
## $ ethnicity_other           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
```

For the free text fields, a straightforward way to extract features is counting the total number of characters.

```{r echo = FALSE}
okc_train <- okc_train %>%
  mutate(
    essay_length = char_length(paste(!!!syms(paste0("essay", 0:9))))
  )
p <- okc_train %>%
  dbplot_histogram(essay_length, bins = 50) +
  theme_bw()
ggsave("images/modeling-okc-histogram-essay-length.png", plot = p, device = "png")
```

```{r}
okc_train <- okc_train %>%
  mutate(
    essay_length = char_length(paste(!!!syms(paste0("essay", 0:9))))
  )
okc_train %>%
  dbplot_histogram(essay_length, bins = 50)
```

```{r echo = FALSE}
render_image("images/modeling-okc-histogram-essay-length.png")
```

## Model Building

Once we have a good grasp on our dataset, we can start building some models. Before we do so, however, we need to come up with a plan to tune and validate our candidate models. Since we are dealing with a binary classification problem, the metrics one can use include accuracy, precision, sensitivity, and area under the receiver operating characteristic (ROC) curve (AUC), among others. The metric you optimize depends on your specific business problem, but for this exercise, we will focus on the AUC.

It is important that we don't peek at the testing holdout set until the very end. For tuning and validation, we will perform 10-fold cross validation. The scheme works as follows: We first divide our dataset into 10 approximately equal sized subsets. We take the 2nd to 10th sets together as the training set for an algorithm, and validate the resulting model on the 1st set. Next, we reserve the 2nd set as the validation set, and train the algorithm on the 1st and 3rd to 10th sets. In total, we train ten models and average the performance. If time and resources allow, you can also perform this procedure multiple times with different random partitions of the data. In our case, we will demonstrate how to perform the cross validation once.

Using the `sdf_partition()` function, we can create a list of subsets from our `okc_train` table:

```{r}
vfolds <- sdf_partition(
  okc_train,
  weights = set_names(rep(0.1, 10), paste0("fold", 1:10))
)
```

We then create our first training/validation split as follows:

```{r}
train_set <- do.call(rbind, vfolds[2:10])
validation_set <- vfolds[[1]]
```

Logistic regression is often a reasonable starting point for binary classification problems, so let us give it a try. Suppose also that our domain knowledge provides us with an initial set of predictors. We can then fit a model by using the formula interface:

```{r}
lr <- ml_logistic_regression(train_set, not_working ~ age + sex + drinks + drugs + essay_length)
lr
```

```r
## Formula: not_working ~ age + sex + drinks + drugs + essay_length
## 
## Coefficients:
##       (Intercept)               age             sex_m   drinks_socially     drinks_rarely      drinks_often 
##      1.674124e+00     -1.359159e-01     -1.913872e-01      3.333511e-01      7.787464e-01      8.154644e-02 
## drinks_not at all    drinks_missing drinks_very often       drugs_never     drugs_missing   drugs_sometimes 
##      9.376850e-01     -2.369372e-01      3.641265e-01     -3.665337e-01     -5.526731e-01     -2.806046e-01 
##      essay_length 
##      3.474749e-05 
```

To obtain a summary of performance metrics on the validation set, we can use the `ml_evaluate()` function.

```{r}
validation_summary <- ml_evaluate(lr, validation_set)
```

You can print `validation_summary` to see the available metrics

```{r}
validation_summary
```

```
## BinaryLogisticRegressionSummaryImpl 
##  Access the following via `$` or `ml_summary()`. 
##  - features_col() 
##  - label_col() 
##  - predictions() 
##  - probability_col() 
##  - area_under_roc() 
##  - f_measure_by_threshold() 
##  - pr() 
##  - precision_by_threshold() 
##  - recall_by_threshold() 
##  - roc() 
##  - prediction_col() 
##  - accuracy() 
##  - f_measure_by_label() 
##  - false_positive_rate_by_label() 
##  - labels() 
##  - precision_by_label() 
##  - recall_by_label() 
##  - true_positive_rate_by_label() 
##  - weighted_f_measure() 
##  - weighted_false_positive_rate() 
##  - weighted_precision() 
##  - weighted_recall() 
##  - weighted_true_positive_rate() 
 ```

We can plot the ROC curve by collecting the output of `validation_summary$roc()` and using ggplot2:

```{r echo = FALSE}
roc <- validation_summary$roc() %>%
  collect()
saveRDS(roc, "data/modeling-okc-roc-1.rds")
```

```{r, echo = FALSE, eval = TRUE}
roc <- readRDS("data/modeling-okc-roc-1.rds")
ggplot(roc, aes(x = FPR, y = TPR)) +
  geom_line() +
  geom_abline(color = "red", lty = "dashed") +
  theme_bw()
```

Recall that the ROC curve plots the true positive rate (sensitivity) against the false positive rate (1 - specificity) for varying values of the classification threshold. In practice, the business problem helps to determine where on the curve one sets the threshold for classification. The AUC is a summary measure for determining the quality of a model, and we can compute it by calling the `area_under_roc()` function.

```{r}
validation_summary$area_under_roc()
```

```r
## [1] 0.7872754
```

**Note**: Spark only provides evaluation methods for generalized linear models (including linear models and logistic regression.) For other algorithms, you can use the evaluator functions (e.g. `ml_binary_classification_evaluator()` on the prediction data frame) or compute your own metrics.

Now, we can easily repeat the logic we have above and apply it to each train/validation split:

```{r}
cv_results <- map_df(1:10, function(v) {
  train_set <- do.call(rbind, vfolds[setdiff(1:10, v)])
  validation_set <- vfolds[[v]]
  model <- ml_logistic_regression(train_set, not_working ~ age + sex + drinks + drugs + essay_length)
  s <- ml_evaluate(model, validation_set)
  roc_df <- s$roc() %>% 
    collect()
  auc <- s$area_under_roc()
  
  tibble(
    Resample = paste0("Fold", str_pad(v, width = 2, pad = "0")),
    roc_df = list(roc_df),
    auc = auc
  )
})
```

This gives us 10 ROC curves:

```{r echo = FALSE}
cv_roc <- cv_results %>% 
  unnest(roc_df)
saveRDS(cv_roc, "data/modeling-okc-cv-roc.rds")
```

```{r echo = FALSE, eval = TRUE}
cv_roc <- readRDS("data/modeling-okc-cv-roc.rds")
cv_roc %>%
  ggplot(aes(x = FPR, y = TPR, color = Resample)) +
  geom_line() + 
  geom_abline(color = "red", lty = "dashed") +
  theme_bw()
```

and we can obtain the average AUC metric:

```{r}
mean(cv_results$auc)
```

```r
## [1] 0.7703891
```

### Logistic Regression as a Generalized Linear Regression

In Spark ML, you can also fit a logistic regression via the generalized linear regression interface by specifying `family = "binomial"`. Because the result is a regression model, the `ml_predict()` method does not give class probabilities. However, this interface may be of interest to those who are looking for generalized linear model (GLM) diagnostics, including confidence intervals for coefficient estimates.

```{r, echo = FALSE}
glr <- ml_generalized_linear_regression(
  train_set, 
  not_working ~ age + sex + drinks + drugs + essay_length, 
  family = "binomial"
)
tidy_glr <- tidy(glr)
saveRDS(tidy_glr, "data/modeling-okc-tidy-glr.rds")
```

```{r}
glr <- ml_generalized_linear_regression(
  train_set, 
  not_working ~ age + sex + drinks + drugs, 
  family = "binomial"
)

tidy(glr)
```

```{r, echo = FALSE, eval = TRUE}
tidy_glr <- readRDS("data/modeling-okc-tidy-glr.rds")
tidy_glr
```

We can extract the coefficient estimates into a tidy data frame, which we can then process further, for example, to create a coefficient plot.

```{r echo = FALSE, eval=TRUE}
tidy_glr %>%
  ggplot(aes(x = term, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = estimate - 1.96 * std.error, ymax = estimate + 1.96 * std.error, width = .1)) +
  coord_flip() +
  theme_bw() +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed")
```

**Note**: Both `ml_logistic_regression()` and `ml_linear_regression()` support elastic net regularization [@zou2005regularization] through the `reg_param` and `elastic_net_param` parameters. `reg_param` corresponds to $lambda$ whereas `elastic_net_param` correspond to $alpha$. `ml_generalized_linear_regression()` supports only `reg_param`.

## More Machine Learning Algorithms

Beyond linear models, Spark ML supports many of the standard ML algorithms with the mechanism demonstrated above, you can try different algorithms and hyperparameters for your problem. The interfaces to access these functionalities are largely identical, so it is easy to experiment with them. For example, to fit a neural network model we can run:

```{r}
nn <- ml_multilayer_perceptron_classifier(
  train_set,
  not_working ~ age + sex + drinks + drugs + essay_length, 
  layers = c(12, 32, 32, 2)
)
```

This gives us a feedforward neural network model with two hidden layers of 32 nodes each. Note that you have to specify the correct values for the input and output layers in the `layers` argument. We can obtain predictions on a validation set using `ml_predict()`

```{r}
predictions <- ml_predict(nn, validation_set)
```

then compute the AUC via `ml_binary_classification_evaluator()`

```{r}
ml_binary_classification_evaluator(predictions)
```

```r
## [1] 0.7337616
```

## List of ML Functions {#functionlist}

The following table exhibits the ML algorithms supported in sparklyr:

### Classification

Algorithm | Function
----------|---------
Decision Trees | ml_decision_tree_classifier()
Gradient-Boosted Trees | ml_gbt_classifier()
Linear Support Vector Machines | ml_linear_svc()
Logistic Regression | ml_logistic_regression()
Multilayer Perceptron | ml_multilayer_perceptron_classifier()
Naive-Bayes | ml_naive_bayes()
One vs Rest | ml_one_vs_rest()
Random Forests | ml_random_forest_classifier()

### Regression

Algorithm | Function
----------|---------
Accelerated Failure Time Survival Regression | ml_aft_survival_regression()
Decision Trees | ml_decision_tree_regressor()
Generalized Linear Regression | ml_generalized_linear_regression()
Gradient-Boosted Trees | ml_gbt_regressor()
Isotonic Regression | ml_isotonic_regression()
Linear Regression | ml_linear_regression()

### Clustering

Algorithm | Function
----------|---------
Bisecting K-Means Clustering | ml_bisecting_kmeans()
Gaussian Mixture Clustering | ml_gaussian_mixture()
K-Means Clustering | ml_kmeans()
Latent Dirichlet Allocation | ml_lda()

### Recommendation

Algorithm | Function
----------|---------
Alternating Least Squares Factorization | ml_als()

### Frequent Pattern Mining

Algorithm | Function
----------|---------
FPGrowth | ml_fpgrowth()

### Feature Transformers

Transformer | Function
------------|---------
Binarizer | ft_binarizer()
Bucketizer | ft_bucketizer()
Chi-Squared Feature Selector | ft_chisq_selector()
Vocabulary from Document Collections | ft_count_vectorizer()
Discrete Cosine Transform  | ft_discrete_cosine_transform()
Transformation using dplyr | ft_dplyr_transformer()
Hadamard Product | ft_elementwise_product()
Feature Hasher | ft_feature_hasher()
Term Frequencies using Hashing | export(ft_hashing_tf)
Inverse Document Frequency | ft_idf()
Imputation for Missing Values | export(ft_imputer)
Index to String | ft_index_to_string()
Feature Interaction Transform | ft_interaction()
Rescale to [-1, 1] Range | ft_max_abs_scaler()
Rescale to [min, max] Range | ft_min_max_scaler()
Locality Sensitive Hashing | ft_minhash_lsh()
Converts to n-grams | ft_ngram()
Normalize using the given P-Norm | ft_normalizer()
One-Hot Encoding | ft_one_hot_encoder()
Feature Expansion in Polynomial Space | ft_polynomial_expansion()
Maps to Binned Categorical Features | ft_quantile_discretizer()
SQL Transformation | ft_sql_transformer()
Standardizes Features using Corrected STD | ft_standard_scaler()
Filters out Stop Words | ft_stop_words_remover()
Map to Label Indices | ft_string_indexer()
Splits by White Spaces | ft_tokenizer()
Combine Vectors to Row Vector | ft_vector_assembler()
Indexing Categorical Feature | ft_vector_indexer()
Subarray of the Original Feature | ft_vector_slicer()
Transform Word into Code | ft_word2vec()
